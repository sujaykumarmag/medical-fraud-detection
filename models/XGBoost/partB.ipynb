{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/part_B/imputed_partb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"Rndrng_NPI\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rndrng_Prvdr_Crdntls</th>\n",
       "      <th>Rndrng_Prvdr_Gndr</th>\n",
       "      <th>Rndrng_Prvdr_Type</th>\n",
       "      <th>Rndrng_Prvdr_Mdcr_Prtcptg_Ind</th>\n",
       "      <th>Tot_HCPCS_Cds</th>\n",
       "      <th>Tot_Benes</th>\n",
       "      <th>Tot_Srvcs</th>\n",
       "      <th>Tot_Sbmtd_Chrg</th>\n",
       "      <th>Tot_Mdcr_Alowd_Amt</th>\n",
       "      <th>Tot_Mdcr_Pymt_Amt</th>\n",
       "      <th>...</th>\n",
       "      <th>Bene_CC_Hyplpdma_Pct</th>\n",
       "      <th>Bene_CC_Hyprtnsn_Pct</th>\n",
       "      <th>Bene_CC_IHD_Pct</th>\n",
       "      <th>Bene_CC_Opo_Pct</th>\n",
       "      <th>Bene_CC_RAOA_Pct</th>\n",
       "      <th>Bene_CC_Sz_Pct</th>\n",
       "      <th>Bene_CC_Strok_Pct</th>\n",
       "      <th>Bene_Avg_Risk_Scre</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>FraudType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>402812.00</td>\n",
       "      <td>85319.63</td>\n",
       "      <td>69175.78</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.5028</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2633.0</td>\n",
       "      <td>5930.0</td>\n",
       "      <td>915291.00</td>\n",
       "      <td>227372.53</td>\n",
       "      <td>176497.74</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>182532.48</td>\n",
       "      <td>101757.15</td>\n",
       "      <td>76938.82</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.6935</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>23680.00</td>\n",
       "      <td>9011.99</td>\n",
       "      <td>7224.35</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7089</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>152154.00</td>\n",
       "      <td>30631.10</td>\n",
       "      <td>23962.85</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.1137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100721</th>\n",
       "      <td>7310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>329504.00</td>\n",
       "      <td>32266.94</td>\n",
       "      <td>25803.90</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.4526</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100722</th>\n",
       "      <td>7310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>182515.00</td>\n",
       "      <td>93505.14</td>\n",
       "      <td>68252.03</td>\n",
       "      <td>...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2418</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100723</th>\n",
       "      <td>3073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>20985.00</td>\n",
       "      <td>16171.02</td>\n",
       "      <td>11759.42</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100724</th>\n",
       "      <td>7310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>851.0</td>\n",
       "      <td>304460.56</td>\n",
       "      <td>113283.09</td>\n",
       "      <td>85463.83</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.1737</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100725</th>\n",
       "      <td>17582</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>884.0</td>\n",
       "      <td>340479.02</td>\n",
       "      <td>90924.61</td>\n",
       "      <td>74063.76</td>\n",
       "      <td>...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.7672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100726 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Rndrng_Prvdr_Crdntls  Rndrng_Prvdr_Gndr  Rndrng_Prvdr_Type  \\\n",
       "0                        7310                0.0                 39   \n",
       "1                        7310                0.0                 65   \n",
       "2                        7310                0.0                  5   \n",
       "3                        7310                1.0                 56   \n",
       "4                        9043                0.0                 27   \n",
       "...                       ...                ...                ...   \n",
       "1100721                  7310                0.0                 22   \n",
       "1100722                  7310                1.0                 39   \n",
       "1100723                  3073                0.0                 13   \n",
       "1100724                  7310                0.0                 63   \n",
       "1100725                 17582                1.0                 39   \n",
       "\n",
       "         Rndrng_Prvdr_Mdcr_Prtcptg_Ind  Tot_HCPCS_Cds  Tot_Benes  Tot_Srvcs  \\\n",
       "0                                    1           16.0      291.0      764.0   \n",
       "1                                    1           18.0     2633.0     5930.0   \n",
       "2                                    1           54.0      167.0     2003.0   \n",
       "3                                    1           21.0       56.0      571.0   \n",
       "4                                    1           30.0       89.0      125.0   \n",
       "...                                ...            ...        ...        ...   \n",
       "1100721                              1            9.0      155.0      171.0   \n",
       "1100722                              1           40.0      333.0     1093.0   \n",
       "1100723                              1            2.0       66.0      415.0   \n",
       "1100724                              1           46.0      456.0      851.0   \n",
       "1100725                              1           15.0      407.0      884.0   \n",
       "\n",
       "         Tot_Sbmtd_Chrg  Tot_Mdcr_Alowd_Amt  Tot_Mdcr_Pymt_Amt  ...  \\\n",
       "0             402812.00            85319.63           69175.78  ...   \n",
       "1             915291.00           227372.53          176497.74  ...   \n",
       "2             182532.48           101757.15           76938.82  ...   \n",
       "3              23680.00             9011.99            7224.35  ...   \n",
       "4             152154.00            30631.10           23962.85  ...   \n",
       "...                 ...                 ...                ...  ...   \n",
       "1100721       329504.00            32266.94           25803.90  ...   \n",
       "1100722       182515.00            93505.14           68252.03  ...   \n",
       "1100723        20985.00            16171.02           11759.42  ...   \n",
       "1100724       304460.56           113283.09           85463.83  ...   \n",
       "1100725       340479.02            90924.61           74063.76  ...   \n",
       "\n",
       "         Bene_CC_Hyplpdma_Pct  Bene_CC_Hyprtnsn_Pct  Bene_CC_IHD_Pct  \\\n",
       "0                        73.0                  75.0             66.0   \n",
       "1                        48.0                  48.0             24.0   \n",
       "2                        52.0                  68.0             31.0   \n",
       "3                        52.0                  50.0             23.0   \n",
       "4                        43.0                  60.0             33.0   \n",
       "...                       ...                   ...              ...   \n",
       "1100721                  71.0                  75.0             70.0   \n",
       "1100722                  49.0                  66.0             25.0   \n",
       "1100723                  61.0                  53.0             26.0   \n",
       "1100724                  44.0                  53.0             26.0   \n",
       "1100725                  75.0                  75.0             61.0   \n",
       "\n",
       "         Bene_CC_Opo_Pct  Bene_CC_RAOA_Pct  Bene_CC_Sz_Pct  Bene_CC_Strok_Pct  \\\n",
       "0                   11.0              51.0             9.0               19.0   \n",
       "1                   10.0              38.0             1.0                3.0   \n",
       "2                    6.0              75.0            10.0                5.0   \n",
       "3                   20.0              32.0             0.0                0.0   \n",
       "4                   13.0              57.0             7.0                8.0   \n",
       "...                  ...               ...             ...                ...   \n",
       "1100721              9.0              48.0            27.0               15.0   \n",
       "1100722              9.0              41.0             3.0                4.0   \n",
       "1100723             17.0              56.0             0.0                0.0   \n",
       "1100724              9.0              37.0             3.0                2.0   \n",
       "1100725             11.0              48.0             7.0               23.0   \n",
       "\n",
       "         Bene_Avg_Risk_Scre  Fraud  FraudType  \n",
       "0                    2.5028      0          0  \n",
       "1                    1.1124      0          0  \n",
       "2                    1.6935      0          0  \n",
       "3                    0.7089      0          0  \n",
       "4                    2.1137      0          0  \n",
       "...                     ...    ...        ...  \n",
       "1100721              3.4526      0          0  \n",
       "1100722              1.2418      0          0  \n",
       "1100723              0.9525      0          0  \n",
       "1100724              1.1737      0          0  \n",
       "1100725              2.7672      0          0  \n",
       "\n",
       "[1100726 rows x 61 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9999091511996584\n",
      "\n",
      "Confusion Matrix:\n",
      " [[220126      0]\n",
      " [    20      0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    220126\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           1.00    220146\n",
      "   macro avg       0.50      0.50      0.50    220146\n",
      "weighted avg       1.00      1.00      1.00    220146\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Fraud', 'FraudType'], axis=1)\n",
    "y = df['Fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Convert the data to DMatrix format for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Set hyperparameters for the XGBoost model\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.1,\n",
    "    'subsample': 0.8,\n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "num_round = 100\n",
    "model = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "# Convert predicted probabilities to binary predictions\n",
    "y_pred = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/part_B/partb_rus_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.723404255319149\n",
      "\n",
      "Confusion Matrix:\n",
      " [[16  4]\n",
      " [ 9 18]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.80      0.71        20\n",
      "           1       0.82      0.67      0.73        27\n",
      "\n",
      "    accuracy                           0.72        47\n",
      "   macro avg       0.73      0.73      0.72        47\n",
      "weighted avg       0.74      0.72      0.72        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Fraud'], axis=1)\n",
    "y = df['Fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Convert the data to DMatrix format for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Set hyperparameters for the XGBoost model\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.1,\n",
    "    'subsample': 0.8,\n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "num_round = 100\n",
    "model = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "# Convert predicted probabilities to binary predictions\n",
    "y_pred = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/part_B/partb_ros_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9594588455492863\n",
      "\n",
      "Confusion Matrix:\n",
      " [[202412  17848]\n",
      " [     0 219984]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96    220260\n",
      "           1       0.92      1.00      0.96    219984\n",
      "\n",
      "    accuracy                           0.96    440244\n",
      "   macro avg       0.96      0.96      0.96    440244\n",
      "weighted avg       0.96      0.96      0.96    440244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Fraud'], axis=1)\n",
    "y = df['Fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Convert the data to DMatrix format for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Set hyperparameters for the XGBoost model\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.1,\n",
    "    'subsample': 0.8,\n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "num_round = 100\n",
    "model = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "# Convert predicted probabilities to binary predictions\n",
    "y_pred = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/part_B/partb_smote_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9692838760312478\n",
      "\n",
      "Confusion Matrix:\n",
      " [[208077   9977]\n",
      " [  3486 216764]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97    218054\n",
      "           1       0.96      0.98      0.97    220250\n",
      "\n",
      "    accuracy                           0.97    438304\n",
      "   macro avg       0.97      0.97      0.97    438304\n",
      "weighted avg       0.97      0.97      0.97    438304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Fraud'], axis=1)\n",
    "y = df['Fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Convert the data to DMatrix format for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Set hyperparameters for the XGBoost model\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.1,\n",
    "    'subsample': 0.8,\n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "num_round = 100\n",
    "model = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "# Convert predicted probabilities to binary predictions\n",
    "y_pred = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/part_B/partb_rus_type_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "\n",
      "Confusion Matrix:\n",
      " [[0 1 0 0]\n",
      " [0 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 1 0 0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       1.0\n",
      "           5       0.00      0.00      0.00       0.0\n",
      "           9       0.00      0.00      0.00       1.0\n",
      "          11       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       3.0\n",
      "   macro avg       0.00      0.00      0.00       3.0\n",
      "weighted avg       0.00      0.00      0.00       3.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming df is your DataFrame containing the data\n",
    "\n",
    "X = df.drop(['FraudType'], axis=1)\n",
    "y = df['FraudType']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the data to DMatrix format for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Set hyperparameters for the XGBoost model\n",
    "params = {\n",
    "    'objective': 'multi:softprob',\n",
    "    'eval_metric': 'mlogloss',  # Use 'mlogloss' for multi-class problems\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'num_class': len(pd.unique(y)),  # Specify the number of classes\n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "num_round = 100\n",
    "model = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_prob = model.predict(dtest)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)  # Convert probabilities to class labels\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/part_B/partb_ros_type_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9966448675664474\n",
      "\n",
      "Confusion Matrix:\n",
      " [[210905   2631    592      0     43    192      0   1382     55      0\n",
      "    4539    167      0]\n",
      " [     0 219923      0      0      0      0      0      0      0      0\n",
      "       0      0      0]\n",
      " [     0      0 220160      0      0      0      0      0      0      0\n",
      "       0      0      0]\n",
      " [     0      0      0 219441      0      0      0      0      0      0\n",
      "       0      0      0]\n",
      " [     0      0      0      0 219881      0      0      0      0      0\n",
      "       0      0      0]\n",
      " [     0      0      0      0      0 220554      0      0      0      0\n",
      "       0      0      0]\n",
      " [     0      0      0      0      0      0 220506      0      0      0\n",
      "       0      0      0]\n",
      " [     0      0      0      0      0      0      0 219980      0      0\n",
      "       0      0      0]\n",
      " [     0      0      0      0      0      0      0      0 219640      0\n",
      "       0      0      0]\n",
      " [     0      0      0      0      0      0      0      0      0 220210\n",
      "       0      0      0]\n",
      " [     0      0      0      0      0      0      0      0      0      0\n",
      "  220713      0      0]\n",
      " [     0      0      0      0      0      0      0      0      0      0\n",
      "       0 220020      0]\n",
      " [     0      0      0      0      0      0      0      0      0      0\n",
      "       0      0 220052]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98    220506\n",
      "           1       0.99      1.00      0.99    219923\n",
      "           2       1.00      1.00      1.00    220160\n",
      "           3       1.00      1.00      1.00    219441\n",
      "           4       1.00      1.00      1.00    219881\n",
      "           5       1.00      1.00      1.00    220554\n",
      "           6       1.00      1.00      1.00    220506\n",
      "           7       0.99      1.00      1.00    219980\n",
      "           8       1.00      1.00      1.00    219640\n",
      "           9       1.00      1.00      1.00    220210\n",
      "          10       0.98      1.00      0.99    220713\n",
      "          11       1.00      1.00      1.00    220020\n",
      "          12       1.00      1.00      1.00    220052\n",
      "\n",
      "    accuracy                           1.00   2861586\n",
      "   macro avg       1.00      1.00      1.00   2861586\n",
      "weighted avg       1.00      1.00      1.00   2861586\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming df is your DataFrame containing the data\n",
    "\n",
    "X = df.drop(['FraudType'], axis=1)\n",
    "y = df['FraudType']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the data to DMatrix format for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Set hyperparameters for the XGBoost model\n",
    "params = {\n",
    "    'objective': 'multi:softprob',\n",
    "    'eval_metric': 'mlogloss',  # Use 'mlogloss' for multi-class problems\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'num_class': len(pd.unique(y)),  # Specify the number of classes\n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "num_round = 100\n",
    "model = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_prob = model.predict(dtest)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)  # Convert probabilities to class labels\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
