{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/part_D/imputed_partd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"PRSCRBR_NPI\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prscrbr_Crdntls</th>\n",
       "      <th>Prscrbr_Gndr</th>\n",
       "      <th>Prscrbr_Type</th>\n",
       "      <th>Prscrbr_Type_src</th>\n",
       "      <th>Tot_Clms</th>\n",
       "      <th>Tot_30day_Fills</th>\n",
       "      <th>Tot_Drug_Cst</th>\n",
       "      <th>Tot_Day_Suply</th>\n",
       "      <th>Tot_Benes</th>\n",
       "      <th>GE65_Sprsn_Flag</th>\n",
       "      <th>...</th>\n",
       "      <th>Bene_Race_Black_Cnt</th>\n",
       "      <th>Bene_Race_Api_Cnt</th>\n",
       "      <th>Bene_Race_Hspnc_Cnt</th>\n",
       "      <th>Bene_Race_Natind_Cnt</th>\n",
       "      <th>Bene_Race_Othr_Cnt</th>\n",
       "      <th>Bene_Dual_Cnt</th>\n",
       "      <th>Bene_Ndual_Cnt</th>\n",
       "      <th>Bene_Avg_Risk_Scre</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>FraudType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>369.800000</td>\n",
       "      <td>20606.08</td>\n",
       "      <td>8621.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2.245800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>2145.666667</td>\n",
       "      <td>79803.65</td>\n",
       "      <td>60953.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.695165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57.700000</td>\n",
       "      <td>327.34</td>\n",
       "      <td>554.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.006070</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3535</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>128.52</td>\n",
       "      <td>181.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.251869</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6421</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>3834.98</td>\n",
       "      <td>1366.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.919074</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254982</th>\n",
       "      <td>13080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>80.666667</td>\n",
       "      <td>9870.01</td>\n",
       "      <td>2357.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.451353</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254983</th>\n",
       "      <td>4831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>73.200000</td>\n",
       "      <td>397.84</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.344691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254984</th>\n",
       "      <td>15356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>90.466667</td>\n",
       "      <td>13618.96</td>\n",
       "      <td>2704.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.545349</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254985</th>\n",
       "      <td>7632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137</td>\n",
       "      <td>1.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>291.066667</td>\n",
       "      <td>10899.52</td>\n",
       "      <td>5801.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.109445</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254986</th>\n",
       "      <td>16837</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>290.633333</td>\n",
       "      <td>14449.86</td>\n",
       "      <td>6436.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.748669</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1254987 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Prscrbr_Crdntls  Prscrbr_Gndr  Prscrbr_Type  Prscrbr_Type_src  \\\n",
       "0                   7632           0.0            86               1.0   \n",
       "1                   7632           0.0             9               1.0   \n",
       "2                   4394           0.0            42               1.0   \n",
       "3                   3535           1.0            42               1.0   \n",
       "4                   6421           1.0           120               1.0   \n",
       "...                  ...           ...           ...               ...   \n",
       "1254982            13080           1.0           128               1.0   \n",
       "1254983             4831           0.0            42               1.0   \n",
       "1254984            15356           0.0           120               1.0   \n",
       "1254985             7632           0.0           137               1.0   \n",
       "1254986            16837           1.0            86               1.0   \n",
       "\n",
       "         Tot_Clms  Tot_30day_Fills  Tot_Drug_Cst  Tot_Day_Suply  Tot_Benes  \\\n",
       "0           324.0       369.800000      20606.08         8621.0      106.0   \n",
       "1          1992.0      2145.666667      79803.65        60953.0      228.0   \n",
       "2            57.0        57.700000        327.34          554.0       43.0   \n",
       "3            18.0        18.000000        128.52          181.0       16.0   \n",
       "4            37.0        47.000000       3834.98         1366.0       17.0   \n",
       "...           ...              ...           ...            ...        ...   \n",
       "1254982      40.0        80.666667       9870.01         2357.0       17.0   \n",
       "1254983      72.0        73.200000        397.84         1092.0       27.0   \n",
       "1254984      47.0        90.466667      13618.96         2704.0       21.0   \n",
       "1254985     249.0       291.066667      10899.52         5801.0      126.0   \n",
       "1254986     274.0       290.633333      14449.86         6436.0      103.0   \n",
       "\n",
       "         GE65_Sprsn_Flag  ...  Bene_Race_Black_Cnt  Bene_Race_Api_Cnt  \\\n",
       "0                    1.0  ...                 27.0                0.0   \n",
       "1                    1.0  ...                 81.0                0.0   \n",
       "2                    1.0  ...                  0.0                0.0   \n",
       "3                    1.0  ...                  0.0                0.0   \n",
       "4                    1.0  ...                  0.0                0.0   \n",
       "...                  ...  ...                  ...                ...   \n",
       "1254982              1.0  ...                  0.0               16.0   \n",
       "1254983              1.0  ...                 18.0               18.0   \n",
       "1254984              1.0  ...                  0.0                0.0   \n",
       "1254985              1.0  ...                 14.0               16.0   \n",
       "1254986              1.0  ...                 25.0                0.0   \n",
       "\n",
       "         Bene_Race_Hspnc_Cnt  Bene_Race_Natind_Cnt  Bene_Race_Othr_Cnt  \\\n",
       "0                       13.0                   0.0                 0.0   \n",
       "1                       12.0                   0.0                 0.0   \n",
       "2                        0.0                   0.0                 0.0   \n",
       "3                        0.0                   0.0                 0.0   \n",
       "4                        0.0                   0.0                 0.0   \n",
       "...                      ...                   ...                 ...   \n",
       "1254982                  0.0                   0.0                 0.0   \n",
       "1254983                  0.0                   0.0                 0.0   \n",
       "1254984                  0.0                   0.0                 0.0   \n",
       "1254985                 18.0                   0.0                14.0   \n",
       "1254986                 16.0                   0.0                 0.0   \n",
       "\n",
       "         Bene_Dual_Cnt  Bene_Ndual_Cnt  Bene_Avg_Risk_Scre  Fraud  FraudType  \n",
       "0                 28.0            78.0            2.245800      0          0  \n",
       "1                125.0           103.0            1.695165      0          0  \n",
       "2                  0.0            43.0            1.006070      0          0  \n",
       "3                  0.0            12.0            1.251869      0          0  \n",
       "4                 11.0            11.0            4.919074      0          0  \n",
       "...                ...             ...                 ...    ...        ...  \n",
       "1254982            0.0            11.0            1.451353      0          0  \n",
       "1254983           18.0            18.0            1.344691      0          0  \n",
       "1254984           13.0            13.0            1.545349      1          2  \n",
       "1254985           18.0           108.0            1.109445      0          0  \n",
       "1254986           28.0            75.0            2.748669      0          0  \n",
       "\n",
       "[1254987 rows x 72 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6444903\ttotal: 535ms\tremaining: 4m 27s\n",
      "1:\tlearn: 0.6004851\ttotal: 1.01s\tremaining: 4m 11s\n",
      "2:\tlearn: 0.5604357\ttotal: 1.45s\tremaining: 4m\n",
      "3:\tlearn: 0.5238871\ttotal: 1.9s\tremaining: 3m 55s\n",
      "4:\tlearn: 0.4903923\ttotal: 2.41s\tremaining: 3m 58s\n",
      "5:\tlearn: 0.4595992\ttotal: 2.88s\tremaining: 3m 57s\n",
      "6:\tlearn: 0.4312502\ttotal: 3.33s\tremaining: 3m 54s\n",
      "7:\tlearn: 0.4050210\ttotal: 3.79s\tremaining: 3m 53s\n",
      "8:\tlearn: 0.3807265\ttotal: 4.13s\tremaining: 3m 45s\n",
      "9:\tlearn: 0.3581974\ttotal: 4.58s\tremaining: 3m 44s\n",
      "10:\tlearn: 0.3372642\ttotal: 5.02s\tremaining: 3m 43s\n",
      "11:\tlearn: 0.3177828\ttotal: 5.48s\tremaining: 3m 42s\n",
      "12:\tlearn: 0.2996312\ttotal: 5.93s\tremaining: 3m 42s\n",
      "13:\tlearn: 0.2826616\ttotal: 6.38s\tremaining: 3m 41s\n",
      "14:\tlearn: 0.2668008\ttotal: 6.82s\tremaining: 3m 40s\n",
      "15:\tlearn: 0.2519531\ttotal: 7.3s\tremaining: 3m 40s\n",
      "16:\tlearn: 0.2380412\ttotal: 7.75s\tremaining: 3m 40s\n",
      "17:\tlearn: 0.2250093\ttotal: 8.23s\tremaining: 3m 40s\n",
      "18:\tlearn: 0.2127674\ttotal: 8.71s\tremaining: 3m 40s\n",
      "19:\tlearn: 0.2012680\ttotal: 9.17s\tremaining: 3m 40s\n",
      "20:\tlearn: 0.1904528\ttotal: 9.65s\tremaining: 3m 40s\n",
      "21:\tlearn: 0.1802870\ttotal: 10.2s\tremaining: 3m 42s\n",
      "22:\tlearn: 0.1707160\ttotal: 10.7s\tremaining: 3m 41s\n",
      "23:\tlearn: 0.1616999\ttotal: 11.1s\tremaining: 3m 40s\n",
      "24:\tlearn: 0.1532018\ttotal: 11.6s\tremaining: 3m 40s\n",
      "25:\tlearn: 0.1451997\ttotal: 12s\tremaining: 3m 39s\n",
      "26:\tlearn: 0.1376424\ttotal: 12.5s\tremaining: 3m 38s\n",
      "27:\tlearn: 0.1305072\ttotal: 13s\tremaining: 3m 39s\n",
      "28:\tlearn: 0.1237709\ttotal: 13.5s\tremaining: 3m 39s\n",
      "29:\tlearn: 0.1174136\ttotal: 14s\tremaining: 3m 39s\n",
      "30:\tlearn: 0.1114054\ttotal: 14.5s\tremaining: 3m 39s\n",
      "31:\tlearn: 0.1057300\ttotal: 15s\tremaining: 3m 39s\n",
      "32:\tlearn: 0.1003487\ttotal: 15.5s\tremaining: 3m 39s\n",
      "33:\tlearn: 0.0952619\ttotal: 16s\tremaining: 3m 39s\n",
      "34:\tlearn: 0.0904554\ttotal: 16.5s\tremaining: 3m 38s\n",
      "35:\tlearn: 0.0859013\ttotal: 16.9s\tremaining: 3m 38s\n",
      "36:\tlearn: 0.0815931\ttotal: 17.4s\tremaining: 3m 37s\n",
      "37:\tlearn: 0.0775145\ttotal: 17.8s\tremaining: 3m 36s\n",
      "38:\tlearn: 0.0736495\ttotal: 18.3s\tremaining: 3m 35s\n",
      "39:\tlearn: 0.0699934\ttotal: 18.7s\tremaining: 3m 35s\n",
      "40:\tlearn: 0.0665221\ttotal: 19.2s\tremaining: 3m 34s\n",
      "41:\tlearn: 0.0632425\ttotal: 19.6s\tremaining: 3m 33s\n",
      "42:\tlearn: 0.0601305\ttotal: 20.1s\tremaining: 3m 33s\n",
      "43:\tlearn: 0.0571707\ttotal: 20.6s\tremaining: 3m 33s\n",
      "44:\tlearn: 0.0543724\ttotal: 21s\tremaining: 3m 32s\n",
      "45:\tlearn: 0.0517168\ttotal: 21.5s\tremaining: 3m 32s\n",
      "46:\tlearn: 0.0491934\ttotal: 22s\tremaining: 3m 31s\n",
      "47:\tlearn: 0.0468066\ttotal: 22.4s\tremaining: 3m 31s\n",
      "48:\tlearn: 0.0445357\ttotal: 22.9s\tremaining: 3m 30s\n",
      "49:\tlearn: 0.0423847\ttotal: 23.4s\tremaining: 3m 30s\n",
      "50:\tlearn: 0.0403411\ttotal: 23.8s\tremaining: 3m 29s\n",
      "51:\tlearn: 0.0384064\ttotal: 24.3s\tremaining: 3m 29s\n",
      "52:\tlearn: 0.0365679\ttotal: 24.8s\tremaining: 3m 29s\n",
      "53:\tlearn: 0.0348207\ttotal: 25.2s\tremaining: 3m 28s\n",
      "54:\tlearn: 0.0331715\ttotal: 25.7s\tremaining: 3m 27s\n",
      "55:\tlearn: 0.0315952\ttotal: 26.1s\tremaining: 3m 27s\n",
      "56:\tlearn: 0.0301015\ttotal: 26.6s\tremaining: 3m 26s\n",
      "57:\tlearn: 0.0286827\ttotal: 27s\tremaining: 3m 26s\n",
      "58:\tlearn: 0.0273381\ttotal: 27.5s\tremaining: 3m 25s\n",
      "59:\tlearn: 0.0260607\ttotal: 28s\tremaining: 3m 25s\n",
      "60:\tlearn: 0.0248436\ttotal: 28.4s\tremaining: 3m 24s\n",
      "61:\tlearn: 0.0236904\ttotal: 28.9s\tremaining: 3m 24s\n",
      "62:\tlearn: 0.0225973\ttotal: 29.4s\tremaining: 3m 23s\n",
      "63:\tlearn: 0.0215557\ttotal: 29.8s\tremaining: 3m 23s\n",
      "64:\tlearn: 0.0205692\ttotal: 30.3s\tremaining: 3m 22s\n",
      "65:\tlearn: 0.0196321\ttotal: 30.8s\tremaining: 3m 22s\n",
      "66:\tlearn: 0.0187424\ttotal: 31.2s\tremaining: 3m 21s\n",
      "67:\tlearn: 0.0178938\ttotal: 31.6s\tremaining: 3m 21s\n",
      "68:\tlearn: 0.0170857\ttotal: 32.1s\tremaining: 3m 20s\n",
      "69:\tlearn: 0.0163230\ttotal: 32.6s\tremaining: 3m 20s\n",
      "70:\tlearn: 0.0155957\ttotal: 33s\tremaining: 3m 19s\n",
      "71:\tlearn: 0.0149071\ttotal: 33.5s\tremaining: 3m 19s\n",
      "72:\tlearn: 0.0142529\ttotal: 34s\tremaining: 3m 18s\n",
      "73:\tlearn: 0.0136310\ttotal: 34.4s\tremaining: 3m 17s\n",
      "74:\tlearn: 0.0130380\ttotal: 34.8s\tremaining: 3m 17s\n",
      "75:\tlearn: 0.0124752\ttotal: 35.3s\tremaining: 3m 16s\n",
      "76:\tlearn: 0.0119466\ttotal: 35.8s\tremaining: 3m 16s\n",
      "77:\tlearn: 0.0114388\ttotal: 36.3s\tremaining: 3m 16s\n",
      "78:\tlearn: 0.0109552\ttotal: 36.7s\tremaining: 3m 15s\n",
      "79:\tlearn: 0.0104983\ttotal: 37.2s\tremaining: 3m 15s\n",
      "80:\tlearn: 0.0100680\ttotal: 37.7s\tremaining: 3m 14s\n",
      "81:\tlearn: 0.0096549\ttotal: 38.1s\tremaining: 3m 14s\n",
      "82:\tlearn: 0.0092612\ttotal: 38.6s\tremaining: 3m 13s\n",
      "83:\tlearn: 0.0088896\ttotal: 39s\tremaining: 3m 13s\n",
      "84:\tlearn: 0.0085341\ttotal: 39.5s\tremaining: 3m 12s\n",
      "85:\tlearn: 0.0081987\ttotal: 39.9s\tremaining: 3m 12s\n",
      "86:\tlearn: 0.0078777\ttotal: 40.3s\tremaining: 3m 11s\n",
      "87:\tlearn: 0.0075754\ttotal: 40.9s\tremaining: 3m 11s\n",
      "88:\tlearn: 0.0072871\ttotal: 41.3s\tremaining: 3m 10s\n",
      "89:\tlearn: 0.0070136\ttotal: 41.8s\tremaining: 3m 10s\n",
      "90:\tlearn: 0.0067544\ttotal: 42.3s\tremaining: 3m 10s\n",
      "91:\tlearn: 0.0065066\ttotal: 42.8s\tremaining: 3m 9s\n",
      "92:\tlearn: 0.0062710\ttotal: 43.2s\tremaining: 3m 9s\n",
      "93:\tlearn: 0.0060487\ttotal: 43.6s\tremaining: 3m 8s\n",
      "94:\tlearn: 0.0058371\ttotal: 44s\tremaining: 3m 7s\n",
      "95:\tlearn: 0.0056357\ttotal: 44.5s\tremaining: 3m 7s\n",
      "96:\tlearn: 0.0054447\ttotal: 45s\tremaining: 3m 6s\n",
      "97:\tlearn: 0.0052677\ttotal: 45.5s\tremaining: 3m 6s\n",
      "98:\tlearn: 0.0050964\ttotal: 45.9s\tremaining: 3m 5s\n",
      "99:\tlearn: 0.0049343\ttotal: 46.5s\tremaining: 3m 5s\n",
      "100:\tlearn: 0.0047812\ttotal: 47.2s\tremaining: 3m 6s\n",
      "101:\tlearn: 0.0046363\ttotal: 47.7s\tremaining: 3m 6s\n",
      "102:\tlearn: 0.0044978\ttotal: 48.4s\tremaining: 3m 6s\n",
      "103:\tlearn: 0.0043667\ttotal: 48.9s\tremaining: 3m 6s\n",
      "104:\tlearn: 0.0042431\ttotal: 49.6s\tremaining: 3m 6s\n",
      "105:\tlearn: 0.0041235\ttotal: 50.2s\tremaining: 3m 6s\n",
      "106:\tlearn: 0.0040106\ttotal: 50.8s\tremaining: 3m 6s\n",
      "107:\tlearn: 0.0039060\ttotal: 51.3s\tremaining: 3m 6s\n",
      "108:\tlearn: 0.0038047\ttotal: 51.8s\tremaining: 3m 5s\n",
      "109:\tlearn: 0.0037102\ttotal: 52.4s\tremaining: 3m 5s\n",
      "110:\tlearn: 0.0036193\ttotal: 53s\tremaining: 3m 5s\n",
      "111:\tlearn: 0.0035346\ttotal: 53.8s\tremaining: 3m 6s\n",
      "112:\tlearn: 0.0034552\ttotal: 54.6s\tremaining: 3m 6s\n",
      "113:\tlearn: 0.0033790\ttotal: 55.5s\tremaining: 3m 8s\n",
      "114:\tlearn: 0.0033057\ttotal: 56.5s\tremaining: 3m 9s\n",
      "115:\tlearn: 0.0032377\ttotal: 57.5s\tremaining: 3m 10s\n",
      "116:\tlearn: 0.0031715\ttotal: 58.3s\tremaining: 3m 10s\n",
      "117:\tlearn: 0.0031093\ttotal: 59.2s\tremaining: 3m 11s\n",
      "118:\tlearn: 0.0030513\ttotal: 1m\tremaining: 3m 12s\n",
      "119:\tlearn: 0.0029952\ttotal: 1m\tremaining: 3m 12s\n",
      "120:\tlearn: 0.0029421\ttotal: 1m 2s\tremaining: 3m 14s\n",
      "121:\tlearn: 0.0028919\ttotal: 1m 2s\tremaining: 3m 14s\n",
      "122:\tlearn: 0.0028446\ttotal: 1m 3s\tremaining: 3m 15s\n",
      "123:\tlearn: 0.0027986\ttotal: 1m 4s\tremaining: 3m 16s\n",
      "124:\tlearn: 0.0027568\ttotal: 1m 5s\tremaining: 3m 16s\n",
      "125:\tlearn: 0.0027176\ttotal: 1m 6s\tremaining: 3m 16s\n",
      "126:\tlearn: 0.0026801\ttotal: 1m 7s\tremaining: 3m 17s\n",
      "127:\tlearn: 0.0026448\ttotal: 1m 8s\tremaining: 3m 18s\n",
      "128:\tlearn: 0.0026119\ttotal: 1m 9s\tremaining: 3m 19s\n",
      "129:\tlearn: 0.0025805\ttotal: 1m 10s\tremaining: 3m 19s\n",
      "130:\tlearn: 0.0025504\ttotal: 1m 10s\tremaining: 3m 19s\n",
      "131:\tlearn: 0.0025215\ttotal: 1m 11s\tremaining: 3m 20s\n",
      "132:\tlearn: 0.0024940\ttotal: 1m 12s\tremaining: 3m 21s\n",
      "133:\tlearn: 0.0024693\ttotal: 1m 13s\tremaining: 3m 21s\n",
      "134:\tlearn: 0.0024453\ttotal: 1m 14s\tremaining: 3m 22s\n",
      "135:\tlearn: 0.0024224\ttotal: 1m 15s\tremaining: 3m 22s\n",
      "136:\tlearn: 0.0024012\ttotal: 1m 16s\tremaining: 3m 22s\n",
      "137:\tlearn: 0.0023818\ttotal: 1m 17s\tremaining: 3m 23s\n",
      "138:\tlearn: 0.0023617\ttotal: 1m 18s\tremaining: 3m 23s\n",
      "139:\tlearn: 0.0023438\ttotal: 1m 19s\tremaining: 3m 24s\n",
      "140:\tlearn: 0.0023275\ttotal: 1m 20s\tremaining: 3m 25s\n",
      "141:\tlearn: 0.0023128\ttotal: 1m 21s\tremaining: 3m 25s\n",
      "142:\tlearn: 0.0022975\ttotal: 1m 22s\tremaining: 3m 26s\n",
      "143:\tlearn: 0.0022835\ttotal: 1m 23s\tremaining: 3m 26s\n",
      "144:\tlearn: 0.0022708\ttotal: 1m 24s\tremaining: 3m 27s\n",
      "145:\tlearn: 0.0022581\ttotal: 1m 25s\tremaining: 3m 27s\n",
      "146:\tlearn: 0.0022463\ttotal: 1m 26s\tremaining: 3m 28s\n",
      "147:\tlearn: 0.0022359\ttotal: 1m 27s\tremaining: 3m 28s\n",
      "148:\tlearn: 0.0022259\ttotal: 1m 28s\tremaining: 3m 29s\n",
      "149:\tlearn: 0.0022158\ttotal: 1m 29s\tremaining: 3m 29s\n",
      "150:\tlearn: 0.0022065\ttotal: 1m 30s\tremaining: 3m 29s\n",
      "151:\tlearn: 0.0021980\ttotal: 1m 31s\tremaining: 3m 30s\n",
      "152:\tlearn: 0.0021901\ttotal: 1m 32s\tremaining: 3m 30s\n",
      "153:\tlearn: 0.0021806\ttotal: 1m 33s\tremaining: 3m 30s\n",
      "154:\tlearn: 0.0021734\ttotal: 1m 34s\tremaining: 3m 31s\n",
      "155:\tlearn: 0.0021666\ttotal: 1m 36s\tremaining: 3m 31s\n",
      "156:\tlearn: 0.0021600\ttotal: 1m 37s\tremaining: 3m 32s\n",
      "157:\tlearn: 0.0021544\ttotal: 1m 38s\tremaining: 3m 33s\n",
      "158:\tlearn: 0.0021489\ttotal: 1m 39s\tremaining: 3m 34s\n",
      "159:\tlearn: 0.0021431\ttotal: 1m 41s\tremaining: 3m 34s\n",
      "160:\tlearn: 0.0021381\ttotal: 1m 42s\tremaining: 3m 36s\n",
      "161:\tlearn: 0.0021318\ttotal: 1m 43s\tremaining: 3m 36s\n",
      "162:\tlearn: 0.0021270\ttotal: 1m 45s\tremaining: 3m 37s\n",
      "163:\tlearn: 0.0021207\ttotal: 1m 46s\tremaining: 3m 38s\n",
      "164:\tlearn: 0.0021152\ttotal: 1m 47s\tremaining: 3m 38s\n",
      "165:\tlearn: 0.0021114\ttotal: 1m 49s\tremaining: 3m 39s\n",
      "166:\tlearn: 0.0021072\ttotal: 1m 50s\tremaining: 3m 40s\n",
      "167:\tlearn: 0.0021025\ttotal: 1m 51s\tremaining: 3m 40s\n",
      "168:\tlearn: 0.0020973\ttotal: 1m 52s\tremaining: 3m 41s\n",
      "169:\tlearn: 0.0020944\ttotal: 1m 54s\tremaining: 3m 41s\n",
      "170:\tlearn: 0.0020918\ttotal: 1m 55s\tremaining: 3m 42s\n",
      "171:\tlearn: 0.0020892\ttotal: 1m 56s\tremaining: 3m 42s\n",
      "172:\tlearn: 0.0020861\ttotal: 1m 58s\tremaining: 3m 43s\n",
      "173:\tlearn: 0.0020826\ttotal: 1m 59s\tremaining: 3m 44s\n",
      "174:\tlearn: 0.0020798\ttotal: 2m\tremaining: 3m 44s\n",
      "175:\tlearn: 0.0020763\ttotal: 2m 2s\tremaining: 3m 45s\n",
      "176:\tlearn: 0.0020735\ttotal: 2m 3s\tremaining: 3m 45s\n",
      "177:\tlearn: 0.0020712\ttotal: 2m 4s\tremaining: 3m 45s\n",
      "178:\tlearn: 0.0020683\ttotal: 2m 6s\tremaining: 3m 46s\n",
      "179:\tlearn: 0.0020663\ttotal: 2m 7s\tremaining: 3m 46s\n",
      "180:\tlearn: 0.0020636\ttotal: 2m 8s\tremaining: 3m 47s\n",
      "181:\tlearn: 0.0020612\ttotal: 2m 10s\tremaining: 3m 47s\n",
      "182:\tlearn: 0.0020589\ttotal: 2m 11s\tremaining: 3m 47s\n",
      "183:\tlearn: 0.0020566\ttotal: 2m 12s\tremaining: 3m 48s\n",
      "184:\tlearn: 0.0020557\ttotal: 2m 14s\tremaining: 3m 48s\n",
      "185:\tlearn: 0.0020544\ttotal: 2m 15s\tremaining: 3m 48s\n",
      "186:\tlearn: 0.0020518\ttotal: 2m 17s\tremaining: 3m 49s\n",
      "187:\tlearn: 0.0020486\ttotal: 2m 18s\tremaining: 3m 49s\n",
      "188:\tlearn: 0.0020465\ttotal: 2m 19s\tremaining: 3m 50s\n",
      "189:\tlearn: 0.0020456\ttotal: 2m 21s\tremaining: 3m 50s\n",
      "190:\tlearn: 0.0020419\ttotal: 2m 22s\tremaining: 3m 50s\n",
      "191:\tlearn: 0.0020404\ttotal: 2m 23s\tremaining: 3m 50s\n",
      "192:\tlearn: 0.0020378\ttotal: 2m 25s\tremaining: 3m 50s\n",
      "193:\tlearn: 0.0020360\ttotal: 2m 26s\tremaining: 3m 50s\n",
      "194:\tlearn: 0.0020344\ttotal: 2m 27s\tremaining: 3m 51s\n",
      "195:\tlearn: 0.0020337\ttotal: 2m 29s\tremaining: 3m 51s\n",
      "196:\tlearn: 0.0020327\ttotal: 2m 30s\tremaining: 3m 51s\n",
      "197:\tlearn: 0.0020317\ttotal: 2m 31s\tremaining: 3m 51s\n",
      "198:\tlearn: 0.0020295\ttotal: 2m 33s\tremaining: 3m 51s\n",
      "199:\tlearn: 0.0020281\ttotal: 2m 34s\tremaining: 3m 51s\n",
      "200:\tlearn: 0.0020260\ttotal: 2m 35s\tremaining: 3m 52s\n",
      "201:\tlearn: 0.0020240\ttotal: 2m 37s\tremaining: 3m 51s\n",
      "202:\tlearn: 0.0020225\ttotal: 2m 38s\tremaining: 3m 52s\n",
      "203:\tlearn: 0.0020211\ttotal: 2m 39s\tremaining: 3m 52s\n",
      "204:\tlearn: 0.0020198\ttotal: 2m 41s\tremaining: 3m 52s\n",
      "205:\tlearn: 0.0020186\ttotal: 2m 42s\tremaining: 3m 52s\n",
      "206:\tlearn: 0.0020147\ttotal: 2m 43s\tremaining: 3m 51s\n",
      "207:\tlearn: 0.0020135\ttotal: 2m 45s\tremaining: 3m 52s\n",
      "208:\tlearn: 0.0020129\ttotal: 2m 46s\tremaining: 3m 52s\n",
      "209:\tlearn: 0.0020099\ttotal: 2m 48s\tremaining: 3m 52s\n",
      "210:\tlearn: 0.0020090\ttotal: 2m 49s\tremaining: 3m 52s\n",
      "211:\tlearn: 0.0020069\ttotal: 2m 51s\tremaining: 3m 52s\n",
      "212:\tlearn: 0.0020050\ttotal: 2m 52s\tremaining: 3m 52s\n",
      "213:\tlearn: 0.0020032\ttotal: 2m 53s\tremaining: 3m 51s\n",
      "214:\tlearn: 0.0020019\ttotal: 2m 54s\tremaining: 3m 51s\n",
      "215:\tlearn: 0.0020014\ttotal: 2m 56s\tremaining: 3m 51s\n",
      "216:\tlearn: 0.0019979\ttotal: 2m 57s\tremaining: 3m 51s\n",
      "217:\tlearn: 0.0019966\ttotal: 2m 59s\tremaining: 3m 51s\n",
      "218:\tlearn: 0.0019960\ttotal: 3m\tremaining: 3m 51s\n",
      "219:\tlearn: 0.0019955\ttotal: 3m 2s\tremaining: 3m 51s\n",
      "220:\tlearn: 0.0019943\ttotal: 3m 3s\tremaining: 3m 51s\n",
      "221:\tlearn: 0.0019934\ttotal: 3m 4s\tremaining: 3m 51s\n",
      "222:\tlearn: 0.0019915\ttotal: 3m 6s\tremaining: 3m 51s\n",
      "223:\tlearn: 0.0019903\ttotal: 3m 7s\tremaining: 3m 51s\n",
      "224:\tlearn: 0.0019893\ttotal: 3m 9s\tremaining: 3m 51s\n",
      "225:\tlearn: 0.0019883\ttotal: 3m 10s\tremaining: 3m 50s\n",
      "226:\tlearn: 0.0019873\ttotal: 3m 11s\tremaining: 3m 50s\n",
      "227:\tlearn: 0.0019858\ttotal: 3m 13s\tremaining: 3m 50s\n",
      "228:\tlearn: 0.0019844\ttotal: 3m 14s\tremaining: 3m 50s\n",
      "229:\tlearn: 0.0019824\ttotal: 3m 16s\tremaining: 3m 50s\n",
      "230:\tlearn: 0.0019798\ttotal: 3m 17s\tremaining: 3m 49s\n",
      "231:\tlearn: 0.0019787\ttotal: 3m 18s\tremaining: 3m 49s\n",
      "232:\tlearn: 0.0019780\ttotal: 3m 20s\tremaining: 3m 49s\n",
      "233:\tlearn: 0.0019771\ttotal: 3m 21s\tremaining: 3m 49s\n",
      "234:\tlearn: 0.0019749\ttotal: 3m 23s\tremaining: 3m 49s\n",
      "235:\tlearn: 0.0019735\ttotal: 3m 24s\tremaining: 3m 48s\n",
      "236:\tlearn: 0.0019729\ttotal: 3m 25s\tremaining: 3m 48s\n",
      "237:\tlearn: 0.0019712\ttotal: 3m 27s\tremaining: 3m 48s\n",
      "238:\tlearn: 0.0019702\ttotal: 3m 28s\tremaining: 3m 47s\n",
      "239:\tlearn: 0.0019694\ttotal: 3m 30s\tremaining: 3m 47s\n",
      "240:\tlearn: 0.0019684\ttotal: 3m 31s\tremaining: 3m 47s\n",
      "241:\tlearn: 0.0019676\ttotal: 3m 32s\tremaining: 3m 46s\n",
      "242:\tlearn: 0.0019672\ttotal: 3m 34s\tremaining: 3m 46s\n",
      "243:\tlearn: 0.0019663\ttotal: 3m 35s\tremaining: 3m 46s\n",
      "244:\tlearn: 0.0019653\ttotal: 3m 36s\tremaining: 3m 45s\n",
      "245:\tlearn: 0.0019643\ttotal: 3m 38s\tremaining: 3m 45s\n",
      "246:\tlearn: 0.0019616\ttotal: 3m 39s\tremaining: 3m 44s\n",
      "247:\tlearn: 0.0019609\ttotal: 3m 40s\tremaining: 3m 44s\n",
      "248:\tlearn: 0.0019603\ttotal: 3m 42s\tremaining: 3m 44s\n",
      "249:\tlearn: 0.0019590\ttotal: 3m 43s\tremaining: 3m 43s\n",
      "250:\tlearn: 0.0019580\ttotal: 3m 44s\tremaining: 3m 43s\n",
      "251:\tlearn: 0.0019574\ttotal: 3m 46s\tremaining: 3m 42s\n",
      "252:\tlearn: 0.0019567\ttotal: 3m 47s\tremaining: 3m 42s\n",
      "253:\tlearn: 0.0019559\ttotal: 3m 49s\tremaining: 3m 41s\n",
      "254:\tlearn: 0.0019546\ttotal: 3m 50s\tremaining: 3m 41s\n",
      "255:\tlearn: 0.0019536\ttotal: 3m 51s\tremaining: 3m 41s\n",
      "256:\tlearn: 0.0019529\ttotal: 3m 53s\tremaining: 3m 40s\n",
      "257:\tlearn: 0.0019520\ttotal: 3m 54s\tremaining: 3m 40s\n",
      "258:\tlearn: 0.0019504\ttotal: 3m 56s\tremaining: 3m 39s\n",
      "259:\tlearn: 0.0019480\ttotal: 3m 57s\tremaining: 3m 39s\n",
      "260:\tlearn: 0.0019477\ttotal: 3m 59s\tremaining: 3m 38s\n",
      "261:\tlearn: 0.0019469\ttotal: 4m\tremaining: 3m 38s\n",
      "262:\tlearn: 0.0019464\ttotal: 4m 1s\tremaining: 3m 37s\n",
      "263:\tlearn: 0.0019455\ttotal: 4m 3s\tremaining: 3m 37s\n",
      "264:\tlearn: 0.0019450\ttotal: 4m 4s\tremaining: 3m 36s\n",
      "265:\tlearn: 0.0019426\ttotal: 4m 5s\tremaining: 3m 36s\n",
      "266:\tlearn: 0.0019417\ttotal: 4m 7s\tremaining: 3m 35s\n",
      "267:\tlearn: 0.0019412\ttotal: 4m 8s\tremaining: 3m 35s\n",
      "268:\tlearn: 0.0019408\ttotal: 4m 10s\tremaining: 3m 34s\n",
      "269:\tlearn: 0.0019397\ttotal: 4m 11s\tremaining: 3m 34s\n",
      "270:\tlearn: 0.0019387\ttotal: 4m 12s\tremaining: 3m 33s\n",
      "271:\tlearn: 0.0019378\ttotal: 4m 14s\tremaining: 3m 32s\n",
      "272:\tlearn: 0.0019369\ttotal: 4m 15s\tremaining: 3m 32s\n",
      "273:\tlearn: 0.0019356\ttotal: 4m 16s\tremaining: 3m 31s\n",
      "274:\tlearn: 0.0019346\ttotal: 4m 18s\tremaining: 3m 31s\n",
      "275:\tlearn: 0.0019342\ttotal: 4m 19s\tremaining: 3m 30s\n",
      "276:\tlearn: 0.0019330\ttotal: 4m 20s\tremaining: 3m 30s\n",
      "277:\tlearn: 0.0019323\ttotal: 4m 22s\tremaining: 3m 29s\n",
      "278:\tlearn: 0.0019314\ttotal: 4m 23s\tremaining: 3m 28s\n",
      "279:\tlearn: 0.0019306\ttotal: 4m 25s\tremaining: 3m 28s\n",
      "280:\tlearn: 0.0019297\ttotal: 4m 26s\tremaining: 3m 27s\n",
      "281:\tlearn: 0.0019285\ttotal: 4m 27s\tremaining: 3m 27s\n",
      "282:\tlearn: 0.0019284\ttotal: 4m 28s\tremaining: 3m 25s\n",
      "283:\tlearn: 0.0019278\ttotal: 4m 30s\tremaining: 3m 25s\n",
      "284:\tlearn: 0.0019271\ttotal: 4m 31s\tremaining: 3m 24s\n",
      "285:\tlearn: 0.0019263\ttotal: 4m 32s\tremaining: 3m 24s\n",
      "286:\tlearn: 0.0019236\ttotal: 4m 34s\tremaining: 3m 23s\n",
      "287:\tlearn: 0.0019233\ttotal: 4m 35s\tremaining: 3m 22s\n",
      "288:\tlearn: 0.0019229\ttotal: 4m 37s\tremaining: 3m 22s\n",
      "289:\tlearn: 0.0019225\ttotal: 4m 38s\tremaining: 3m 21s\n",
      "290:\tlearn: 0.0019201\ttotal: 4m 39s\tremaining: 3m 21s\n",
      "291:\tlearn: 0.0019189\ttotal: 4m 41s\tremaining: 3m 20s\n",
      "292:\tlearn: 0.0019175\ttotal: 4m 42s\tremaining: 3m 19s\n",
      "293:\tlearn: 0.0019171\ttotal: 4m 44s\tremaining: 3m 19s\n",
      "294:\tlearn: 0.0019159\ttotal: 4m 45s\tremaining: 3m 18s\n",
      "295:\tlearn: 0.0019157\ttotal: 4m 47s\tremaining: 3m 18s\n",
      "296:\tlearn: 0.0019151\ttotal: 4m 48s\tremaining: 3m 17s\n",
      "297:\tlearn: 0.0019128\ttotal: 4m 50s\tremaining: 3m 16s\n",
      "298:\tlearn: 0.0019118\ttotal: 4m 51s\tremaining: 3m 15s\n",
      "299:\tlearn: 0.0019093\ttotal: 4m 52s\tremaining: 3m 15s\n",
      "300:\tlearn: 0.0019087\ttotal: 4m 54s\tremaining: 3m 14s\n",
      "301:\tlearn: 0.0019083\ttotal: 4m 55s\tremaining: 3m 13s\n",
      "302:\tlearn: 0.0019078\ttotal: 4m 57s\tremaining: 3m 13s\n",
      "303:\tlearn: 0.0019075\ttotal: 4m 58s\tremaining: 3m 12s\n",
      "304:\tlearn: 0.0019068\ttotal: 4m 59s\tremaining: 3m 11s\n",
      "305:\tlearn: 0.0019057\ttotal: 5m 1s\tremaining: 3m 11s\n",
      "306:\tlearn: 0.0019050\ttotal: 5m 2s\tremaining: 3m 10s\n",
      "307:\tlearn: 0.0019040\ttotal: 5m 4s\tremaining: 3m 9s\n",
      "308:\tlearn: 0.0019035\ttotal: 5m 5s\tremaining: 3m 8s\n",
      "309:\tlearn: 0.0019029\ttotal: 5m 7s\tremaining: 3m 8s\n",
      "310:\tlearn: 0.0019024\ttotal: 5m 8s\tremaining: 3m 7s\n",
      "311:\tlearn: 0.0019015\ttotal: 5m 9s\tremaining: 3m 6s\n",
      "312:\tlearn: 0.0019009\ttotal: 5m 11s\tremaining: 3m 6s\n",
      "313:\tlearn: 0.0019003\ttotal: 5m 12s\tremaining: 3m 5s\n",
      "314:\tlearn: 0.0018999\ttotal: 5m 14s\tremaining: 3m 4s\n",
      "315:\tlearn: 0.0018989\ttotal: 5m 15s\tremaining: 3m 3s\n",
      "316:\tlearn: 0.0018987\ttotal: 5m 17s\tremaining: 3m 3s\n",
      "317:\tlearn: 0.0018982\ttotal: 5m 18s\tremaining: 3m 2s\n",
      "318:\tlearn: 0.0018975\ttotal: 5m 20s\tremaining: 3m 1s\n",
      "319:\tlearn: 0.0018952\ttotal: 5m 21s\tremaining: 3m\n",
      "320:\tlearn: 0.0018949\ttotal: 5m 22s\tremaining: 3m\n",
      "321:\tlearn: 0.0018945\ttotal: 5m 24s\tremaining: 2m 59s\n",
      "322:\tlearn: 0.0018939\ttotal: 5m 25s\tremaining: 2m 58s\n",
      "323:\tlearn: 0.0018934\ttotal: 5m 26s\tremaining: 2m 57s\n",
      "324:\tlearn: 0.0018923\ttotal: 5m 28s\tremaining: 2m 56s\n",
      "325:\tlearn: 0.0018913\ttotal: 5m 29s\tremaining: 2m 55s\n",
      "326:\tlearn: 0.0018908\ttotal: 5m 31s\tremaining: 2m 55s\n",
      "327:\tlearn: 0.0018898\ttotal: 5m 32s\tremaining: 2m 54s\n",
      "328:\tlearn: 0.0018889\ttotal: 5m 33s\tremaining: 2m 53s\n",
      "329:\tlearn: 0.0018884\ttotal: 5m 35s\tremaining: 2m 52s\n",
      "330:\tlearn: 0.0018871\ttotal: 5m 36s\tremaining: 2m 51s\n",
      "331:\tlearn: 0.0018847\ttotal: 5m 37s\tremaining: 2m 50s\n",
      "332:\tlearn: 0.0018838\ttotal: 5m 39s\tremaining: 2m 50s\n",
      "333:\tlearn: 0.0018815\ttotal: 5m 40s\tremaining: 2m 49s\n",
      "334:\tlearn: 0.0018807\ttotal: 5m 41s\tremaining: 2m 48s\n",
      "335:\tlearn: 0.0018801\ttotal: 5m 43s\tremaining: 2m 47s\n",
      "336:\tlearn: 0.0018800\ttotal: 5m 43s\tremaining: 2m 46s\n",
      "337:\tlearn: 0.0018784\ttotal: 5m 44s\tremaining: 2m 45s\n",
      "338:\tlearn: 0.0018780\ttotal: 5m 46s\tremaining: 2m 44s\n",
      "339:\tlearn: 0.0018778\ttotal: 5m 47s\tremaining: 2m 43s\n",
      "340:\tlearn: 0.0018773\ttotal: 5m 48s\tremaining: 2m 42s\n",
      "341:\tlearn: 0.0018749\ttotal: 5m 49s\tremaining: 2m 41s\n",
      "342:\tlearn: 0.0018739\ttotal: 5m 50s\tremaining: 2m 40s\n",
      "343:\tlearn: 0.0018735\ttotal: 5m 51s\tremaining: 2m 39s\n",
      "344:\tlearn: 0.0018732\ttotal: 5m 52s\tremaining: 2m 38s\n",
      "345:\tlearn: 0.0018721\ttotal: 5m 53s\tremaining: 2m 37s\n",
      "346:\tlearn: 0.0018713\ttotal: 5m 55s\tremaining: 2m 36s\n",
      "347:\tlearn: 0.0018697\ttotal: 5m 56s\tremaining: 2m 35s\n",
      "348:\tlearn: 0.0018690\ttotal: 5m 57s\tremaining: 2m 34s\n",
      "349:\tlearn: 0.0018680\ttotal: 5m 58s\tremaining: 2m 33s\n",
      "350:\tlearn: 0.0018675\ttotal: 5m 59s\tremaining: 2m 32s\n",
      "351:\tlearn: 0.0018670\ttotal: 6m 1s\tremaining: 2m 31s\n",
      "352:\tlearn: 0.0018664\ttotal: 6m 2s\tremaining: 2m 30s\n",
      "353:\tlearn: 0.0018659\ttotal: 6m 3s\tremaining: 2m 29s\n",
      "354:\tlearn: 0.0018647\ttotal: 6m 4s\tremaining: 2m 28s\n",
      "355:\tlearn: 0.0018638\ttotal: 6m 5s\tremaining: 2m 28s\n",
      "356:\tlearn: 0.0018636\ttotal: 6m 7s\tremaining: 2m 27s\n",
      "357:\tlearn: 0.0018628\ttotal: 6m 8s\tremaining: 2m 26s\n",
      "358:\tlearn: 0.0018616\ttotal: 6m 9s\tremaining: 2m 25s\n",
      "359:\tlearn: 0.0018613\ttotal: 6m 10s\tremaining: 2m 24s\n",
      "360:\tlearn: 0.0018605\ttotal: 6m 11s\tremaining: 2m 23s\n",
      "361:\tlearn: 0.0018597\ttotal: 6m 12s\tremaining: 2m 22s\n",
      "362:\tlearn: 0.0018593\ttotal: 6m 14s\tremaining: 2m 21s\n",
      "363:\tlearn: 0.0018591\ttotal: 6m 15s\tremaining: 2m 20s\n",
      "364:\tlearn: 0.0018577\ttotal: 6m 16s\tremaining: 2m 19s\n",
      "365:\tlearn: 0.0018565\ttotal: 6m 17s\tremaining: 2m 18s\n",
      "366:\tlearn: 0.0018555\ttotal: 6m 18s\tremaining: 2m 17s\n",
      "367:\tlearn: 0.0018542\ttotal: 6m 19s\tremaining: 2m 16s\n",
      "368:\tlearn: 0.0018536\ttotal: 6m 21s\tremaining: 2m 15s\n",
      "369:\tlearn: 0.0018523\ttotal: 6m 22s\tremaining: 2m 14s\n",
      "370:\tlearn: 0.0018515\ttotal: 6m 23s\tremaining: 2m 13s\n",
      "371:\tlearn: 0.0018510\ttotal: 6m 24s\tremaining: 2m 12s\n",
      "372:\tlearn: 0.0018496\ttotal: 6m 25s\tremaining: 2m 11s\n",
      "373:\tlearn: 0.0018494\ttotal: 6m 27s\tremaining: 2m 10s\n",
      "374:\tlearn: 0.0018491\ttotal: 6m 28s\tremaining: 2m 9s\n",
      "375:\tlearn: 0.0018491\ttotal: 6m 28s\tremaining: 2m 8s\n",
      "376:\tlearn: 0.0018485\ttotal: 6m 29s\tremaining: 2m 7s\n",
      "377:\tlearn: 0.0018473\ttotal: 6m 30s\tremaining: 2m 6s\n",
      "378:\tlearn: 0.0018467\ttotal: 6m 31s\tremaining: 2m 5s\n",
      "379:\tlearn: 0.0018459\ttotal: 6m 32s\tremaining: 2m 4s\n",
      "380:\tlearn: 0.0018459\ttotal: 6m 34s\tremaining: 2m 3s\n",
      "381:\tlearn: 0.0018451\ttotal: 6m 35s\tremaining: 2m 2s\n",
      "382:\tlearn: 0.0018443\ttotal: 6m 36s\tremaining: 2m 1s\n",
      "383:\tlearn: 0.0018436\ttotal: 6m 37s\tremaining: 1m 59s\n",
      "384:\tlearn: 0.0018429\ttotal: 6m 38s\tremaining: 1m 58s\n",
      "385:\tlearn: 0.0018427\ttotal: 6m 39s\tremaining: 1m 57s\n",
      "386:\tlearn: 0.0018419\ttotal: 6m 40s\tremaining: 1m 56s\n",
      "387:\tlearn: 0.0018407\ttotal: 6m 41s\tremaining: 1m 55s\n",
      "388:\tlearn: 0.0018399\ttotal: 6m 42s\tremaining: 1m 54s\n",
      "389:\tlearn: 0.0018389\ttotal: 6m 43s\tremaining: 1m 53s\n",
      "390:\tlearn: 0.0018381\ttotal: 6m 45s\tremaining: 1m 52s\n",
      "391:\tlearn: 0.0018363\ttotal: 6m 46s\tremaining: 1m 51s\n",
      "392:\tlearn: 0.0018351\ttotal: 6m 47s\tremaining: 1m 51s\n",
      "393:\tlearn: 0.0018346\ttotal: 6m 49s\tremaining: 1m 50s\n",
      "394:\tlearn: 0.0018335\ttotal: 6m 50s\tremaining: 1m 49s\n",
      "395:\tlearn: 0.0018329\ttotal: 6m 52s\tremaining: 1m 48s\n",
      "396:\tlearn: 0.0018318\ttotal: 6m 54s\tremaining: 1m 47s\n",
      "397:\tlearn: 0.0018304\ttotal: 6m 55s\tremaining: 1m 46s\n",
      "398:\tlearn: 0.0018296\ttotal: 6m 57s\tremaining: 1m 45s\n",
      "399:\tlearn: 0.0018287\ttotal: 6m 59s\tremaining: 1m 44s\n",
      "400:\tlearn: 0.0018275\ttotal: 7m\tremaining: 1m 43s\n",
      "401:\tlearn: 0.0018272\ttotal: 7m 2s\tremaining: 1m 42s\n",
      "402:\tlearn: 0.0018265\ttotal: 7m 3s\tremaining: 1m 42s\n",
      "403:\tlearn: 0.0018260\ttotal: 7m 5s\tremaining: 1m 41s\n",
      "404:\tlearn: 0.0018253\ttotal: 7m 6s\tremaining: 1m 40s\n",
      "405:\tlearn: 0.0018248\ttotal: 7m 8s\tremaining: 1m 39s\n",
      "406:\tlearn: 0.0018242\ttotal: 7m 9s\tremaining: 1m 38s\n",
      "407:\tlearn: 0.0018233\ttotal: 7m 11s\tremaining: 1m 37s\n",
      "408:\tlearn: 0.0018229\ttotal: 7m 12s\tremaining: 1m 36s\n",
      "409:\tlearn: 0.0018220\ttotal: 7m 14s\tremaining: 1m 35s\n",
      "410:\tlearn: 0.0018213\ttotal: 7m 15s\tremaining: 1m 34s\n",
      "411:\tlearn: 0.0018209\ttotal: 7m 17s\tremaining: 1m 33s\n",
      "412:\tlearn: 0.0018201\ttotal: 7m 18s\tremaining: 1m 32s\n",
      "413:\tlearn: 0.0018191\ttotal: 7m 20s\tremaining: 1m 31s\n",
      "414:\tlearn: 0.0018178\ttotal: 7m 21s\tremaining: 1m 30s\n",
      "415:\tlearn: 0.0018176\ttotal: 7m 23s\tremaining: 1m 29s\n",
      "416:\tlearn: 0.0018174\ttotal: 7m 24s\tremaining: 1m 28s\n",
      "417:\tlearn: 0.0018166\ttotal: 7m 26s\tremaining: 1m 27s\n",
      "418:\tlearn: 0.0018158\ttotal: 7m 27s\tremaining: 1m 26s\n",
      "419:\tlearn: 0.0018157\ttotal: 7m 29s\tremaining: 1m 25s\n",
      "420:\tlearn: 0.0018153\ttotal: 7m 30s\tremaining: 1m 24s\n",
      "421:\tlearn: 0.0018151\ttotal: 7m 31s\tremaining: 1m 23s\n",
      "422:\tlearn: 0.0018138\ttotal: 7m 33s\tremaining: 1m 22s\n",
      "423:\tlearn: 0.0018131\ttotal: 7m 35s\tremaining: 1m 21s\n",
      "424:\tlearn: 0.0018125\ttotal: 7m 36s\tremaining: 1m 20s\n",
      "425:\tlearn: 0.0018123\ttotal: 7m 37s\tremaining: 1m 19s\n",
      "426:\tlearn: 0.0018116\ttotal: 7m 39s\tremaining: 1m 18s\n",
      "427:\tlearn: 0.0018107\ttotal: 7m 40s\tremaining: 1m 17s\n",
      "428:\tlearn: 0.0018102\ttotal: 7m 42s\tremaining: 1m 16s\n",
      "429:\tlearn: 0.0018095\ttotal: 7m 43s\tremaining: 1m 15s\n",
      "430:\tlearn: 0.0018087\ttotal: 7m 45s\tremaining: 1m 14s\n",
      "431:\tlearn: 0.0018077\ttotal: 7m 46s\tremaining: 1m 13s\n",
      "432:\tlearn: 0.0018072\ttotal: 7m 48s\tremaining: 1m 12s\n",
      "433:\tlearn: 0.0018072\ttotal: 7m 49s\tremaining: 1m 11s\n",
      "434:\tlearn: 0.0018068\ttotal: 7m 51s\tremaining: 1m 10s\n",
      "435:\tlearn: 0.0018062\ttotal: 7m 52s\tremaining: 1m 9s\n",
      "436:\tlearn: 0.0018054\ttotal: 7m 54s\tremaining: 1m 8s\n",
      "437:\tlearn: 0.0018048\ttotal: 7m 55s\tremaining: 1m 7s\n",
      "438:\tlearn: 0.0018044\ttotal: 7m 57s\tremaining: 1m 6s\n",
      "439:\tlearn: 0.0018037\ttotal: 7m 58s\tremaining: 1m 5s\n",
      "440:\tlearn: 0.0018029\ttotal: 8m\tremaining: 1m 4s\n",
      "441:\tlearn: 0.0018018\ttotal: 8m 1s\tremaining: 1m 3s\n",
      "442:\tlearn: 0.0018010\ttotal: 8m 3s\tremaining: 1m 2s\n",
      "443:\tlearn: 0.0018004\ttotal: 8m 4s\tremaining: 1m 1s\n",
      "444:\tlearn: 0.0018000\ttotal: 8m 6s\tremaining: 1m\n",
      "445:\tlearn: 0.0017988\ttotal: 8m 7s\tremaining: 59.1s\n",
      "446:\tlearn: 0.0017984\ttotal: 8m 9s\tremaining: 58s\n",
      "447:\tlearn: 0.0017970\ttotal: 8m 10s\tremaining: 56.9s\n",
      "448:\tlearn: 0.0017964\ttotal: 8m 12s\tremaining: 55.9s\n",
      "449:\tlearn: 0.0017961\ttotal: 8m 13s\tremaining: 54.9s\n",
      "450:\tlearn: 0.0017946\ttotal: 8m 15s\tremaining: 53.8s\n",
      "451:\tlearn: 0.0017942\ttotal: 8m 16s\tremaining: 52.7s\n",
      "452:\tlearn: 0.0017937\ttotal: 8m 18s\tremaining: 51.7s\n",
      "453:\tlearn: 0.0017934\ttotal: 8m 19s\tremaining: 50.6s\n",
      "454:\tlearn: 0.0017914\ttotal: 8m 21s\tremaining: 49.6s\n",
      "455:\tlearn: 0.0017901\ttotal: 8m 22s\tremaining: 48.5s\n",
      "456:\tlearn: 0.0017891\ttotal: 8m 24s\tremaining: 47.4s\n",
      "457:\tlearn: 0.0017887\ttotal: 8m 25s\tremaining: 46.4s\n",
      "458:\tlearn: 0.0017881\ttotal: 8m 27s\tremaining: 45.3s\n",
      "459:\tlearn: 0.0017877\ttotal: 8m 28s\tremaining: 44.2s\n",
      "460:\tlearn: 0.0017877\ttotal: 8m 30s\tremaining: 43.2s\n",
      "461:\tlearn: 0.0017874\ttotal: 8m 31s\tremaining: 42.1s\n",
      "462:\tlearn: 0.0017856\ttotal: 8m 33s\tremaining: 41s\n",
      "463:\tlearn: 0.0017854\ttotal: 8m 34s\tremaining: 39.9s\n",
      "464:\tlearn: 0.0017844\ttotal: 8m 36s\tremaining: 38.9s\n",
      "465:\tlearn: 0.0017840\ttotal: 8m 37s\tremaining: 37.8s\n",
      "466:\tlearn: 0.0017835\ttotal: 8m 39s\tremaining: 36.7s\n",
      "467:\tlearn: 0.0017833\ttotal: 8m 41s\tremaining: 35.6s\n",
      "468:\tlearn: 0.0017832\ttotal: 8m 42s\tremaining: 34.5s\n",
      "469:\tlearn: 0.0017817\ttotal: 8m 44s\tremaining: 33.5s\n",
      "470:\tlearn: 0.0017816\ttotal: 8m 45s\tremaining: 32.4s\n",
      "471:\tlearn: 0.0017799\ttotal: 8m 46s\tremaining: 31.3s\n",
      "472:\tlearn: 0.0017795\ttotal: 8m 48s\tremaining: 30.1s\n",
      "473:\tlearn: 0.0017786\ttotal: 8m 49s\tremaining: 29s\n",
      "474:\tlearn: 0.0017774\ttotal: 8m 50s\tremaining: 27.9s\n",
      "475:\tlearn: 0.0017761\ttotal: 8m 51s\tremaining: 26.8s\n",
      "476:\tlearn: 0.0017757\ttotal: 8m 52s\tremaining: 25.7s\n",
      "477:\tlearn: 0.0017755\ttotal: 8m 54s\tremaining: 24.6s\n",
      "478:\tlearn: 0.0017742\ttotal: 8m 55s\tremaining: 23.5s\n",
      "479:\tlearn: 0.0017724\ttotal: 8m 56s\tremaining: 22.4s\n",
      "480:\tlearn: 0.0017723\ttotal: 8m 57s\tremaining: 21.2s\n",
      "481:\tlearn: 0.0017716\ttotal: 8m 58s\tremaining: 20.1s\n",
      "482:\tlearn: 0.0017698\ttotal: 9m\tremaining: 19s\n",
      "483:\tlearn: 0.0017687\ttotal: 9m 1s\tremaining: 17.9s\n",
      "484:\tlearn: 0.0017678\ttotal: 9m 2s\tremaining: 16.8s\n",
      "485:\tlearn: 0.0017675\ttotal: 9m 3s\tremaining: 15.7s\n",
      "486:\tlearn: 0.0017662\ttotal: 9m 5s\tremaining: 14.5s\n",
      "487:\tlearn: 0.0017657\ttotal: 9m 6s\tremaining: 13.4s\n",
      "488:\tlearn: 0.0017651\ttotal: 9m 7s\tremaining: 12.3s\n",
      "489:\tlearn: 0.0017637\ttotal: 9m 8s\tremaining: 11.2s\n",
      "490:\tlearn: 0.0017625\ttotal: 9m 9s\tremaining: 10.1s\n",
      "491:\tlearn: 0.0017613\ttotal: 9m 11s\tremaining: 8.96s\n",
      "492:\tlearn: 0.0017604\ttotal: 9m 12s\tremaining: 7.84s\n",
      "493:\tlearn: 0.0017594\ttotal: 9m 13s\tremaining: 6.72s\n",
      "494:\tlearn: 0.0017588\ttotal: 9m 14s\tremaining: 5.6s\n",
      "495:\tlearn: 0.0017584\ttotal: 9m 16s\tremaining: 4.49s\n",
      "496:\tlearn: 0.0017572\ttotal: 9m 17s\tremaining: 3.36s\n",
      "497:\tlearn: 0.0017566\ttotal: 9m 18s\tremaining: 2.24s\n",
      "498:\tlearn: 0.0017558\ttotal: 9m 19s\tremaining: 1.12s\n",
      "499:\tlearn: 0.0017545\ttotal: 9m 21s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9997649383660427\n",
      "\n",
      "Confusion Matrix:\n",
      " [[250939      0]\n",
      " [    59      0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    250939\n",
      "           1       0.00      0.00      0.00        59\n",
      "\n",
      "    accuracy                           1.00    250998\n",
      "   macro avg       0.50      0.50      0.50    250998\n",
      "weighted avg       1.00      1.00      1.00    250998\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Fraud','FraudType'], axis=1)\n",
    "y = df['Fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a CatBoost Classifier\n",
    "model = CatBoostClassifier(iterations=500, depth=10, learning_rate=0.05, loss_function='MultiClass', random_seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, cat_features=None)  # You can specify categorical features if needed\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/part_D/partd_rus_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"Unnamed: 0.1\",\"PRSCRBR_NPI\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prscrbr_Crdntls</th>\n",
       "      <th>Prscrbr_Gndr</th>\n",
       "      <th>Prscrbr_Type</th>\n",
       "      <th>Prscrbr_Type_src</th>\n",
       "      <th>Tot_Clms</th>\n",
       "      <th>Tot_30day_Fills</th>\n",
       "      <th>Tot_Drug_Cst</th>\n",
       "      <th>Tot_Day_Suply</th>\n",
       "      <th>Tot_Benes</th>\n",
       "      <th>GE65_Sprsn_Flag</th>\n",
       "      <th>...</th>\n",
       "      <th>Bene_Race_Wht_Cnt</th>\n",
       "      <th>Bene_Race_Black_Cnt</th>\n",
       "      <th>Bene_Race_Api_Cnt</th>\n",
       "      <th>Bene_Race_Hspnc_Cnt</th>\n",
       "      <th>Bene_Race_Natind_Cnt</th>\n",
       "      <th>Bene_Race_Othr_Cnt</th>\n",
       "      <th>Bene_Dual_Cnt</th>\n",
       "      <th>Bene_Ndual_Cnt</th>\n",
       "      <th>Bene_Avg_Risk_Scre</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2929</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>1191.566667</td>\n",
       "      <td>71404.48</td>\n",
       "      <td>25695.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.488790</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131</td>\n",
       "      <td>1.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>203.400000</td>\n",
       "      <td>2945.42</td>\n",
       "      <td>1641.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.040951</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7058.0</td>\n",
       "      <td>14652.966667</td>\n",
       "      <td>841439.84</td>\n",
       "      <td>428631.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>338.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>1.375367</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>4984.06</td>\n",
       "      <td>4018.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.393905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1060</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2551.76</td>\n",
       "      <td>2813.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.222294</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>7632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>423.600000</td>\n",
       "      <td>66723.17</td>\n",
       "      <td>12370.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.249708</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>5885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>1618.800000</td>\n",
       "      <td>56694.66</td>\n",
       "      <td>45859.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.956362</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>7632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>2311.366667</td>\n",
       "      <td>100240.86</td>\n",
       "      <td>67529.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.233241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>9176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2132.0</td>\n",
       "      <td>2296.933333</td>\n",
       "      <td>1444745.29</td>\n",
       "      <td>64849.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.292911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>15356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>90.466667</td>\n",
       "      <td>13618.96</td>\n",
       "      <td>2704.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.545349</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>584 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prscrbr_Crdntls  Prscrbr_Gndr  Prscrbr_Type  Prscrbr_Type_src  Tot_Clms  \\\n",
       "0               2929           1.0           120               1.0    1132.0   \n",
       "1               4394           0.0           131               1.0     201.0   \n",
       "2               5885           0.0            86               1.0    7058.0   \n",
       "3               9176           0.0            64               1.0     186.0   \n",
       "4               1060           1.0           120               1.0      54.0   \n",
       "..               ...           ...           ...               ...       ...   \n",
       "579             7632           0.0            63               1.0     263.0   \n",
       "580             5885           0.0            60               1.0     813.0   \n",
       "581             7632           0.0            63               0.0    1040.0   \n",
       "582             9176           0.0            86               1.0    2132.0   \n",
       "583            15356           0.0           120               1.0      47.0   \n",
       "\n",
       "     Tot_30day_Fills  Tot_Drug_Cst  Tot_Day_Suply  Tot_Benes  GE65_Sprsn_Flag  \\\n",
       "0        1191.566667      71404.48        25695.0      103.0              1.0   \n",
       "1         203.400000       2945.42         1641.0       77.0              1.0   \n",
       "2       14652.966667     841439.84       428631.0      413.0              1.0   \n",
       "3         244.000000       4984.06         4018.0      105.0              1.0   \n",
       "4          96.000000       2551.76         2813.0       17.0              1.0   \n",
       "..               ...           ...            ...        ...              ...   \n",
       "579       423.600000      66723.17        12370.0       55.0              1.0   \n",
       "580      1618.800000      56694.66        45859.0       85.0              1.0   \n",
       "581      2311.366667     100240.86        67529.0      122.0              1.0   \n",
       "582      2296.933333    1444745.29        64849.0       90.0              1.0   \n",
       "583        90.466667      13618.96         2704.0       21.0              1.0   \n",
       "\n",
       "     ...  Bene_Race_Wht_Cnt  Bene_Race_Black_Cnt  Bene_Race_Api_Cnt  \\\n",
       "0    ...               97.0                  0.0                0.0   \n",
       "1    ...               69.0                 20.0                0.0   \n",
       "2    ...              338.0                 38.0                0.0   \n",
       "3    ...               80.0                 17.0                0.0   \n",
       "4    ...               13.0                  0.0                0.0   \n",
       "..   ...                ...                  ...                ...   \n",
       "579  ...               39.0                 38.0               35.0   \n",
       "580  ...              100.0                 23.0               27.0   \n",
       "581  ...               44.0                 30.0                0.0   \n",
       "582  ...               59.0                 11.0               15.0   \n",
       "583  ...               16.0                  0.0                0.0   \n",
       "\n",
       "     Bene_Race_Hspnc_Cnt  Bene_Race_Natind_Cnt  Bene_Race_Othr_Cnt  \\\n",
       "0                    0.0                  30.0                 0.0   \n",
       "1                    0.0                   0.0                 0.0   \n",
       "2                   28.0                   0.0                11.0   \n",
       "3                    0.0                   0.0                 0.0   \n",
       "4                    0.0                   0.0                 0.0   \n",
       "..                   ...                   ...                 ...   \n",
       "579                 14.0                   0.0                 0.0   \n",
       "580                 23.0                   0.0                14.0   \n",
       "581                105.0                   0.0                 0.0   \n",
       "582                 15.0                   0.0                14.0   \n",
       "583                  0.0                   0.0                 0.0   \n",
       "\n",
       "     Bene_Dual_Cnt  Bene_Ndual_Cnt  Bene_Avg_Risk_Scre  Fraud  \n",
       "0             37.0            66.0            1.488790      0  \n",
       "1             13.0            80.0            1.040951      0  \n",
       "2            116.0           297.0            1.375367      0  \n",
       "3             32.0            73.0            1.393905      0  \n",
       "4              0.0            17.0            1.222294      0  \n",
       "..             ...             ...                 ...    ...  \n",
       "579           16.0            20.0            2.249708      1  \n",
       "580           38.0            47.0            0.956362      1  \n",
       "581          101.0            21.0            1.233241      1  \n",
       "582           49.0            41.0            1.292911      1  \n",
       "583           13.0            13.0            1.545349      1  \n",
       "\n",
       "[584 rows x 71 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6869508\ttotal: 116ms\tremaining: 57.9s\n",
      "1:\tlearn: 0.6786844\ttotal: 224ms\tremaining: 55.7s\n",
      "2:\tlearn: 0.6734361\ttotal: 319ms\tremaining: 52.9s\n",
      "3:\tlearn: 0.6676917\ttotal: 437ms\tremaining: 54.2s\n",
      "4:\tlearn: 0.6572535\ttotal: 549ms\tremaining: 54.4s\n",
      "5:\tlearn: 0.6497610\ttotal: 665ms\tremaining: 54.7s\n",
      "6:\tlearn: 0.6423041\ttotal: 770ms\tremaining: 54.2s\n",
      "7:\tlearn: 0.6358433\ttotal: 898ms\tremaining: 55.2s\n",
      "8:\tlearn: 0.6298912\ttotal: 1.02s\tremaining: 55.8s\n",
      "9:\tlearn: 0.6228520\ttotal: 1.15s\tremaining: 56.4s\n",
      "10:\tlearn: 0.6180515\ttotal: 1.22s\tremaining: 54.2s\n",
      "11:\tlearn: 0.6115049\ttotal: 1.34s\tremaining: 54.7s\n",
      "12:\tlearn: 0.6062372\ttotal: 1.44s\tremaining: 53.9s\n",
      "13:\tlearn: 0.6024180\ttotal: 1.55s\tremaining: 53.7s\n",
      "14:\tlearn: 0.5970721\ttotal: 1.65s\tremaining: 53.4s\n",
      "15:\tlearn: 0.5908110\ttotal: 1.78s\tremaining: 53.8s\n",
      "16:\tlearn: 0.5845684\ttotal: 1.9s\tremaining: 53.9s\n",
      "17:\tlearn: 0.5786400\ttotal: 1.99s\tremaining: 53.4s\n",
      "18:\tlearn: 0.5734863\ttotal: 2.08s\tremaining: 52.5s\n",
      "19:\tlearn: 0.5693084\ttotal: 2.22s\tremaining: 53.4s\n",
      "20:\tlearn: 0.5650631\ttotal: 2.36s\tremaining: 53.8s\n",
      "21:\tlearn: 0.5605009\ttotal: 2.5s\tremaining: 54.3s\n",
      "22:\tlearn: 0.5549412\ttotal: 2.63s\tremaining: 54.6s\n",
      "23:\tlearn: 0.5509267\ttotal: 2.71s\tremaining: 53.7s\n",
      "24:\tlearn: 0.5466465\ttotal: 2.84s\tremaining: 54s\n",
      "25:\tlearn: 0.5427117\ttotal: 2.94s\tremaining: 53.7s\n",
      "26:\tlearn: 0.5386930\ttotal: 3.03s\tremaining: 53.1s\n",
      "27:\tlearn: 0.5350240\ttotal: 3.13s\tremaining: 52.7s\n",
      "28:\tlearn: 0.5309252\ttotal: 3.26s\tremaining: 52.9s\n",
      "29:\tlearn: 0.5266736\ttotal: 3.36s\tremaining: 52.6s\n",
      "30:\tlearn: 0.5221949\ttotal: 3.44s\tremaining: 52s\n",
      "31:\tlearn: 0.5183344\ttotal: 3.56s\tremaining: 52.1s\n",
      "32:\tlearn: 0.5146151\ttotal: 3.67s\tremaining: 52s\n",
      "33:\tlearn: 0.5105131\ttotal: 3.82s\tremaining: 52.3s\n",
      "34:\tlearn: 0.5070962\ttotal: 3.9s\tremaining: 51.7s\n",
      "35:\tlearn: 0.5039243\ttotal: 4.02s\tremaining: 51.8s\n",
      "36:\tlearn: 0.5004423\ttotal: 4.14s\tremaining: 51.8s\n",
      "37:\tlearn: 0.4964035\ttotal: 4.24s\tremaining: 51.6s\n",
      "38:\tlearn: 0.4914996\ttotal: 4.36s\tremaining: 51.6s\n",
      "39:\tlearn: 0.4885976\ttotal: 4.46s\tremaining: 51.4s\n",
      "40:\tlearn: 0.4849261\ttotal: 4.58s\tremaining: 51.2s\n",
      "41:\tlearn: 0.4825080\ttotal: 4.7s\tremaining: 51.2s\n",
      "42:\tlearn: 0.4793533\ttotal: 4.83s\tremaining: 51.3s\n",
      "43:\tlearn: 0.4765385\ttotal: 4.93s\tremaining: 51.2s\n",
      "44:\tlearn: 0.4737701\ttotal: 5.02s\tremaining: 50.7s\n",
      "45:\tlearn: 0.4698870\ttotal: 5.15s\tremaining: 50.8s\n",
      "46:\tlearn: 0.4666604\ttotal: 5.3s\tremaining: 51.1s\n",
      "47:\tlearn: 0.4632732\ttotal: 5.39s\tremaining: 50.8s\n",
      "48:\tlearn: 0.4598862\ttotal: 5.53s\tremaining: 50.9s\n",
      "49:\tlearn: 0.4562609\ttotal: 5.66s\tremaining: 51s\n",
      "50:\tlearn: 0.4532512\ttotal: 5.74s\tremaining: 50.6s\n",
      "51:\tlearn: 0.4496692\ttotal: 5.82s\tremaining: 50.2s\n",
      "52:\tlearn: 0.4459584\ttotal: 5.97s\tremaining: 50.4s\n",
      "53:\tlearn: 0.4429814\ttotal: 6.08s\tremaining: 50.2s\n",
      "54:\tlearn: 0.4416173\ttotal: 6.21s\tremaining: 50.2s\n",
      "55:\tlearn: 0.4400092\ttotal: 6.33s\tremaining: 50.2s\n",
      "56:\tlearn: 0.4371265\ttotal: 6.45s\tremaining: 50.1s\n",
      "57:\tlearn: 0.4339160\ttotal: 6.52s\tremaining: 49.7s\n",
      "58:\tlearn: 0.4316195\ttotal: 6.67s\tremaining: 49.9s\n",
      "59:\tlearn: 0.4287346\ttotal: 6.77s\tremaining: 49.7s\n",
      "60:\tlearn: 0.4262075\ttotal: 6.94s\tremaining: 50s\n",
      "61:\tlearn: 0.4232046\ttotal: 7.03s\tremaining: 49.7s\n",
      "62:\tlearn: 0.4199637\ttotal: 7.15s\tremaining: 49.6s\n",
      "63:\tlearn: 0.4183486\ttotal: 7.24s\tremaining: 49.3s\n",
      "64:\tlearn: 0.4160407\ttotal: 7.32s\tremaining: 49s\n",
      "65:\tlearn: 0.4138939\ttotal: 7.45s\tremaining: 49s\n",
      "66:\tlearn: 0.4115525\ttotal: 7.58s\tremaining: 49s\n",
      "67:\tlearn: 0.4097907\ttotal: 7.71s\tremaining: 49s\n",
      "68:\tlearn: 0.4070489\ttotal: 7.82s\tremaining: 48.8s\n",
      "69:\tlearn: 0.4044933\ttotal: 7.95s\tremaining: 48.8s\n",
      "70:\tlearn: 0.4031549\ttotal: 8.05s\tremaining: 48.6s\n",
      "71:\tlearn: 0.4013273\ttotal: 8.16s\tremaining: 48.5s\n",
      "72:\tlearn: 0.3984672\ttotal: 8.27s\tremaining: 48.4s\n",
      "73:\tlearn: 0.3961822\ttotal: 8.4s\tremaining: 48.3s\n",
      "74:\tlearn: 0.3938335\ttotal: 8.49s\tremaining: 48.1s\n",
      "75:\tlearn: 0.3910633\ttotal: 8.6s\tremaining: 48s\n",
      "76:\tlearn: 0.3898880\ttotal: 8.72s\tremaining: 47.9s\n",
      "77:\tlearn: 0.3879358\ttotal: 8.82s\tremaining: 47.7s\n",
      "78:\tlearn: 0.3859073\ttotal: 8.92s\tremaining: 47.6s\n",
      "79:\tlearn: 0.3833648\ttotal: 9.03s\tremaining: 47.4s\n",
      "80:\tlearn: 0.3808535\ttotal: 9.15s\tremaining: 47.3s\n",
      "81:\tlearn: 0.3786473\ttotal: 9.27s\tremaining: 47.2s\n",
      "82:\tlearn: 0.3760004\ttotal: 9.39s\tremaining: 47.2s\n",
      "83:\tlearn: 0.3744466\ttotal: 9.53s\tremaining: 47.2s\n",
      "84:\tlearn: 0.3725185\ttotal: 9.62s\tremaining: 47s\n",
      "85:\tlearn: 0.3700989\ttotal: 9.76s\tremaining: 47s\n",
      "86:\tlearn: 0.3686170\ttotal: 9.85s\tremaining: 46.7s\n",
      "87:\tlearn: 0.3664086\ttotal: 9.96s\tremaining: 46.7s\n",
      "88:\tlearn: 0.3641931\ttotal: 10.1s\tremaining: 46.6s\n",
      "89:\tlearn: 0.3621017\ttotal: 10.2s\tremaining: 46.5s\n",
      "90:\tlearn: 0.3599481\ttotal: 10.3s\tremaining: 46.3s\n",
      "91:\tlearn: 0.3586001\ttotal: 10.4s\tremaining: 46.1s\n",
      "92:\tlearn: 0.3563531\ttotal: 10.5s\tremaining: 46s\n",
      "93:\tlearn: 0.3539948\ttotal: 10.6s\tremaining: 46s\n",
      "94:\tlearn: 0.3527752\ttotal: 10.7s\tremaining: 45.8s\n",
      "95:\tlearn: 0.3511241\ttotal: 10.8s\tremaining: 45.7s\n",
      "96:\tlearn: 0.3486006\ttotal: 11s\tremaining: 45.6s\n",
      "97:\tlearn: 0.3468111\ttotal: 11.1s\tremaining: 45.4s\n",
      "98:\tlearn: 0.3441523\ttotal: 11.1s\tremaining: 45.1s\n",
      "99:\tlearn: 0.3419752\ttotal: 11.3s\tremaining: 45.1s\n",
      "100:\tlearn: 0.3405349\ttotal: 11.4s\tremaining: 45s\n",
      "101:\tlearn: 0.3389081\ttotal: 11.6s\tremaining: 45.1s\n",
      "102:\tlearn: 0.3372463\ttotal: 11.7s\tremaining: 45s\n",
      "103:\tlearn: 0.3352155\ttotal: 11.8s\tremaining: 44.9s\n",
      "104:\tlearn: 0.3337885\ttotal: 11.9s\tremaining: 44.7s\n",
      "105:\tlearn: 0.3324045\ttotal: 12s\tremaining: 44.7s\n",
      "106:\tlearn: 0.3305091\ttotal: 12.1s\tremaining: 44.5s\n",
      "107:\tlearn: 0.3294003\ttotal: 12.2s\tremaining: 44.4s\n",
      "108:\tlearn: 0.3276045\ttotal: 12.3s\tremaining: 44.3s\n",
      "109:\tlearn: 0.3259808\ttotal: 12.4s\tremaining: 44.1s\n",
      "110:\tlearn: 0.3238628\ttotal: 12.5s\tremaining: 43.9s\n",
      "111:\tlearn: 0.3221117\ttotal: 12.6s\tremaining: 43.8s\n",
      "112:\tlearn: 0.3199906\ttotal: 12.7s\tremaining: 43.7s\n",
      "113:\tlearn: 0.3184548\ttotal: 12.9s\tremaining: 43.5s\n",
      "114:\tlearn: 0.3167463\ttotal: 13s\tremaining: 43.4s\n",
      "115:\tlearn: 0.3152618\ttotal: 13.1s\tremaining: 43.3s\n",
      "116:\tlearn: 0.3134635\ttotal: 13.2s\tremaining: 43.3s\n",
      "117:\tlearn: 0.3121290\ttotal: 13.3s\tremaining: 43.2s\n",
      "118:\tlearn: 0.3108850\ttotal: 13.4s\tremaining: 42.9s\n",
      "119:\tlearn: 0.3095977\ttotal: 13.5s\tremaining: 42.8s\n",
      "120:\tlearn: 0.3077646\ttotal: 13.7s\tremaining: 42.8s\n",
      "121:\tlearn: 0.3064463\ttotal: 13.8s\tremaining: 42.7s\n",
      "122:\tlearn: 0.3049171\ttotal: 13.9s\tremaining: 42.6s\n",
      "123:\tlearn: 0.3032176\ttotal: 14s\tremaining: 42.5s\n",
      "124:\tlearn: 0.3014477\ttotal: 14.1s\tremaining: 42.2s\n",
      "125:\tlearn: 0.2997141\ttotal: 14.2s\tremaining: 42.1s\n",
      "126:\tlearn: 0.2973230\ttotal: 14.3s\tremaining: 42.1s\n",
      "127:\tlearn: 0.2957129\ttotal: 14.4s\tremaining: 42s\n",
      "128:\tlearn: 0.2938145\ttotal: 14.5s\tremaining: 41.8s\n",
      "129:\tlearn: 0.2929537\ttotal: 14.7s\tremaining: 41.7s\n",
      "130:\tlearn: 0.2915920\ttotal: 14.8s\tremaining: 41.6s\n",
      "131:\tlearn: 0.2898397\ttotal: 14.8s\tremaining: 41.4s\n",
      "132:\tlearn: 0.2883786\ttotal: 15s\tremaining: 41.4s\n",
      "133:\tlearn: 0.2865735\ttotal: 15.1s\tremaining: 41.4s\n",
      "134:\tlearn: 0.2855683\ttotal: 15.3s\tremaining: 41.2s\n",
      "135:\tlearn: 0.2841020\ttotal: 15.4s\tremaining: 41.2s\n",
      "136:\tlearn: 0.2822282\ttotal: 15.5s\tremaining: 41.1s\n",
      "137:\tlearn: 0.2808295\ttotal: 15.6s\tremaining: 40.9s\n",
      "138:\tlearn: 0.2791289\ttotal: 15.7s\tremaining: 40.8s\n",
      "139:\tlearn: 0.2774444\ttotal: 15.8s\tremaining: 40.7s\n",
      "140:\tlearn: 0.2761597\ttotal: 15.9s\tremaining: 40.5s\n",
      "141:\tlearn: 0.2748143\ttotal: 16s\tremaining: 40.4s\n",
      "142:\tlearn: 0.2733368\ttotal: 16.1s\tremaining: 40.3s\n",
      "143:\tlearn: 0.2715565\ttotal: 16.3s\tremaining: 40.2s\n",
      "144:\tlearn: 0.2699857\ttotal: 16.3s\tremaining: 40s\n",
      "145:\tlearn: 0.2687836\ttotal: 16.4s\tremaining: 39.9s\n",
      "146:\tlearn: 0.2677146\ttotal: 16.6s\tremaining: 39.8s\n",
      "147:\tlearn: 0.2658910\ttotal: 16.7s\tremaining: 39.8s\n",
      "148:\tlearn: 0.2643944\ttotal: 16.8s\tremaining: 39.7s\n",
      "149:\tlearn: 0.2629643\ttotal: 17s\tremaining: 39.6s\n",
      "150:\tlearn: 0.2612148\ttotal: 17s\tremaining: 39.4s\n",
      "151:\tlearn: 0.2594597\ttotal: 17.1s\tremaining: 39.2s\n",
      "152:\tlearn: 0.2578324\ttotal: 17.3s\tremaining: 39.2s\n",
      "153:\tlearn: 0.2561791\ttotal: 17.4s\tremaining: 39.1s\n",
      "154:\tlearn: 0.2547189\ttotal: 17.5s\tremaining: 38.9s\n",
      "155:\tlearn: 0.2534454\ttotal: 17.6s\tremaining: 38.8s\n",
      "156:\tlearn: 0.2522108\ttotal: 17.8s\tremaining: 38.8s\n",
      "157:\tlearn: 0.2505875\ttotal: 17.8s\tremaining: 38.6s\n",
      "158:\tlearn: 0.2491234\ttotal: 18s\tremaining: 38.5s\n",
      "159:\tlearn: 0.2471079\ttotal: 18.1s\tremaining: 38.4s\n",
      "160:\tlearn: 0.2457849\ttotal: 18.2s\tremaining: 38.3s\n",
      "161:\tlearn: 0.2441974\ttotal: 18.3s\tremaining: 38.2s\n",
      "162:\tlearn: 0.2429464\ttotal: 18.5s\tremaining: 38.2s\n",
      "163:\tlearn: 0.2418095\ttotal: 18.5s\tremaining: 37.9s\n",
      "164:\tlearn: 0.2402395\ttotal: 18.6s\tremaining: 37.8s\n",
      "165:\tlearn: 0.2389110\ttotal: 18.8s\tremaining: 37.7s\n",
      "166:\tlearn: 0.2373448\ttotal: 18.9s\tremaining: 37.6s\n",
      "167:\tlearn: 0.2361405\ttotal: 19s\tremaining: 37.5s\n",
      "168:\tlearn: 0.2351664\ttotal: 19.1s\tremaining: 37.5s\n",
      "169:\tlearn: 0.2340438\ttotal: 19.3s\tremaining: 37.4s\n",
      "170:\tlearn: 0.2326566\ttotal: 19.3s\tremaining: 37.2s\n",
      "171:\tlearn: 0.2314959\ttotal: 19.4s\tremaining: 37s\n",
      "172:\tlearn: 0.2303567\ttotal: 19.5s\tremaining: 36.9s\n",
      "173:\tlearn: 0.2290802\ttotal: 19.6s\tremaining: 36.8s\n",
      "174:\tlearn: 0.2278032\ttotal: 19.8s\tremaining: 36.7s\n",
      "175:\tlearn: 0.2264324\ttotal: 19.9s\tremaining: 36.6s\n",
      "176:\tlearn: 0.2254862\ttotal: 20s\tremaining: 36.5s\n",
      "177:\tlearn: 0.2240090\ttotal: 20.1s\tremaining: 36.3s\n",
      "178:\tlearn: 0.2225958\ttotal: 20.2s\tremaining: 36.3s\n",
      "179:\tlearn: 0.2211643\ttotal: 20.4s\tremaining: 36.2s\n",
      "180:\tlearn: 0.2199106\ttotal: 20.4s\tremaining: 36s\n",
      "181:\tlearn: 0.2185592\ttotal: 20.6s\tremaining: 35.9s\n",
      "182:\tlearn: 0.2170675\ttotal: 20.7s\tremaining: 35.8s\n",
      "183:\tlearn: 0.2158757\ttotal: 20.8s\tremaining: 35.7s\n",
      "184:\tlearn: 0.2146087\ttotal: 20.9s\tremaining: 35.5s\n",
      "185:\tlearn: 0.2133973\ttotal: 21s\tremaining: 35.4s\n",
      "186:\tlearn: 0.2124031\ttotal: 21.1s\tremaining: 35.3s\n",
      "187:\tlearn: 0.2111423\ttotal: 21.2s\tremaining: 35.2s\n",
      "188:\tlearn: 0.2100570\ttotal: 21.3s\tremaining: 35.1s\n",
      "189:\tlearn: 0.2088510\ttotal: 21.4s\tremaining: 34.9s\n",
      "190:\tlearn: 0.2078415\ttotal: 21.5s\tremaining: 34.8s\n",
      "191:\tlearn: 0.2069783\ttotal: 21.6s\tremaining: 34.7s\n",
      "192:\tlearn: 0.2057021\ttotal: 21.7s\tremaining: 34.6s\n",
      "193:\tlearn: 0.2049128\ttotal: 21.9s\tremaining: 34.6s\n",
      "194:\tlearn: 0.2038769\ttotal: 22s\tremaining: 34.4s\n",
      "195:\tlearn: 0.2027159\ttotal: 22.1s\tremaining: 34.3s\n",
      "196:\tlearn: 0.2016210\ttotal: 22.3s\tremaining: 34.2s\n",
      "197:\tlearn: 0.2008489\ttotal: 22.3s\tremaining: 34.1s\n",
      "198:\tlearn: 0.1996874\ttotal: 22.5s\tremaining: 34s\n",
      "199:\tlearn: 0.1987318\ttotal: 22.7s\tremaining: 34s\n",
      "200:\tlearn: 0.1974303\ttotal: 22.8s\tremaining: 34s\n",
      "201:\tlearn: 0.1963275\ttotal: 22.9s\tremaining: 33.8s\n",
      "202:\tlearn: 0.1951983\ttotal: 23s\tremaining: 33.7s\n",
      "203:\tlearn: 0.1942007\ttotal: 23.1s\tremaining: 33.6s\n",
      "204:\tlearn: 0.1932688\ttotal: 23.3s\tremaining: 33.5s\n",
      "205:\tlearn: 0.1919807\ttotal: 23.4s\tremaining: 33.3s\n",
      "206:\tlearn: 0.1910001\ttotal: 23.5s\tremaining: 33.2s\n",
      "207:\tlearn: 0.1900389\ttotal: 23.6s\tremaining: 33.1s\n",
      "208:\tlearn: 0.1891425\ttotal: 23.6s\tremaining: 32.9s\n",
      "209:\tlearn: 0.1882784\ttotal: 23.7s\tremaining: 32.8s\n",
      "210:\tlearn: 0.1873297\ttotal: 23.8s\tremaining: 32.6s\n",
      "211:\tlearn: 0.1865183\ttotal: 23.9s\tremaining: 32.5s\n",
      "212:\tlearn: 0.1856632\ttotal: 24.1s\tremaining: 32.4s\n",
      "213:\tlearn: 0.1847241\ttotal: 24.2s\tremaining: 32.3s\n",
      "214:\tlearn: 0.1838521\ttotal: 24.3s\tremaining: 32.1s\n",
      "215:\tlearn: 0.1829527\ttotal: 24.4s\tremaining: 32.1s\n",
      "216:\tlearn: 0.1819183\ttotal: 24.5s\tremaining: 31.9s\n",
      "217:\tlearn: 0.1810468\ttotal: 24.6s\tremaining: 31.8s\n",
      "218:\tlearn: 0.1802084\ttotal: 24.7s\tremaining: 31.7s\n",
      "219:\tlearn: 0.1793304\ttotal: 24.8s\tremaining: 31.6s\n",
      "220:\tlearn: 0.1784204\ttotal: 24.9s\tremaining: 31.4s\n",
      "221:\tlearn: 0.1774498\ttotal: 25s\tremaining: 31.3s\n",
      "222:\tlearn: 0.1764272\ttotal: 25.1s\tremaining: 31.2s\n",
      "223:\tlearn: 0.1756801\ttotal: 25.2s\tremaining: 31.1s\n",
      "224:\tlearn: 0.1747903\ttotal: 25.4s\tremaining: 31s\n",
      "225:\tlearn: 0.1737993\ttotal: 25.4s\tremaining: 30.8s\n",
      "226:\tlearn: 0.1730329\ttotal: 25.5s\tremaining: 30.7s\n",
      "227:\tlearn: 0.1722202\ttotal: 25.6s\tremaining: 30.6s\n",
      "228:\tlearn: 0.1714516\ttotal: 25.8s\tremaining: 30.5s\n",
      "229:\tlearn: 0.1707641\ttotal: 25.9s\tremaining: 30.3s\n",
      "230:\tlearn: 0.1698583\ttotal: 26s\tremaining: 30.2s\n",
      "231:\tlearn: 0.1690631\ttotal: 26s\tremaining: 30.1s\n",
      "232:\tlearn: 0.1681726\ttotal: 26.2s\tremaining: 30s\n",
      "233:\tlearn: 0.1675564\ttotal: 26.3s\tremaining: 29.9s\n",
      "234:\tlearn: 0.1668891\ttotal: 26.4s\tremaining: 29.8s\n",
      "235:\tlearn: 0.1662414\ttotal: 26.5s\tremaining: 29.6s\n",
      "236:\tlearn: 0.1656188\ttotal: 26.6s\tremaining: 29.5s\n",
      "237:\tlearn: 0.1647800\ttotal: 26.7s\tremaining: 29.4s\n",
      "238:\tlearn: 0.1638913\ttotal: 26.8s\tremaining: 29.3s\n",
      "239:\tlearn: 0.1629865\ttotal: 26.9s\tremaining: 29.1s\n",
      "240:\tlearn: 0.1621474\ttotal: 27s\tremaining: 29.1s\n",
      "241:\tlearn: 0.1613934\ttotal: 27.2s\tremaining: 29s\n",
      "242:\tlearn: 0.1608256\ttotal: 27.2s\tremaining: 28.8s\n",
      "243:\tlearn: 0.1603216\ttotal: 27.3s\tremaining: 28.7s\n",
      "244:\tlearn: 0.1596123\ttotal: 27.4s\tremaining: 28.6s\n",
      "245:\tlearn: 0.1591006\ttotal: 27.5s\tremaining: 28.4s\n",
      "246:\tlearn: 0.1583955\ttotal: 27.7s\tremaining: 28.3s\n",
      "247:\tlearn: 0.1577839\ttotal: 27.8s\tremaining: 28.2s\n",
      "248:\tlearn: 0.1570036\ttotal: 27.8s\tremaining: 28s\n",
      "249:\tlearn: 0.1562708\ttotal: 27.9s\tremaining: 27.9s\n",
      "250:\tlearn: 0.1556535\ttotal: 28s\tremaining: 27.8s\n",
      "251:\tlearn: 0.1548070\ttotal: 28.1s\tremaining: 27.7s\n",
      "252:\tlearn: 0.1540951\ttotal: 28.2s\tremaining: 27.6s\n",
      "253:\tlearn: 0.1533773\ttotal: 28.3s\tremaining: 27.5s\n",
      "254:\tlearn: 0.1526246\ttotal: 28.4s\tremaining: 27.3s\n",
      "255:\tlearn: 0.1519247\ttotal: 28.5s\tremaining: 27.2s\n",
      "256:\tlearn: 0.1513264\ttotal: 28.6s\tremaining: 27.1s\n",
      "257:\tlearn: 0.1503973\ttotal: 28.7s\tremaining: 26.9s\n",
      "258:\tlearn: 0.1498062\ttotal: 28.8s\tremaining: 26.8s\n",
      "259:\tlearn: 0.1488724\ttotal: 28.9s\tremaining: 26.7s\n",
      "260:\tlearn: 0.1483288\ttotal: 29s\tremaining: 26.6s\n",
      "261:\tlearn: 0.1475434\ttotal: 29.1s\tremaining: 26.4s\n",
      "262:\tlearn: 0.1469201\ttotal: 29.2s\tremaining: 26.3s\n",
      "263:\tlearn: 0.1462420\ttotal: 29.3s\tremaining: 26.1s\n",
      "264:\tlearn: 0.1454276\ttotal: 29.4s\tremaining: 26s\n",
      "265:\tlearn: 0.1445268\ttotal: 29.5s\tremaining: 25.9s\n",
      "266:\tlearn: 0.1437673\ttotal: 29.6s\tremaining: 25.8s\n",
      "267:\tlearn: 0.1430515\ttotal: 29.6s\tremaining: 25.7s\n",
      "268:\tlearn: 0.1426504\ttotal: 29.7s\tremaining: 25.5s\n",
      "269:\tlearn: 0.1420872\ttotal: 29.9s\tremaining: 25.4s\n",
      "270:\tlearn: 0.1414685\ttotal: 29.9s\tremaining: 25.3s\n",
      "271:\tlearn: 0.1409778\ttotal: 30s\tremaining: 25.2s\n",
      "272:\tlearn: 0.1402950\ttotal: 30.1s\tremaining: 25.1s\n",
      "273:\tlearn: 0.1396772\ttotal: 30.2s\tremaining: 24.9s\n",
      "274:\tlearn: 0.1390221\ttotal: 30.3s\tremaining: 24.8s\n",
      "275:\tlearn: 0.1385760\ttotal: 30.4s\tremaining: 24.7s\n",
      "276:\tlearn: 0.1378447\ttotal: 30.5s\tremaining: 24.5s\n",
      "277:\tlearn: 0.1373882\ttotal: 30.6s\tremaining: 24.4s\n",
      "278:\tlearn: 0.1368420\ttotal: 30.7s\tremaining: 24.3s\n",
      "279:\tlearn: 0.1361955\ttotal: 30.7s\tremaining: 24.2s\n",
      "280:\tlearn: 0.1356869\ttotal: 30.8s\tremaining: 24s\n",
      "281:\tlearn: 0.1350806\ttotal: 30.9s\tremaining: 23.9s\n",
      "282:\tlearn: 0.1345386\ttotal: 31s\tremaining: 23.8s\n",
      "283:\tlearn: 0.1340746\ttotal: 31.1s\tremaining: 23.6s\n",
      "284:\tlearn: 0.1336291\ttotal: 31.2s\tremaining: 23.5s\n",
      "285:\tlearn: 0.1329730\ttotal: 31.3s\tremaining: 23.4s\n",
      "286:\tlearn: 0.1324802\ttotal: 31.4s\tremaining: 23.3s\n",
      "287:\tlearn: 0.1321013\ttotal: 31.5s\tremaining: 23.2s\n",
      "288:\tlearn: 0.1315986\ttotal: 31.6s\tremaining: 23s\n",
      "289:\tlearn: 0.1309841\ttotal: 31.6s\tremaining: 22.9s\n",
      "290:\tlearn: 0.1304626\ttotal: 31.7s\tremaining: 22.8s\n",
      "291:\tlearn: 0.1300452\ttotal: 31.8s\tremaining: 22.7s\n",
      "292:\tlearn: 0.1294358\ttotal: 31.9s\tremaining: 22.6s\n",
      "293:\tlearn: 0.1289560\ttotal: 32s\tremaining: 22.4s\n",
      "294:\tlearn: 0.1283070\ttotal: 32.1s\tremaining: 22.3s\n",
      "295:\tlearn: 0.1277955\ttotal: 32.2s\tremaining: 22.2s\n",
      "296:\tlearn: 0.1272273\ttotal: 32.3s\tremaining: 22.1s\n",
      "297:\tlearn: 0.1267679\ttotal: 32.4s\tremaining: 22s\n",
      "298:\tlearn: 0.1263111\ttotal: 32.5s\tremaining: 21.9s\n",
      "299:\tlearn: 0.1257586\ttotal: 32.6s\tremaining: 21.8s\n",
      "300:\tlearn: 0.1253187\ttotal: 32.7s\tremaining: 21.6s\n",
      "301:\tlearn: 0.1247323\ttotal: 32.8s\tremaining: 21.5s\n",
      "302:\tlearn: 0.1241842\ttotal: 32.9s\tremaining: 21.4s\n",
      "303:\tlearn: 0.1236596\ttotal: 33s\tremaining: 21.3s\n",
      "304:\tlearn: 0.1231119\ttotal: 33.1s\tremaining: 21.2s\n",
      "305:\tlearn: 0.1226557\ttotal: 33.2s\tremaining: 21s\n",
      "306:\tlearn: 0.1221907\ttotal: 33.3s\tremaining: 20.9s\n",
      "307:\tlearn: 0.1218640\ttotal: 33.4s\tremaining: 20.8s\n",
      "308:\tlearn: 0.1214877\ttotal: 33.5s\tremaining: 20.7s\n",
      "309:\tlearn: 0.1209414\ttotal: 33.6s\tremaining: 20.6s\n",
      "310:\tlearn: 0.1203687\ttotal: 33.7s\tremaining: 20.5s\n",
      "311:\tlearn: 0.1198323\ttotal: 33.8s\tremaining: 20.4s\n",
      "312:\tlearn: 0.1193554\ttotal: 33.9s\tremaining: 20.2s\n",
      "313:\tlearn: 0.1189492\ttotal: 34s\tremaining: 20.1s\n",
      "314:\tlearn: 0.1184580\ttotal: 34.1s\tremaining: 20s\n",
      "315:\tlearn: 0.1180317\ttotal: 34.3s\tremaining: 19.9s\n",
      "316:\tlearn: 0.1175877\ttotal: 34.4s\tremaining: 19.8s\n",
      "317:\tlearn: 0.1171899\ttotal: 34.5s\tremaining: 19.7s\n",
      "318:\tlearn: 0.1167885\ttotal: 34.5s\tremaining: 19.6s\n",
      "319:\tlearn: 0.1164922\ttotal: 34.6s\tremaining: 19.5s\n",
      "320:\tlearn: 0.1160834\ttotal: 34.7s\tremaining: 19.4s\n",
      "321:\tlearn: 0.1157026\ttotal: 34.8s\tremaining: 19.2s\n",
      "322:\tlearn: 0.1153775\ttotal: 34.9s\tremaining: 19.1s\n",
      "323:\tlearn: 0.1149724\ttotal: 35s\tremaining: 19s\n",
      "324:\tlearn: 0.1145189\ttotal: 35.1s\tremaining: 18.9s\n",
      "325:\tlearn: 0.1139702\ttotal: 35.2s\tremaining: 18.8s\n",
      "326:\tlearn: 0.1136076\ttotal: 35.3s\tremaining: 18.7s\n",
      "327:\tlearn: 0.1131837\ttotal: 35.4s\tremaining: 18.6s\n",
      "328:\tlearn: 0.1126954\ttotal: 35.5s\tremaining: 18.5s\n",
      "329:\tlearn: 0.1122774\ttotal: 35.7s\tremaining: 18.4s\n",
      "330:\tlearn: 0.1119182\ttotal: 35.7s\tremaining: 18.3s\n",
      "331:\tlearn: 0.1114734\ttotal: 35.8s\tremaining: 18.1s\n",
      "332:\tlearn: 0.1110891\ttotal: 35.9s\tremaining: 18s\n",
      "333:\tlearn: 0.1106687\ttotal: 36s\tremaining: 17.9s\n",
      "334:\tlearn: 0.1102564\ttotal: 36.1s\tremaining: 17.8s\n",
      "335:\tlearn: 0.1099419\ttotal: 36.2s\tremaining: 17.7s\n",
      "336:\tlearn: 0.1095977\ttotal: 36.3s\tremaining: 17.6s\n",
      "337:\tlearn: 0.1091248\ttotal: 36.4s\tremaining: 17.4s\n",
      "338:\tlearn: 0.1087555\ttotal: 36.5s\tremaining: 17.3s\n",
      "339:\tlearn: 0.1083196\ttotal: 36.6s\tremaining: 17.2s\n",
      "340:\tlearn: 0.1078986\ttotal: 36.7s\tremaining: 17.1s\n",
      "341:\tlearn: 0.1075447\ttotal: 36.8s\tremaining: 17s\n",
      "342:\tlearn: 0.1071531\ttotal: 36.9s\tremaining: 16.9s\n",
      "343:\tlearn: 0.1067757\ttotal: 37s\tremaining: 16.8s\n",
      "344:\tlearn: 0.1063702\ttotal: 37.1s\tremaining: 16.7s\n",
      "345:\tlearn: 0.1060301\ttotal: 37.2s\tremaining: 16.5s\n",
      "346:\tlearn: 0.1055946\ttotal: 37.3s\tremaining: 16.4s\n",
      "347:\tlearn: 0.1052558\ttotal: 37.4s\tremaining: 16.3s\n",
      "348:\tlearn: 0.1047019\ttotal: 37.5s\tremaining: 16.2s\n",
      "349:\tlearn: 0.1043434\ttotal: 37.6s\tremaining: 16.1s\n",
      "350:\tlearn: 0.1040885\ttotal: 37.6s\tremaining: 16s\n",
      "351:\tlearn: 0.1038598\ttotal: 37.7s\tremaining: 15.9s\n",
      "352:\tlearn: 0.1034403\ttotal: 37.8s\tremaining: 15.7s\n",
      "353:\tlearn: 0.1029770\ttotal: 37.9s\tremaining: 15.6s\n",
      "354:\tlearn: 0.1027277\ttotal: 38s\tremaining: 15.5s\n",
      "355:\tlearn: 0.1024275\ttotal: 38.2s\tremaining: 15.4s\n",
      "356:\tlearn: 0.1020989\ttotal: 38.2s\tremaining: 15.3s\n",
      "357:\tlearn: 0.1017625\ttotal: 38.3s\tremaining: 15.2s\n",
      "358:\tlearn: 0.1014092\ttotal: 38.4s\tremaining: 15.1s\n",
      "359:\tlearn: 0.1010206\ttotal: 38.5s\tremaining: 15s\n",
      "360:\tlearn: 0.1006146\ttotal: 38.6s\tremaining: 14.9s\n",
      "361:\tlearn: 0.1002648\ttotal: 38.7s\tremaining: 14.8s\n",
      "362:\tlearn: 0.0999185\ttotal: 38.8s\tremaining: 14.6s\n",
      "363:\tlearn: 0.0996340\ttotal: 38.9s\tremaining: 14.5s\n",
      "364:\tlearn: 0.0993248\ttotal: 39s\tremaining: 14.4s\n",
      "365:\tlearn: 0.0990160\ttotal: 39.1s\tremaining: 14.3s\n",
      "366:\tlearn: 0.0988030\ttotal: 39.2s\tremaining: 14.2s\n",
      "367:\tlearn: 0.0984087\ttotal: 39.3s\tremaining: 14.1s\n",
      "368:\tlearn: 0.0980696\ttotal: 39.4s\tremaining: 14s\n",
      "369:\tlearn: 0.0977651\ttotal: 39.5s\tremaining: 13.9s\n",
      "370:\tlearn: 0.0974008\ttotal: 39.5s\tremaining: 13.8s\n",
      "371:\tlearn: 0.0971140\ttotal: 39.6s\tremaining: 13.6s\n",
      "372:\tlearn: 0.0967713\ttotal: 39.7s\tremaining: 13.5s\n",
      "373:\tlearn: 0.0963485\ttotal: 39.8s\tremaining: 13.4s\n",
      "374:\tlearn: 0.0960473\ttotal: 39.9s\tremaining: 13.3s\n",
      "375:\tlearn: 0.0957670\ttotal: 40.1s\tremaining: 13.2s\n",
      "376:\tlearn: 0.0953334\ttotal: 40.2s\tremaining: 13.1s\n",
      "377:\tlearn: 0.0950062\ttotal: 40.2s\tremaining: 13s\n",
      "378:\tlearn: 0.0946765\ttotal: 40.3s\tremaining: 12.9s\n",
      "379:\tlearn: 0.0943909\ttotal: 40.4s\tremaining: 12.7s\n",
      "380:\tlearn: 0.0940068\ttotal: 40.5s\tremaining: 12.6s\n",
      "381:\tlearn: 0.0936518\ttotal: 40.6s\tremaining: 12.5s\n",
      "382:\tlearn: 0.0933242\ttotal: 40.7s\tremaining: 12.4s\n",
      "383:\tlearn: 0.0930255\ttotal: 40.8s\tremaining: 12.3s\n",
      "384:\tlearn: 0.0927139\ttotal: 40.9s\tremaining: 12.2s\n",
      "385:\tlearn: 0.0923630\ttotal: 41s\tremaining: 12.1s\n",
      "386:\tlearn: 0.0920975\ttotal: 41.1s\tremaining: 12s\n",
      "387:\tlearn: 0.0918205\ttotal: 41.1s\tremaining: 11.9s\n",
      "388:\tlearn: 0.0915727\ttotal: 41.2s\tremaining: 11.7s\n",
      "389:\tlearn: 0.0912964\ttotal: 41.3s\tremaining: 11.6s\n",
      "390:\tlearn: 0.0910034\ttotal: 41.4s\tremaining: 11.5s\n",
      "391:\tlearn: 0.0907480\ttotal: 41.5s\tremaining: 11.4s\n",
      "392:\tlearn: 0.0904147\ttotal: 41.6s\tremaining: 11.3s\n",
      "393:\tlearn: 0.0902233\ttotal: 41.7s\tremaining: 11.2s\n",
      "394:\tlearn: 0.0898770\ttotal: 41.8s\tremaining: 11.1s\n",
      "395:\tlearn: 0.0895446\ttotal: 41.9s\tremaining: 11s\n",
      "396:\tlearn: 0.0893377\ttotal: 42s\tremaining: 10.9s\n",
      "397:\tlearn: 0.0890285\ttotal: 42.1s\tremaining: 10.8s\n",
      "398:\tlearn: 0.0887583\ttotal: 42.2s\tremaining: 10.7s\n",
      "399:\tlearn: 0.0885201\ttotal: 42.3s\tremaining: 10.6s\n",
      "400:\tlearn: 0.0882781\ttotal: 42.4s\tremaining: 10.5s\n",
      "401:\tlearn: 0.0879668\ttotal: 42.5s\tremaining: 10.4s\n",
      "402:\tlearn: 0.0876858\ttotal: 42.6s\tremaining: 10.3s\n",
      "403:\tlearn: 0.0873841\ttotal: 42.7s\tremaining: 10.1s\n",
      "404:\tlearn: 0.0870901\ttotal: 42.7s\tremaining: 10s\n",
      "405:\tlearn: 0.0868188\ttotal: 42.9s\tremaining: 9.92s\n",
      "406:\tlearn: 0.0865397\ttotal: 43s\tremaining: 9.82s\n",
      "407:\tlearn: 0.0862957\ttotal: 43.1s\tremaining: 9.72s\n",
      "408:\tlearn: 0.0860929\ttotal: 43.2s\tremaining: 9.62s\n",
      "409:\tlearn: 0.0858384\ttotal: 43.3s\tremaining: 9.51s\n",
      "410:\tlearn: 0.0855397\ttotal: 43.4s\tremaining: 9.4s\n",
      "411:\tlearn: 0.0853262\ttotal: 43.5s\tremaining: 9.29s\n",
      "412:\tlearn: 0.0850361\ttotal: 43.6s\tremaining: 9.18s\n",
      "413:\tlearn: 0.0847796\ttotal: 43.7s\tremaining: 9.08s\n",
      "414:\tlearn: 0.0844147\ttotal: 43.8s\tremaining: 8.97s\n",
      "415:\tlearn: 0.0842168\ttotal: 43.9s\tremaining: 8.87s\n",
      "416:\tlearn: 0.0840231\ttotal: 44s\tremaining: 8.76s\n",
      "417:\tlearn: 0.0838094\ttotal: 44.1s\tremaining: 8.64s\n",
      "418:\tlearn: 0.0835920\ttotal: 44.1s\tremaining: 8.53s\n",
      "419:\tlearn: 0.0833501\ttotal: 44.3s\tremaining: 8.43s\n",
      "420:\tlearn: 0.0830976\ttotal: 44.4s\tremaining: 8.33s\n",
      "421:\tlearn: 0.0828725\ttotal: 44.5s\tremaining: 8.22s\n",
      "422:\tlearn: 0.0826704\ttotal: 44.7s\tremaining: 8.13s\n",
      "423:\tlearn: 0.0823930\ttotal: 44.8s\tremaining: 8.02s\n",
      "424:\tlearn: 0.0821444\ttotal: 44.9s\tremaining: 7.91s\n",
      "425:\tlearn: 0.0818793\ttotal: 45s\tremaining: 7.82s\n",
      "426:\tlearn: 0.0816737\ttotal: 45.1s\tremaining: 7.71s\n",
      "427:\tlearn: 0.0814328\ttotal: 45.2s\tremaining: 7.61s\n",
      "428:\tlearn: 0.0812064\ttotal: 45.3s\tremaining: 7.5s\n",
      "429:\tlearn: 0.0809453\ttotal: 45.5s\tremaining: 7.4s\n",
      "430:\tlearn: 0.0807025\ttotal: 45.6s\tremaining: 7.3s\n",
      "431:\tlearn: 0.0804182\ttotal: 45.7s\tremaining: 7.19s\n",
      "432:\tlearn: 0.0801989\ttotal: 45.8s\tremaining: 7.09s\n",
      "433:\tlearn: 0.0799552\ttotal: 45.9s\tremaining: 6.99s\n",
      "434:\tlearn: 0.0797356\ttotal: 46s\tremaining: 6.88s\n",
      "435:\tlearn: 0.0795569\ttotal: 46.2s\tremaining: 6.78s\n",
      "436:\tlearn: 0.0792834\ttotal: 46.3s\tremaining: 6.67s\n",
      "437:\tlearn: 0.0790001\ttotal: 46.4s\tremaining: 6.57s\n",
      "438:\tlearn: 0.0787828\ttotal: 46.6s\tremaining: 6.47s\n",
      "439:\tlearn: 0.0784132\ttotal: 46.8s\tremaining: 6.38s\n",
      "440:\tlearn: 0.0782643\ttotal: 46.9s\tremaining: 6.28s\n",
      "441:\tlearn: 0.0780570\ttotal: 47s\tremaining: 6.17s\n",
      "442:\tlearn: 0.0777962\ttotal: 47.1s\tremaining: 6.06s\n",
      "443:\tlearn: 0.0775487\ttotal: 47.3s\tremaining: 5.97s\n",
      "444:\tlearn: 0.0773818\ttotal: 47.5s\tremaining: 5.87s\n",
      "445:\tlearn: 0.0771591\ttotal: 47.5s\tremaining: 5.76s\n",
      "446:\tlearn: 0.0769730\ttotal: 47.6s\tremaining: 5.65s\n",
      "447:\tlearn: 0.0767227\ttotal: 47.8s\tremaining: 5.55s\n",
      "448:\tlearn: 0.0764977\ttotal: 47.9s\tremaining: 5.44s\n",
      "449:\tlearn: 0.0762219\ttotal: 48s\tremaining: 5.34s\n",
      "450:\tlearn: 0.0760036\ttotal: 48.3s\tremaining: 5.24s\n",
      "451:\tlearn: 0.0757626\ttotal: 48.4s\tremaining: 5.14s\n",
      "452:\tlearn: 0.0755564\ttotal: 48.5s\tremaining: 5.04s\n",
      "453:\tlearn: 0.0752939\ttotal: 48.8s\tremaining: 4.95s\n",
      "454:\tlearn: 0.0750648\ttotal: 49s\tremaining: 4.84s\n",
      "455:\tlearn: 0.0748789\ttotal: 49.1s\tremaining: 4.74s\n",
      "456:\tlearn: 0.0746508\ttotal: 49.3s\tremaining: 4.63s\n",
      "457:\tlearn: 0.0744185\ttotal: 49.4s\tremaining: 4.53s\n",
      "458:\tlearn: 0.0742302\ttotal: 49.5s\tremaining: 4.42s\n",
      "459:\tlearn: 0.0739927\ttotal: 49.7s\tremaining: 4.32s\n",
      "460:\tlearn: 0.0737988\ttotal: 49.8s\tremaining: 4.21s\n",
      "461:\tlearn: 0.0735948\ttotal: 50s\tremaining: 4.11s\n",
      "462:\tlearn: 0.0734122\ttotal: 50.1s\tremaining: 4.01s\n",
      "463:\tlearn: 0.0732281\ttotal: 50.3s\tremaining: 3.9s\n",
      "464:\tlearn: 0.0730731\ttotal: 50.4s\tremaining: 3.79s\n",
      "465:\tlearn: 0.0728444\ttotal: 50.5s\tremaining: 3.69s\n",
      "466:\tlearn: 0.0726447\ttotal: 50.7s\tremaining: 3.58s\n",
      "467:\tlearn: 0.0724537\ttotal: 50.9s\tremaining: 3.48s\n",
      "468:\tlearn: 0.0722828\ttotal: 51s\tremaining: 3.37s\n",
      "469:\tlearn: 0.0720516\ttotal: 51.1s\tremaining: 3.26s\n",
      "470:\tlearn: 0.0718325\ttotal: 51.3s\tremaining: 3.16s\n",
      "471:\tlearn: 0.0715193\ttotal: 51.4s\tremaining: 3.05s\n",
      "472:\tlearn: 0.0713624\ttotal: 51.6s\tremaining: 2.95s\n",
      "473:\tlearn: 0.0710877\ttotal: 51.7s\tremaining: 2.84s\n",
      "474:\tlearn: 0.0708907\ttotal: 51.8s\tremaining: 2.73s\n",
      "475:\tlearn: 0.0706999\ttotal: 52s\tremaining: 2.62s\n",
      "476:\tlearn: 0.0704907\ttotal: 52.1s\tremaining: 2.51s\n",
      "477:\tlearn: 0.0703369\ttotal: 52.2s\tremaining: 2.4s\n",
      "478:\tlearn: 0.0701442\ttotal: 52.4s\tremaining: 2.3s\n",
      "479:\tlearn: 0.0699465\ttotal: 52.6s\tremaining: 2.19s\n",
      "480:\tlearn: 0.0697580\ttotal: 52.7s\tremaining: 2.08s\n",
      "481:\tlearn: 0.0695701\ttotal: 52.8s\tremaining: 1.97s\n",
      "482:\tlearn: 0.0693621\ttotal: 53s\tremaining: 1.86s\n",
      "483:\tlearn: 0.0692243\ttotal: 53.1s\tremaining: 1.75s\n",
      "484:\tlearn: 0.0690620\ttotal: 53.2s\tremaining: 1.65s\n",
      "485:\tlearn: 0.0688475\ttotal: 53.4s\tremaining: 1.54s\n",
      "486:\tlearn: 0.0687011\ttotal: 53.5s\tremaining: 1.43s\n",
      "487:\tlearn: 0.0685303\ttotal: 53.7s\tremaining: 1.32s\n",
      "488:\tlearn: 0.0683549\ttotal: 53.8s\tremaining: 1.21s\n",
      "489:\tlearn: 0.0682094\ttotal: 53.9s\tremaining: 1.1s\n",
      "490:\tlearn: 0.0680546\ttotal: 54.1s\tremaining: 991ms\n",
      "491:\tlearn: 0.0678703\ttotal: 54.2s\tremaining: 882ms\n",
      "492:\tlearn: 0.0677495\ttotal: 54.3s\tremaining: 772ms\n",
      "493:\tlearn: 0.0675637\ttotal: 54.5s\tremaining: 662ms\n",
      "494:\tlearn: 0.0673979\ttotal: 54.6s\tremaining: 552ms\n",
      "495:\tlearn: 0.0672234\ttotal: 54.7s\tremaining: 442ms\n",
      "496:\tlearn: 0.0670483\ttotal: 54.9s\tremaining: 331ms\n",
      "497:\tlearn: 0.0668858\ttotal: 55s\tremaining: 221ms\n",
      "498:\tlearn: 0.0666992\ttotal: 55.2s\tremaining: 111ms\n",
      "499:\tlearn: 0.0664862\ttotal: 55.4s\tremaining: 0us\n",
      "Accuracy: 0.7435897435897436\n",
      "\n",
      "Confusion Matrix:\n",
      " [[43 16]\n",
      " [14 44]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74        59\n",
      "           1       0.73      0.76      0.75        58\n",
      "\n",
      "    accuracy                           0.74       117\n",
      "   macro avg       0.74      0.74      0.74       117\n",
      "weighted avg       0.74      0.74      0.74       117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Fraud'], axis=1)\n",
    "y = df['Fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a CatBoost Classifier\n",
    "model = CatBoostClassifier(iterations=500, depth=10, learning_rate=0.05, loss_function='MultiClass', random_seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, cat_features=None)  # You can specify categorical features if needed\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/part_D/partd_ros_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"Unnamed: 0.1\",\"PRSCRBR_NPI\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prscrbr_Crdntls</th>\n",
       "      <th>Prscrbr_Gndr</th>\n",
       "      <th>Prscrbr_Type</th>\n",
       "      <th>Prscrbr_Type_src</th>\n",
       "      <th>Tot_Clms</th>\n",
       "      <th>Tot_30day_Fills</th>\n",
       "      <th>Tot_Drug_Cst</th>\n",
       "      <th>Tot_Day_Suply</th>\n",
       "      <th>Tot_Benes</th>\n",
       "      <th>GE65_Sprsn_Flag</th>\n",
       "      <th>...</th>\n",
       "      <th>Bene_Race_Wht_Cnt</th>\n",
       "      <th>Bene_Race_Black_Cnt</th>\n",
       "      <th>Bene_Race_Api_Cnt</th>\n",
       "      <th>Bene_Race_Hspnc_Cnt</th>\n",
       "      <th>Bene_Race_Natind_Cnt</th>\n",
       "      <th>Bene_Race_Othr_Cnt</th>\n",
       "      <th>Bene_Dual_Cnt</th>\n",
       "      <th>Bene_Ndual_Cnt</th>\n",
       "      <th>Bene_Avg_Risk_Scre</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>369.800000</td>\n",
       "      <td>20606.08</td>\n",
       "      <td>8621.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>67.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2.245800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>2145.666667</td>\n",
       "      <td>79803.65</td>\n",
       "      <td>60953.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>130.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.695165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57.700000</td>\n",
       "      <td>327.34</td>\n",
       "      <td>554.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.006070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3535</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>128.52</td>\n",
       "      <td>181.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.251869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6421</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>3834.98</td>\n",
       "      <td>1366.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.919074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2509385</th>\n",
       "      <td>9176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6364.0</td>\n",
       "      <td>11801.166667</td>\n",
       "      <td>478117.79</td>\n",
       "      <td>342993.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>236.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>1.169697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2509386</th>\n",
       "      <td>9176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5599.0</td>\n",
       "      <td>10111.033333</td>\n",
       "      <td>538281.10</td>\n",
       "      <td>296379.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>393.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>1.369505</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2509387</th>\n",
       "      <td>9176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>109.333333</td>\n",
       "      <td>3824.90</td>\n",
       "      <td>3195.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.111492</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2509388</th>\n",
       "      <td>7632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>959.0</td>\n",
       "      <td>1501.533333</td>\n",
       "      <td>107461.83</td>\n",
       "      <td>40631.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.624990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2509389</th>\n",
       "      <td>13776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>843.81</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.171146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2509390 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Prscrbr_Crdntls  Prscrbr_Gndr  Prscrbr_Type  Prscrbr_Type_src  \\\n",
       "0                   7632           0.0            86               1.0   \n",
       "1                   7632           0.0             9               1.0   \n",
       "2                   4394           0.0            42               1.0   \n",
       "3                   3535           1.0            42               1.0   \n",
       "4                   6421           1.0           120               1.0   \n",
       "...                  ...           ...           ...               ...   \n",
       "2509385             9176           0.0            86               1.0   \n",
       "2509386             9176           0.0            60               1.0   \n",
       "2509387             9176           0.0            60               1.0   \n",
       "2509388             7632           0.0            86               1.0   \n",
       "2509389            13776           0.0           155               1.0   \n",
       "\n",
       "         Tot_Clms  Tot_30day_Fills  Tot_Drug_Cst  Tot_Day_Suply  Tot_Benes  \\\n",
       "0           324.0       369.800000      20606.08         8621.0      106.0   \n",
       "1          1992.0      2145.666667      79803.65        60953.0      228.0   \n",
       "2            57.0        57.700000        327.34          554.0       43.0   \n",
       "3            18.0        18.000000        128.52          181.0       16.0   \n",
       "4            37.0        47.000000       3834.98         1366.0       17.0   \n",
       "...           ...              ...           ...            ...        ...   \n",
       "2509385    6364.0     11801.166667     478117.79       342993.0      312.0   \n",
       "2509386    5599.0     10111.033333     538281.10       296379.0      444.0   \n",
       "2509387     106.0       109.333333       3824.90         3195.0       33.0   \n",
       "2509388     959.0      1501.533333     107461.83        40631.0      134.0   \n",
       "2509389      27.0        51.000000        843.81         1212.0       12.0   \n",
       "\n",
       "         GE65_Sprsn_Flag  ...  Bene_Race_Wht_Cnt  Bene_Race_Black_Cnt  \\\n",
       "0                    1.0  ...               67.0                 27.0   \n",
       "1                    1.0  ...              130.0                 81.0   \n",
       "2                    1.0  ...               41.0                  0.0   \n",
       "3                    1.0  ...               12.0                  0.0   \n",
       "4                    1.0  ...               12.0                  0.0   \n",
       "...                  ...  ...                ...                  ...   \n",
       "2509385              1.0  ...              236.0                 41.0   \n",
       "2509386              1.0  ...              393.0                 66.0   \n",
       "2509387              1.0  ...               33.0                  0.0   \n",
       "2509388              1.0  ...               53.0                 18.0   \n",
       "2509389              1.0  ...               12.0                  0.0   \n",
       "\n",
       "         Bene_Race_Api_Cnt  Bene_Race_Hspnc_Cnt  Bene_Race_Natind_Cnt  \\\n",
       "0                      0.0                 13.0                   0.0   \n",
       "1                      0.0                 12.0                   0.0   \n",
       "2                      0.0                  0.0                   0.0   \n",
       "3                      0.0                  0.0                   0.0   \n",
       "4                      0.0                  0.0                   0.0   \n",
       "...                    ...                  ...                   ...   \n",
       "2509385                0.0                 22.0                   0.0   \n",
       "2509386               13.0                 32.0                   0.0   \n",
       "2509387                0.0                  0.0                   0.0   \n",
       "2509388               14.0                 42.0                   0.0   \n",
       "2509389                0.0                  0.0                   0.0   \n",
       "\n",
       "         Bene_Race_Othr_Cnt  Bene_Dual_Cnt  Bene_Ndual_Cnt  \\\n",
       "0                       0.0           28.0            78.0   \n",
       "1                       0.0          125.0           103.0   \n",
       "2                       0.0            0.0            43.0   \n",
       "3                       0.0            0.0            12.0   \n",
       "4                       0.0           11.0            11.0   \n",
       "...                     ...            ...             ...   \n",
       "2509385                13.0           60.0           252.0   \n",
       "2509386                17.0          233.0           211.0   \n",
       "2509387                 0.0           12.0            21.0   \n",
       "2509388                19.0           80.0            54.0   \n",
       "2509389                 0.0            0.0            11.0   \n",
       "\n",
       "         Bene_Avg_Risk_Scre  Fraud  \n",
       "0                  2.245800      0  \n",
       "1                  1.695165      0  \n",
       "2                  1.006070      0  \n",
       "3                  1.251869      0  \n",
       "4                  4.919074      0  \n",
       "...                     ...    ...  \n",
       "2509385            1.169697      1  \n",
       "2509386            1.369505      1  \n",
       "2509387            2.111492      1  \n",
       "2509388            1.624990      1  \n",
       "2509389            1.171146      1  \n",
       "\n",
       "[2509390 rows x 71 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6684962\ttotal: 3s\tremaining: 24m 56s\n",
      "1:\tlearn: 0.6476746\ttotal: 5.94s\tremaining: 24m 40s\n",
      "2:\tlearn: 0.6284672\ttotal: 8.55s\tremaining: 23m 36s\n",
      "3:\tlearn: 0.6095824\ttotal: 11.3s\tremaining: 23m 21s\n",
      "4:\tlearn: 0.5920936\ttotal: 14.1s\tremaining: 23m 15s\n",
      "5:\tlearn: 0.5752369\ttotal: 16.9s\tremaining: 23m 14s\n",
      "6:\tlearn: 0.5587521\ttotal: 19.8s\tremaining: 23m 17s\n",
      "7:\tlearn: 0.5435766\ttotal: 22.6s\tremaining: 23m 7s\n",
      "8:\tlearn: 0.5301650\ttotal: 25.3s\tremaining: 23m 1s\n",
      "9:\tlearn: 0.5156660\ttotal: 28.1s\tremaining: 22m 57s\n",
      "10:\tlearn: 0.5023003\ttotal: 30.8s\tremaining: 22m 50s\n",
      "11:\tlearn: 0.4908825\ttotal: 33.7s\tremaining: 22m 51s\n",
      "12:\tlearn: 0.4808997\ttotal: 36.5s\tremaining: 22m 48s\n",
      "13:\tlearn: 0.4703135\ttotal: 39.2s\tremaining: 22m 42s\n",
      "14:\tlearn: 0.4595995\ttotal: 42.2s\tremaining: 22m 43s\n",
      "15:\tlearn: 0.4498469\ttotal: 44.9s\tremaining: 22m 39s\n",
      "16:\tlearn: 0.4400028\ttotal: 47.8s\tremaining: 22m 38s\n",
      "17:\tlearn: 0.4299621\ttotal: 50.5s\tremaining: 22m 32s\n",
      "18:\tlearn: 0.4221375\ttotal: 53.5s\tremaining: 22m 33s\n",
      "19:\tlearn: 0.4104361\ttotal: 56.4s\tremaining: 22m 34s\n",
      "20:\tlearn: 0.4008078\ttotal: 59.4s\tremaining: 22m 34s\n",
      "21:\tlearn: 0.3902886\ttotal: 1m 2s\tremaining: 22m 33s\n",
      "22:\tlearn: 0.3829557\ttotal: 1m 5s\tremaining: 22m 34s\n",
      "23:\tlearn: 0.3750926\ttotal: 1m 8s\tremaining: 22m 31s\n",
      "24:\tlearn: 0.3683848\ttotal: 1m 11s\tremaining: 22m 30s\n",
      "25:\tlearn: 0.3606152\ttotal: 1m 13s\tremaining: 22m 26s\n",
      "26:\tlearn: 0.3536089\ttotal: 1m 16s\tremaining: 22m 23s\n",
      "27:\tlearn: 0.3471473\ttotal: 1m 19s\tremaining: 22m 21s\n",
      "28:\tlearn: 0.3418188\ttotal: 1m 22s\tremaining: 22m 19s\n",
      "29:\tlearn: 0.3350541\ttotal: 1m 25s\tremaining: 22m 15s\n",
      "30:\tlearn: 0.3284291\ttotal: 1m 28s\tremaining: 22m 14s\n",
      "31:\tlearn: 0.3219210\ttotal: 1m 31s\tremaining: 22m 13s\n",
      "32:\tlearn: 0.3161597\ttotal: 1m 34s\tremaining: 22m 10s\n",
      "33:\tlearn: 0.3118795\ttotal: 1m 37s\tremaining: 22m 11s\n",
      "34:\tlearn: 0.3076056\ttotal: 1m 39s\tremaining: 22m 7s\n",
      "35:\tlearn: 0.3034517\ttotal: 1m 42s\tremaining: 22m 6s\n",
      "36:\tlearn: 0.2993604\ttotal: 1m 46s\tremaining: 22m 6s\n",
      "37:\tlearn: 0.2944723\ttotal: 1m 48s\tremaining: 22m 4s\n",
      "38:\tlearn: 0.2894558\ttotal: 1m 52s\tremaining: 22m 4s\n",
      "39:\tlearn: 0.2849421\ttotal: 1m 55s\tremaining: 22m 5s\n",
      "40:\tlearn: 0.2796057\ttotal: 1m 58s\tremaining: 22m 3s\n",
      "41:\tlearn: 0.2755738\ttotal: 2m 1s\tremaining: 21m 59s\n",
      "42:\tlearn: 0.2719491\ttotal: 2m 3s\tremaining: 21m 57s\n",
      "43:\tlearn: 0.2669845\ttotal: 2m 7s\tremaining: 21m 56s\n",
      "44:\tlearn: 0.2619798\ttotal: 2m 10s\tremaining: 21m 55s\n",
      "45:\tlearn: 0.2586989\ttotal: 2m 13s\tremaining: 21m 54s\n",
      "46:\tlearn: 0.2553920\ttotal: 2m 16s\tremaining: 21m 52s\n",
      "47:\tlearn: 0.2518786\ttotal: 2m 19s\tremaining: 21m 51s\n",
      "48:\tlearn: 0.2482688\ttotal: 2m 22s\tremaining: 21m 47s\n",
      "49:\tlearn: 0.2449012\ttotal: 2m 25s\tremaining: 21m 47s\n",
      "50:\tlearn: 0.2425345\ttotal: 2m 28s\tremaining: 21m 48s\n",
      "51:\tlearn: 0.2391254\ttotal: 2m 31s\tremaining: 21m 44s\n",
      "52:\tlearn: 0.2363810\ttotal: 2m 34s\tremaining: 21m 42s\n",
      "53:\tlearn: 0.2331143\ttotal: 2m 37s\tremaining: 21m 39s\n",
      "54:\tlearn: 0.2303210\ttotal: 2m 40s\tremaining: 21m 37s\n",
      "55:\tlearn: 0.2277425\ttotal: 2m 43s\tremaining: 21m 38s\n",
      "56:\tlearn: 0.2248821\ttotal: 2m 46s\tremaining: 21m 34s\n",
      "57:\tlearn: 0.2216431\ttotal: 2m 49s\tremaining: 21m 33s\n",
      "58:\tlearn: 0.2188378\ttotal: 2m 52s\tremaining: 21m 30s\n",
      "59:\tlearn: 0.2161509\ttotal: 2m 55s\tremaining: 21m 27s\n",
      "60:\tlearn: 0.2139626\ttotal: 2m 58s\tremaining: 21m 26s\n",
      "61:\tlearn: 0.2112929\ttotal: 3m 1s\tremaining: 21m 24s\n",
      "62:\tlearn: 0.2084205\ttotal: 3m 4s\tremaining: 21m 21s\n",
      "63:\tlearn: 0.2052525\ttotal: 3m 7s\tremaining: 21m 17s\n",
      "64:\tlearn: 0.2024695\ttotal: 3m 10s\tremaining: 21m 16s\n",
      "65:\tlearn: 0.2005318\ttotal: 3m 14s\tremaining: 21m 15s\n",
      "66:\tlearn: 0.1982601\ttotal: 3m 17s\tremaining: 21m 13s\n",
      "67:\tlearn: 0.1958261\ttotal: 3m 19s\tremaining: 21m 10s\n",
      "68:\tlearn: 0.1936496\ttotal: 3m 23s\tremaining: 21m 9s\n",
      "69:\tlearn: 0.1913960\ttotal: 3m 26s\tremaining: 21m 5s\n",
      "70:\tlearn: 0.1890340\ttotal: 3m 29s\tremaining: 21m 2s\n",
      "71:\tlearn: 0.1868637\ttotal: 3m 32s\tremaining: 21m\n",
      "72:\tlearn: 0.1840320\ttotal: 3m 35s\tremaining: 20m 58s\n",
      "73:\tlearn: 0.1823262\ttotal: 3m 38s\tremaining: 20m 57s\n",
      "74:\tlearn: 0.1802865\ttotal: 3m 41s\tremaining: 20m 54s\n",
      "75:\tlearn: 0.1777918\ttotal: 3m 44s\tremaining: 20m 51s\n",
      "76:\tlearn: 0.1760219\ttotal: 3m 47s\tremaining: 20m 48s\n",
      "77:\tlearn: 0.1738560\ttotal: 3m 49s\tremaining: 20m 41s\n",
      "78:\tlearn: 0.1713503\ttotal: 3m 51s\tremaining: 20m 33s\n",
      "79:\tlearn: 0.1694581\ttotal: 3m 53s\tremaining: 20m 27s\n",
      "80:\tlearn: 0.1671559\ttotal: 3m 55s\tremaining: 20m 20s\n",
      "81:\tlearn: 0.1646385\ttotal: 3m 58s\tremaining: 20m 13s\n",
      "82:\tlearn: 0.1632900\ttotal: 4m\tremaining: 20m 8s\n",
      "83:\tlearn: 0.1615523\ttotal: 4m 2s\tremaining: 20m 2s\n",
      "84:\tlearn: 0.1598776\ttotal: 4m 5s\tremaining: 19m 56s\n",
      "85:\tlearn: 0.1574729\ttotal: 4m 7s\tremaining: 19m 50s\n",
      "86:\tlearn: 0.1560572\ttotal: 4m 9s\tremaining: 19m 45s\n",
      "87:\tlearn: 0.1537937\ttotal: 4m 12s\tremaining: 19m 40s\n",
      "88:\tlearn: 0.1521920\ttotal: 4m 14s\tremaining: 19m 37s\n",
      "89:\tlearn: 0.1495310\ttotal: 4m 18s\tremaining: 19m 35s\n",
      "90:\tlearn: 0.1485810\ttotal: 4m 21s\tremaining: 19m 35s\n",
      "91:\tlearn: 0.1471724\ttotal: 4m 24s\tremaining: 19m 33s\n",
      "92:\tlearn: 0.1456681\ttotal: 4m 27s\tremaining: 19m 31s\n",
      "93:\tlearn: 0.1446541\ttotal: 4m 30s\tremaining: 19m 29s\n",
      "94:\tlearn: 0.1429443\ttotal: 4m 33s\tremaining: 19m 27s\n",
      "95:\tlearn: 0.1410438\ttotal: 4m 36s\tremaining: 19m 24s\n",
      "96:\tlearn: 0.1392352\ttotal: 4m 39s\tremaining: 19m 23s\n",
      "97:\tlearn: 0.1375490\ttotal: 4m 42s\tremaining: 19m 20s\n",
      "98:\tlearn: 0.1361221\ttotal: 4m 46s\tremaining: 19m 18s\n",
      "99:\tlearn: 0.1346505\ttotal: 4m 49s\tremaining: 19m 16s\n",
      "100:\tlearn: 0.1328044\ttotal: 4m 52s\tremaining: 19m 14s\n",
      "101:\tlearn: 0.1310356\ttotal: 4m 55s\tremaining: 19m 11s\n",
      "102:\tlearn: 0.1299229\ttotal: 4m 58s\tremaining: 19m 8s\n",
      "103:\tlearn: 0.1288579\ttotal: 5m 1s\tremaining: 19m 6s\n",
      "104:\tlearn: 0.1271397\ttotal: 5m 4s\tremaining: 19m 4s\n",
      "105:\tlearn: 0.1261206\ttotal: 5m 6s\tremaining: 19m\n",
      "106:\tlearn: 0.1253893\ttotal: 5m 10s\tremaining: 18m 59s\n",
      "107:\tlearn: 0.1240279\ttotal: 5m 13s\tremaining: 18m 56s\n",
      "108:\tlearn: 0.1230492\ttotal: 5m 16s\tremaining: 18m 54s\n",
      "109:\tlearn: 0.1215312\ttotal: 5m 19s\tremaining: 18m 52s\n",
      "110:\tlearn: 0.1203228\ttotal: 5m 22s\tremaining: 18m 50s\n",
      "111:\tlearn: 0.1188335\ttotal: 5m 25s\tremaining: 18m 48s\n",
      "112:\tlearn: 0.1175126\ttotal: 5m 28s\tremaining: 18m 45s\n",
      "113:\tlearn: 0.1167465\ttotal: 5m 31s\tremaining: 18m 43s\n",
      "114:\tlearn: 0.1157226\ttotal: 5m 34s\tremaining: 18m 41s\n",
      "115:\tlearn: 0.1144159\ttotal: 5m 38s\tremaining: 18m 39s\n",
      "116:\tlearn: 0.1133796\ttotal: 5m 41s\tremaining: 18m 36s\n",
      "117:\tlearn: 0.1121445\ttotal: 5m 44s\tremaining: 18m 33s\n",
      "118:\tlearn: 0.1109898\ttotal: 5m 47s\tremaining: 18m 31s\n",
      "119:\tlearn: 0.1098575\ttotal: 5m 50s\tremaining: 18m 29s\n",
      "120:\tlearn: 0.1089757\ttotal: 5m 53s\tremaining: 18m 27s\n",
      "121:\tlearn: 0.1080377\ttotal: 5m 56s\tremaining: 18m 25s\n",
      "122:\tlearn: 0.1064766\ttotal: 5m 59s\tremaining: 18m 23s\n",
      "123:\tlearn: 0.1057234\ttotal: 6m 3s\tremaining: 18m 21s\n",
      "124:\tlearn: 0.1047471\ttotal: 6m 6s\tremaining: 18m 18s\n",
      "125:\tlearn: 0.1033487\ttotal: 6m 9s\tremaining: 18m 15s\n",
      "126:\tlearn: 0.1018604\ttotal: 6m 12s\tremaining: 18m 12s\n",
      "127:\tlearn: 0.1010971\ttotal: 6m 15s\tremaining: 18m 10s\n",
      "128:\tlearn: 0.0997773\ttotal: 6m 18s\tremaining: 18m 8s\n",
      "129:\tlearn: 0.0988858\ttotal: 6m 21s\tremaining: 18m 5s\n",
      "130:\tlearn: 0.0982270\ttotal: 6m 24s\tremaining: 18m 3s\n",
      "131:\tlearn: 0.0971869\ttotal: 6m 27s\tremaining: 18m\n",
      "132:\tlearn: 0.0961303\ttotal: 6m 30s\tremaining: 17m 58s\n",
      "133:\tlearn: 0.0951039\ttotal: 6m 33s\tremaining: 17m 55s\n",
      "134:\tlearn: 0.0934492\ttotal: 6m 36s\tremaining: 17m 52s\n",
      "135:\tlearn: 0.0928323\ttotal: 6m 39s\tremaining: 17m 50s\n",
      "136:\tlearn: 0.0920277\ttotal: 6m 42s\tremaining: 17m 47s\n",
      "137:\tlearn: 0.0912668\ttotal: 6m 46s\tremaining: 17m 45s\n",
      "138:\tlearn: 0.0903435\ttotal: 6m 49s\tremaining: 17m 42s\n",
      "139:\tlearn: 0.0895911\ttotal: 6m 52s\tremaining: 17m 40s\n",
      "140:\tlearn: 0.0883956\ttotal: 6m 55s\tremaining: 17m 37s\n",
      "141:\tlearn: 0.0878907\ttotal: 6m 58s\tremaining: 17m 35s\n",
      "142:\tlearn: 0.0870018\ttotal: 7m 1s\tremaining: 17m 33s\n",
      "143:\tlearn: 0.0858851\ttotal: 7m 4s\tremaining: 17m 30s\n",
      "144:\tlearn: 0.0849122\ttotal: 7m 7s\tremaining: 17m 27s\n",
      "145:\tlearn: 0.0841675\ttotal: 7m 10s\tremaining: 17m 24s\n",
      "146:\tlearn: 0.0832713\ttotal: 7m 13s\tremaining: 17m 21s\n",
      "147:\tlearn: 0.0828066\ttotal: 7m 17s\tremaining: 17m 19s\n",
      "148:\tlearn: 0.0819418\ttotal: 7m 20s\tremaining: 17m 16s\n",
      "149:\tlearn: 0.0809423\ttotal: 7m 22s\tremaining: 17m 13s\n",
      "150:\tlearn: 0.0803568\ttotal: 7m 26s\tremaining: 17m 10s\n",
      "151:\tlearn: 0.0795297\ttotal: 7m 29s\tremaining: 17m 8s\n",
      "152:\tlearn: 0.0790827\ttotal: 7m 32s\tremaining: 17m 5s\n",
      "153:\tlearn: 0.0783429\ttotal: 7m 35s\tremaining: 17m 3s\n",
      "154:\tlearn: 0.0779713\ttotal: 7m 38s\tremaining: 17m 1s\n",
      "155:\tlearn: 0.0772369\ttotal: 7m 41s\tremaining: 16m 58s\n",
      "156:\tlearn: 0.0762490\ttotal: 7m 44s\tremaining: 16m 55s\n",
      "157:\tlearn: 0.0756964\ttotal: 7m 47s\tremaining: 16m 52s\n",
      "158:\tlearn: 0.0746384\ttotal: 7m 50s\tremaining: 16m 49s\n",
      "159:\tlearn: 0.0738417\ttotal: 7m 53s\tremaining: 16m 46s\n",
      "160:\tlearn: 0.0731403\ttotal: 7m 56s\tremaining: 16m 43s\n",
      "161:\tlearn: 0.0727166\ttotal: 7m 59s\tremaining: 16m 40s\n",
      "162:\tlearn: 0.0720278\ttotal: 8m 2s\tremaining: 16m 38s\n",
      "163:\tlearn: 0.0714898\ttotal: 8m 6s\tremaining: 16m 36s\n",
      "164:\tlearn: 0.0709097\ttotal: 8m 9s\tremaining: 16m 33s\n",
      "165:\tlearn: 0.0700426\ttotal: 8m 12s\tremaining: 16m 30s\n",
      "166:\tlearn: 0.0693692\ttotal: 8m 15s\tremaining: 16m 27s\n",
      "167:\tlearn: 0.0687956\ttotal: 8m 18s\tremaining: 16m 24s\n",
      "168:\tlearn: 0.0682467\ttotal: 8m 21s\tremaining: 16m 22s\n",
      "169:\tlearn: 0.0676219\ttotal: 8m 24s\tremaining: 16m 19s\n",
      "170:\tlearn: 0.0669177\ttotal: 8m 27s\tremaining: 16m 16s\n",
      "171:\tlearn: 0.0664956\ttotal: 8m 31s\tremaining: 16m 14s\n",
      "172:\tlearn: 0.0656399\ttotal: 8m 33s\tremaining: 16m 11s\n",
      "173:\tlearn: 0.0651622\ttotal: 8m 36s\tremaining: 16m 8s\n",
      "174:\tlearn: 0.0645749\ttotal: 8m 39s\tremaining: 16m 5s\n",
      "175:\tlearn: 0.0642002\ttotal: 8m 43s\tremaining: 16m 2s\n",
      "176:\tlearn: 0.0633123\ttotal: 8m 45s\tremaining: 15m 59s\n",
      "177:\tlearn: 0.0628839\ttotal: 8m 49s\tremaining: 15m 57s\n",
      "178:\tlearn: 0.0621840\ttotal: 8m 52s\tremaining: 15m 54s\n",
      "179:\tlearn: 0.0619196\ttotal: 8m 55s\tremaining: 15m 52s\n",
      "180:\tlearn: 0.0613627\ttotal: 8m 59s\tremaining: 15m 49s\n",
      "181:\tlearn: 0.0608512\ttotal: 9m 1s\tremaining: 15m 47s\n",
      "182:\tlearn: 0.0601679\ttotal: 9m 5s\tremaining: 15m 44s\n",
      "183:\tlearn: 0.0594563\ttotal: 9m 7s\tremaining: 15m 40s\n",
      "184:\tlearn: 0.0589152\ttotal: 9m 11s\tremaining: 15m 38s\n",
      "185:\tlearn: 0.0583343\ttotal: 9m 14s\tremaining: 15m 35s\n",
      "186:\tlearn: 0.0580636\ttotal: 9m 17s\tremaining: 15m 33s\n",
      "187:\tlearn: 0.0576654\ttotal: 9m 20s\tremaining: 15m 30s\n",
      "188:\tlearn: 0.0570958\ttotal: 9m 23s\tremaining: 15m 27s\n",
      "189:\tlearn: 0.0567955\ttotal: 9m 26s\tremaining: 15m 24s\n",
      "190:\tlearn: 0.0564176\ttotal: 9m 30s\tremaining: 15m 22s\n",
      "191:\tlearn: 0.0560851\ttotal: 9m 33s\tremaining: 15m 20s\n",
      "192:\tlearn: 0.0555522\ttotal: 9m 36s\tremaining: 15m 17s\n",
      "193:\tlearn: 0.0549109\ttotal: 9m 39s\tremaining: 15m 13s\n",
      "194:\tlearn: 0.0542103\ttotal: 9m 42s\tremaining: 15m 10s\n",
      "195:\tlearn: 0.0537720\ttotal: 9m 45s\tremaining: 15m 8s\n",
      "196:\tlearn: 0.0531344\ttotal: 9m 48s\tremaining: 15m 5s\n",
      "197:\tlearn: 0.0528197\ttotal: 9m 51s\tremaining: 15m 2s\n",
      "198:\tlearn: 0.0524881\ttotal: 9m 55s\tremaining: 15m\n",
      "199:\tlearn: 0.0519609\ttotal: 9m 58s\tremaining: 14m 57s\n",
      "200:\tlearn: 0.0514715\ttotal: 10m 1s\tremaining: 14m 54s\n",
      "201:\tlearn: 0.0508711\ttotal: 10m 4s\tremaining: 14m 51s\n",
      "202:\tlearn: 0.0504034\ttotal: 10m 7s\tremaining: 14m 48s\n",
      "203:\tlearn: 0.0498305\ttotal: 10m 10s\tremaining: 14m 45s\n",
      "204:\tlearn: 0.0493693\ttotal: 10m 13s\tremaining: 14m 42s\n",
      "205:\tlearn: 0.0489838\ttotal: 10m 16s\tremaining: 14m 40s\n",
      "206:\tlearn: 0.0484583\ttotal: 10m 19s\tremaining: 14m 37s\n",
      "207:\tlearn: 0.0482308\ttotal: 10m 23s\tremaining: 14m 34s\n",
      "208:\tlearn: 0.0478096\ttotal: 10m 26s\tremaining: 14m 31s\n",
      "209:\tlearn: 0.0472301\ttotal: 10m 29s\tremaining: 14m 28s\n",
      "210:\tlearn: 0.0466945\ttotal: 10m 32s\tremaining: 14m 25s\n",
      "211:\tlearn: 0.0462552\ttotal: 10m 35s\tremaining: 14m 23s\n",
      "212:\tlearn: 0.0460358\ttotal: 10m 38s\tremaining: 14m 20s\n",
      "213:\tlearn: 0.0457495\ttotal: 10m 41s\tremaining: 14m 17s\n",
      "214:\tlearn: 0.0455288\ttotal: 10m 45s\tremaining: 14m 15s\n",
      "215:\tlearn: 0.0450315\ttotal: 10m 47s\tremaining: 14m 11s\n",
      "216:\tlearn: 0.0446010\ttotal: 10m 50s\tremaining: 14m 8s\n",
      "217:\tlearn: 0.0442686\ttotal: 10m 54s\tremaining: 14m 6s\n",
      "218:\tlearn: 0.0436176\ttotal: 10m 57s\tremaining: 14m 3s\n",
      "219:\tlearn: 0.0431752\ttotal: 11m\tremaining: 14m\n",
      "220:\tlearn: 0.0425941\ttotal: 11m 3s\tremaining: 13m 57s\n",
      "221:\tlearn: 0.0420975\ttotal: 11m 6s\tremaining: 13m 55s\n",
      "222:\tlearn: 0.0414680\ttotal: 11m 9s\tremaining: 13m 52s\n",
      "223:\tlearn: 0.0410641\ttotal: 11m 12s\tremaining: 13m 49s\n",
      "224:\tlearn: 0.0407968\ttotal: 11m 16s\tremaining: 13m 46s\n",
      "225:\tlearn: 0.0405857\ttotal: 11m 19s\tremaining: 13m 43s\n",
      "226:\tlearn: 0.0399658\ttotal: 11m 22s\tremaining: 13m 40s\n",
      "227:\tlearn: 0.0396630\ttotal: 11m 25s\tremaining: 13m 37s\n",
      "228:\tlearn: 0.0394594\ttotal: 11m 28s\tremaining: 13m 35s\n",
      "229:\tlearn: 0.0390585\ttotal: 11m 31s\tremaining: 13m 32s\n",
      "230:\tlearn: 0.0387137\ttotal: 11m 35s\tremaining: 13m 29s\n",
      "231:\tlearn: 0.0382589\ttotal: 11m 38s\tremaining: 13m 26s\n",
      "232:\tlearn: 0.0378601\ttotal: 11m 40s\tremaining: 13m 22s\n",
      "233:\tlearn: 0.0376551\ttotal: 11m 42s\tremaining: 13m 18s\n",
      "234:\tlearn: 0.0371859\ttotal: 11m 44s\tremaining: 13m 14s\n",
      "235:\tlearn: 0.0368637\ttotal: 11m 47s\tremaining: 13m 10s\n",
      "236:\tlearn: 0.0365028\ttotal: 11m 49s\tremaining: 13m 7s\n",
      "237:\tlearn: 0.0363236\ttotal: 11m 51s\tremaining: 13m 3s\n",
      "238:\tlearn: 0.0359211\ttotal: 11m 53s\tremaining: 12m 59s\n",
      "239:\tlearn: 0.0355443\ttotal: 11m 55s\tremaining: 12m 55s\n",
      "240:\tlearn: 0.0353324\ttotal: 11m 58s\tremaining: 12m 51s\n",
      "241:\tlearn: 0.0350719\ttotal: 12m\tremaining: 12m 47s\n",
      "242:\tlearn: 0.0348829\ttotal: 12m 2s\tremaining: 12m 44s\n",
      "243:\tlearn: 0.0347735\ttotal: 12m 4s\tremaining: 12m 40s\n",
      "244:\tlearn: 0.0343830\ttotal: 12m 6s\tremaining: 12m 36s\n",
      "245:\tlearn: 0.0340826\ttotal: 12m 8s\tremaining: 12m 32s\n",
      "246:\tlearn: 0.0337451\ttotal: 12m 10s\tremaining: 12m 28s\n",
      "247:\tlearn: 0.0334721\ttotal: 12m 13s\tremaining: 12m 24s\n",
      "248:\tlearn: 0.0333152\ttotal: 12m 15s\tremaining: 12m 21s\n",
      "249:\tlearn: 0.0330238\ttotal: 12m 17s\tremaining: 12m 17s\n",
      "250:\tlearn: 0.0326196\ttotal: 12m 20s\tremaining: 12m 14s\n",
      "251:\tlearn: 0.0321866\ttotal: 12m 22s\tremaining: 12m 10s\n",
      "252:\tlearn: 0.0318228\ttotal: 12m 25s\tremaining: 12m 8s\n",
      "253:\tlearn: 0.0316624\ttotal: 12m 29s\tremaining: 12m 5s\n",
      "254:\tlearn: 0.0313740\ttotal: 12m 32s\tremaining: 12m 2s\n",
      "255:\tlearn: 0.0311093\ttotal: 12m 35s\tremaining: 12m\n",
      "256:\tlearn: 0.0308663\ttotal: 12m 38s\tremaining: 11m 57s\n",
      "257:\tlearn: 0.0303949\ttotal: 12m 41s\tremaining: 11m 54s\n",
      "258:\tlearn: 0.0301392\ttotal: 12m 44s\tremaining: 11m 51s\n",
      "259:\tlearn: 0.0299618\ttotal: 12m 48s\tremaining: 11m 49s\n",
      "260:\tlearn: 0.0297236\ttotal: 12m 51s\tremaining: 11m 46s\n",
      "261:\tlearn: 0.0295685\ttotal: 12m 54s\tremaining: 11m 43s\n",
      "262:\tlearn: 0.0292302\ttotal: 12m 57s\tremaining: 11m 40s\n",
      "263:\tlearn: 0.0289406\ttotal: 13m\tremaining: 11m 37s\n",
      "264:\tlearn: 0.0286908\ttotal: 13m 3s\tremaining: 11m 35s\n",
      "265:\tlearn: 0.0285693\ttotal: 13m 7s\tremaining: 11m 32s\n",
      "266:\tlearn: 0.0282829\ttotal: 13m 10s\tremaining: 11m 29s\n",
      "267:\tlearn: 0.0280984\ttotal: 13m 13s\tremaining: 11m 27s\n",
      "268:\tlearn: 0.0278409\ttotal: 13m 16s\tremaining: 11m 24s\n",
      "269:\tlearn: 0.0276986\ttotal: 13m 20s\tremaining: 11m 21s\n",
      "270:\tlearn: 0.0273304\ttotal: 13m 23s\tremaining: 11m 18s\n",
      "271:\tlearn: 0.0270117\ttotal: 13m 26s\tremaining: 11m 15s\n",
      "272:\tlearn: 0.0269115\ttotal: 13m 29s\tremaining: 11m 13s\n",
      "273:\tlearn: 0.0267030\ttotal: 13m 32s\tremaining: 11m 10s\n",
      "274:\tlearn: 0.0264097\ttotal: 13m 35s\tremaining: 11m 7s\n",
      "275:\tlearn: 0.0261432\ttotal: 13m 38s\tremaining: 11m 4s\n",
      "276:\tlearn: 0.0259382\ttotal: 13m 42s\tremaining: 11m 1s\n",
      "277:\tlearn: 0.0257170\ttotal: 13m 45s\tremaining: 10m 58s\n",
      "278:\tlearn: 0.0255051\ttotal: 13m 48s\tremaining: 10m 56s\n",
      "279:\tlearn: 0.0251496\ttotal: 13m 51s\tremaining: 10m 53s\n",
      "280:\tlearn: 0.0248814\ttotal: 13m 54s\tremaining: 10m 50s\n",
      "281:\tlearn: 0.0246638\ttotal: 13m 57s\tremaining: 10m 47s\n",
      "282:\tlearn: 0.0245568\ttotal: 14m\tremaining: 10m 44s\n",
      "283:\tlearn: 0.0243352\ttotal: 14m 2s\tremaining: 10m 40s\n",
      "284:\tlearn: 0.0242103\ttotal: 14m 5s\tremaining: 10m 37s\n",
      "285:\tlearn: 0.0241259\ttotal: 14m 7s\tremaining: 10m 34s\n",
      "286:\tlearn: 0.0239350\ttotal: 14m 9s\tremaining: 10m 30s\n",
      "287:\tlearn: 0.0237670\ttotal: 14m 11s\tremaining: 10m 26s\n",
      "288:\tlearn: 0.0234847\ttotal: 14m 13s\tremaining: 10m 23s\n",
      "289:\tlearn: 0.0233385\ttotal: 14m 15s\tremaining: 10m 19s\n",
      "290:\tlearn: 0.0232322\ttotal: 14m 17s\tremaining: 10m 16s\n",
      "291:\tlearn: 0.0229623\ttotal: 14m 19s\tremaining: 10m 12s\n",
      "292:\tlearn: 0.0228038\ttotal: 14m 21s\tremaining: 10m 8s\n",
      "293:\tlearn: 0.0227121\ttotal: 14m 23s\tremaining: 10m 5s\n",
      "294:\tlearn: 0.0225266\ttotal: 14m 25s\tremaining: 10m 1s\n",
      "295:\tlearn: 0.0223512\ttotal: 14m 27s\tremaining: 9m 58s\n",
      "296:\tlearn: 0.0222421\ttotal: 14m 30s\tremaining: 9m 54s\n",
      "297:\tlearn: 0.0220822\ttotal: 14m 32s\tremaining: 9m 51s\n",
      "298:\tlearn: 0.0218800\ttotal: 14m 34s\tremaining: 9m 47s\n",
      "299:\tlearn: 0.0217287\ttotal: 14m 36s\tremaining: 9m 44s\n",
      "300:\tlearn: 0.0216296\ttotal: 14m 38s\tremaining: 9m 40s\n",
      "301:\tlearn: 0.0214481\ttotal: 14m 40s\tremaining: 9m 37s\n",
      "302:\tlearn: 0.0212534\ttotal: 14m 42s\tremaining: 9m 33s\n",
      "303:\tlearn: 0.0210779\ttotal: 14m 44s\tremaining: 9m 30s\n",
      "304:\tlearn: 0.0208500\ttotal: 14m 46s\tremaining: 9m 26s\n",
      "305:\tlearn: 0.0207443\ttotal: 14m 49s\tremaining: 9m 23s\n",
      "306:\tlearn: 0.0205880\ttotal: 14m 51s\tremaining: 9m 20s\n",
      "307:\tlearn: 0.0204857\ttotal: 14m 53s\tremaining: 9m 16s\n",
      "308:\tlearn: 0.0203247\ttotal: 14m 55s\tremaining: 9m 13s\n",
      "309:\tlearn: 0.0201432\ttotal: 14m 57s\tremaining: 9m 10s\n",
      "310:\tlearn: 0.0199843\ttotal: 14m 59s\tremaining: 9m 6s\n",
      "311:\tlearn: 0.0198358\ttotal: 15m 1s\tremaining: 9m 3s\n",
      "312:\tlearn: 0.0197852\ttotal: 15m 4s\tremaining: 9m\n",
      "313:\tlearn: 0.0196240\ttotal: 15m 6s\tremaining: 8m 56s\n",
      "314:\tlearn: 0.0194240\ttotal: 15m 8s\tremaining: 8m 53s\n",
      "315:\tlearn: 0.0192680\ttotal: 15m 10s\tremaining: 8m 49s\n",
      "316:\tlearn: 0.0191420\ttotal: 15m 12s\tremaining: 8m 46s\n",
      "317:\tlearn: 0.0191028\ttotal: 15m 14s\tremaining: 8m 43s\n",
      "318:\tlearn: 0.0190024\ttotal: 15m 16s\tremaining: 8m 39s\n",
      "319:\tlearn: 0.0188452\ttotal: 15m 18s\tremaining: 8m 36s\n",
      "320:\tlearn: 0.0187651\ttotal: 15m 20s\tremaining: 8m 33s\n",
      "321:\tlearn: 0.0186039\ttotal: 15m 22s\tremaining: 8m 30s\n",
      "322:\tlearn: 0.0185325\ttotal: 15m 25s\tremaining: 8m 26s\n",
      "323:\tlearn: 0.0184027\ttotal: 15m 27s\tremaining: 8m 23s\n",
      "324:\tlearn: 0.0182420\ttotal: 15m 29s\tremaining: 8m 20s\n",
      "325:\tlearn: 0.0181048\ttotal: 15m 31s\tremaining: 8m 17s\n",
      "326:\tlearn: 0.0179004\ttotal: 15m 33s\tremaining: 8m 13s\n",
      "327:\tlearn: 0.0177500\ttotal: 15m 35s\tremaining: 8m 10s\n",
      "328:\tlearn: 0.0175079\ttotal: 15m 37s\tremaining: 8m 7s\n",
      "329:\tlearn: 0.0174151\ttotal: 15m 39s\tremaining: 8m 4s\n",
      "330:\tlearn: 0.0172598\ttotal: 15m 41s\tremaining: 8m\n",
      "331:\tlearn: 0.0171150\ttotal: 15m 43s\tremaining: 7m 57s\n",
      "332:\tlearn: 0.0170409\ttotal: 15m 45s\tremaining: 7m 54s\n",
      "333:\tlearn: 0.0169085\ttotal: 15m 47s\tremaining: 7m 51s\n",
      "334:\tlearn: 0.0168137\ttotal: 15m 50s\tremaining: 7m 47s\n",
      "335:\tlearn: 0.0166638\ttotal: 15m 52s\tremaining: 7m 44s\n",
      "336:\tlearn: 0.0165245\ttotal: 15m 54s\tremaining: 7m 41s\n",
      "337:\tlearn: 0.0163475\ttotal: 15m 56s\tremaining: 7m 38s\n",
      "338:\tlearn: 0.0161662\ttotal: 15m 58s\tremaining: 7m 35s\n",
      "339:\tlearn: 0.0161305\ttotal: 16m\tremaining: 7m 32s\n",
      "340:\tlearn: 0.0160367\ttotal: 16m 2s\tremaining: 7m 28s\n",
      "341:\tlearn: 0.0159700\ttotal: 16m 4s\tremaining: 7m 25s\n",
      "342:\tlearn: 0.0157763\ttotal: 16m 7s\tremaining: 7m 22s\n",
      "343:\tlearn: 0.0156692\ttotal: 16m 9s\tremaining: 7m 19s\n",
      "344:\tlearn: 0.0156182\ttotal: 16m 11s\tremaining: 7m 16s\n",
      "345:\tlearn: 0.0154918\ttotal: 16m 13s\tremaining: 7m 13s\n",
      "346:\tlearn: 0.0153417\ttotal: 16m 15s\tremaining: 7m 9s\n",
      "347:\tlearn: 0.0151880\ttotal: 16m 17s\tremaining: 7m 6s\n",
      "348:\tlearn: 0.0150866\ttotal: 16m 19s\tremaining: 7m 3s\n",
      "349:\tlearn: 0.0149204\ttotal: 16m 21s\tremaining: 7m\n",
      "350:\tlearn: 0.0148021\ttotal: 16m 23s\tremaining: 6m 57s\n",
      "351:\tlearn: 0.0147254\ttotal: 16m 25s\tremaining: 6m 54s\n",
      "352:\tlearn: 0.0145469\ttotal: 16m 27s\tremaining: 6m 51s\n",
      "353:\tlearn: 0.0144728\ttotal: 16m 30s\tremaining: 6m 48s\n",
      "354:\tlearn: 0.0144082\ttotal: 16m 32s\tremaining: 6m 45s\n",
      "355:\tlearn: 0.0142253\ttotal: 16m 34s\tremaining: 6m 42s\n",
      "356:\tlearn: 0.0141692\ttotal: 16m 36s\tremaining: 6m 39s\n",
      "357:\tlearn: 0.0140293\ttotal: 16m 38s\tremaining: 6m 36s\n",
      "358:\tlearn: 0.0139958\ttotal: 16m 40s\tremaining: 6m 32s\n",
      "359:\tlearn: 0.0138398\ttotal: 16m 42s\tremaining: 6m 29s\n",
      "360:\tlearn: 0.0137133\ttotal: 16m 44s\tremaining: 6m 26s\n",
      "361:\tlearn: 0.0136246\ttotal: 16m 46s\tremaining: 6m 23s\n",
      "362:\tlearn: 0.0135205\ttotal: 16m 48s\tremaining: 6m 20s\n",
      "363:\tlearn: 0.0133271\ttotal: 16m 50s\tremaining: 6m 17s\n",
      "364:\tlearn: 0.0132634\ttotal: 16m 53s\tremaining: 6m 14s\n",
      "365:\tlearn: 0.0131628\ttotal: 16m 55s\tremaining: 6m 11s\n",
      "366:\tlearn: 0.0130606\ttotal: 16m 57s\tremaining: 6m 8s\n",
      "367:\tlearn: 0.0129822\ttotal: 16m 59s\tremaining: 6m 5s\n",
      "368:\tlearn: 0.0128316\ttotal: 17m 1s\tremaining: 6m 2s\n",
      "369:\tlearn: 0.0127525\ttotal: 17m 3s\tremaining: 5m 59s\n",
      "370:\tlearn: 0.0126324\ttotal: 17m 5s\tremaining: 5m 56s\n",
      "371:\tlearn: 0.0125192\ttotal: 17m 7s\tremaining: 5m 53s\n",
      "372:\tlearn: 0.0124280\ttotal: 17m 10s\tremaining: 5m 50s\n",
      "373:\tlearn: 0.0123361\ttotal: 17m 12s\tremaining: 5m 47s\n",
      "374:\tlearn: 0.0122590\ttotal: 17m 14s\tremaining: 5m 44s\n",
      "375:\tlearn: 0.0121942\ttotal: 17m 16s\tremaining: 5m 41s\n",
      "376:\tlearn: 0.0120923\ttotal: 17m 18s\tremaining: 5m 38s\n",
      "377:\tlearn: 0.0119937\ttotal: 17m 20s\tremaining: 5m 35s\n",
      "378:\tlearn: 0.0118678\ttotal: 17m 22s\tremaining: 5m 32s\n",
      "379:\tlearn: 0.0118043\ttotal: 17m 25s\tremaining: 5m 30s\n",
      "380:\tlearn: 0.0116682\ttotal: 17m 27s\tremaining: 5m 27s\n",
      "381:\tlearn: 0.0115806\ttotal: 17m 29s\tremaining: 5m 24s\n",
      "382:\tlearn: 0.0114827\ttotal: 17m 31s\tremaining: 5m 21s\n",
      "383:\tlearn: 0.0113897\ttotal: 17m 33s\tremaining: 5m 18s\n",
      "384:\tlearn: 0.0113314\ttotal: 17m 35s\tremaining: 5m 15s\n",
      "385:\tlearn: 0.0113038\ttotal: 17m 37s\tremaining: 5m 12s\n",
      "386:\tlearn: 0.0111824\ttotal: 17m 39s\tremaining: 5m 9s\n",
      "387:\tlearn: 0.0110894\ttotal: 17m 42s\tremaining: 5m 6s\n",
      "388:\tlearn: 0.0109583\ttotal: 17m 44s\tremaining: 5m 3s\n",
      "389:\tlearn: 0.0108881\ttotal: 17m 46s\tremaining: 5m\n",
      "390:\tlearn: 0.0107867\ttotal: 17m 48s\tremaining: 4m 57s\n",
      "391:\tlearn: 0.0107409\ttotal: 17m 50s\tremaining: 4m 54s\n",
      "392:\tlearn: 0.0106611\ttotal: 17m 52s\tremaining: 4m 52s\n",
      "393:\tlearn: 0.0105961\ttotal: 17m 54s\tremaining: 4m 49s\n",
      "394:\tlearn: 0.0105131\ttotal: 17m 56s\tremaining: 4m 46s\n",
      "395:\tlearn: 0.0104388\ttotal: 17m 58s\tremaining: 4m 43s\n",
      "396:\tlearn: 0.0103075\ttotal: 18m\tremaining: 4m 40s\n",
      "397:\tlearn: 0.0102533\ttotal: 18m 3s\tremaining: 4m 37s\n",
      "398:\tlearn: 0.0101934\ttotal: 18m 5s\tremaining: 4m 34s\n",
      "399:\tlearn: 0.0101284\ttotal: 18m 7s\tremaining: 4m 31s\n",
      "400:\tlearn: 0.0100686\ttotal: 18m 9s\tremaining: 4m 28s\n",
      "401:\tlearn: 0.0100124\ttotal: 18m 11s\tremaining: 4m 26s\n",
      "402:\tlearn: 0.0099478\ttotal: 18m 13s\tremaining: 4m 23s\n",
      "403:\tlearn: 0.0098569\ttotal: 18m 15s\tremaining: 4m 20s\n",
      "404:\tlearn: 0.0097759\ttotal: 18m 17s\tremaining: 4m 17s\n",
      "405:\tlearn: 0.0097176\ttotal: 18m 19s\tremaining: 4m 14s\n",
      "406:\tlearn: 0.0096050\ttotal: 18m 22s\tremaining: 4m 11s\n",
      "407:\tlearn: 0.0095341\ttotal: 18m 24s\tremaining: 4m 8s\n",
      "408:\tlearn: 0.0094394\ttotal: 18m 26s\tremaining: 4m 6s\n",
      "409:\tlearn: 0.0093689\ttotal: 18m 28s\tremaining: 4m 3s\n",
      "410:\tlearn: 0.0092942\ttotal: 18m 30s\tremaining: 4m\n",
      "411:\tlearn: 0.0092584\ttotal: 18m 32s\tremaining: 3m 57s\n",
      "412:\tlearn: 0.0092171\ttotal: 18m 34s\tremaining: 3m 54s\n",
      "413:\tlearn: 0.0091778\ttotal: 18m 37s\tremaining: 3m 52s\n",
      "414:\tlearn: 0.0091399\ttotal: 18m 39s\tremaining: 3m 49s\n",
      "415:\tlearn: 0.0090667\ttotal: 18m 41s\tremaining: 3m 46s\n",
      "416:\tlearn: 0.0090176\ttotal: 18m 44s\tremaining: 3m 43s\n",
      "417:\tlearn: 0.0089783\ttotal: 18m 46s\tremaining: 3m 41s\n",
      "418:\tlearn: 0.0089514\ttotal: 18m 49s\tremaining: 3m 38s\n",
      "419:\tlearn: 0.0088835\ttotal: 18m 51s\tremaining: 3m 35s\n",
      "420:\tlearn: 0.0088148\ttotal: 18m 53s\tremaining: 3m 32s\n",
      "421:\tlearn: 0.0087281\ttotal: 18m 55s\tremaining: 3m 29s\n",
      "422:\tlearn: 0.0086714\ttotal: 18m 57s\tremaining: 3m 27s\n",
      "423:\tlearn: 0.0085547\ttotal: 18m 59s\tremaining: 3m 24s\n",
      "424:\tlearn: 0.0084824\ttotal: 19m 1s\tremaining: 3m 21s\n",
      "425:\tlearn: 0.0084575\ttotal: 19m 4s\tremaining: 3m 18s\n",
      "426:\tlearn: 0.0084233\ttotal: 19m 6s\tremaining: 3m 15s\n",
      "427:\tlearn: 0.0083657\ttotal: 19m 8s\tremaining: 3m 13s\n",
      "428:\tlearn: 0.0082996\ttotal: 19m 10s\tremaining: 3m 10s\n",
      "429:\tlearn: 0.0082346\ttotal: 19m 12s\tremaining: 3m 7s\n",
      "430:\tlearn: 0.0081723\ttotal: 19m 14s\tremaining: 3m 4s\n",
      "431:\tlearn: 0.0081245\ttotal: 19m 16s\tremaining: 3m 2s\n",
      "432:\tlearn: 0.0081024\ttotal: 19m 18s\tremaining: 2m 59s\n",
      "433:\tlearn: 0.0080384\ttotal: 19m 20s\tremaining: 2m 56s\n",
      "434:\tlearn: 0.0079760\ttotal: 19m 22s\tremaining: 2m 53s\n",
      "435:\tlearn: 0.0079524\ttotal: 19m 25s\tremaining: 2m 51s\n",
      "436:\tlearn: 0.0078643\ttotal: 19m 27s\tremaining: 2m 48s\n",
      "437:\tlearn: 0.0078185\ttotal: 19m 29s\tremaining: 2m 45s\n",
      "438:\tlearn: 0.0077636\ttotal: 19m 31s\tremaining: 2m 42s\n",
      "439:\tlearn: 0.0077099\ttotal: 19m 33s\tremaining: 2m 40s\n",
      "440:\tlearn: 0.0076464\ttotal: 19m 35s\tremaining: 2m 37s\n",
      "441:\tlearn: 0.0075970\ttotal: 19m 37s\tremaining: 2m 34s\n",
      "442:\tlearn: 0.0075324\ttotal: 19m 39s\tremaining: 2m 31s\n",
      "443:\tlearn: 0.0074934\ttotal: 19m 41s\tremaining: 2m 29s\n",
      "444:\tlearn: 0.0074466\ttotal: 19m 43s\tremaining: 2m 26s\n",
      "445:\tlearn: 0.0073879\ttotal: 19m 45s\tremaining: 2m 23s\n",
      "446:\tlearn: 0.0073597\ttotal: 19m 48s\tremaining: 2m 20s\n",
      "447:\tlearn: 0.0072912\ttotal: 19m 50s\tremaining: 2m 18s\n",
      "448:\tlearn: 0.0072390\ttotal: 19m 52s\tremaining: 2m 15s\n",
      "449:\tlearn: 0.0071887\ttotal: 19m 54s\tremaining: 2m 12s\n",
      "450:\tlearn: 0.0071694\ttotal: 19m 56s\tremaining: 2m 10s\n",
      "451:\tlearn: 0.0071187\ttotal: 19m 58s\tremaining: 2m 7s\n",
      "452:\tlearn: 0.0070664\ttotal: 20m 1s\tremaining: 2m 4s\n",
      "453:\tlearn: 0.0070474\ttotal: 20m 3s\tremaining: 2m 1s\n",
      "454:\tlearn: 0.0070039\ttotal: 20m 5s\tremaining: 1m 59s\n",
      "455:\tlearn: 0.0069673\ttotal: 20m 7s\tremaining: 1m 56s\n",
      "456:\tlearn: 0.0069063\ttotal: 20m 10s\tremaining: 1m 53s\n",
      "457:\tlearn: 0.0068488\ttotal: 20m 11s\tremaining: 1m 51s\n",
      "458:\tlearn: 0.0067891\ttotal: 20m 13s\tremaining: 1m 48s\n",
      "459:\tlearn: 0.0067611\ttotal: 20m 16s\tremaining: 1m 45s\n",
      "460:\tlearn: 0.0067246\ttotal: 20m 18s\tremaining: 1m 43s\n",
      "461:\tlearn: 0.0066745\ttotal: 20m 20s\tremaining: 1m 40s\n",
      "462:\tlearn: 0.0066300\ttotal: 20m 22s\tremaining: 1m 37s\n",
      "463:\tlearn: 0.0065818\ttotal: 20m 24s\tremaining: 1m 34s\n",
      "464:\tlearn: 0.0065434\ttotal: 20m 26s\tremaining: 1m 32s\n",
      "465:\tlearn: 0.0065028\ttotal: 20m 28s\tremaining: 1m 29s\n",
      "466:\tlearn: 0.0064742\ttotal: 20m 30s\tremaining: 1m 26s\n",
      "467:\tlearn: 0.0063926\ttotal: 20m 32s\tremaining: 1m 24s\n",
      "468:\tlearn: 0.0063783\ttotal: 20m 35s\tremaining: 1m 21s\n",
      "469:\tlearn: 0.0063653\ttotal: 20m 37s\tremaining: 1m 18s\n",
      "470:\tlearn: 0.0063095\ttotal: 20m 39s\tremaining: 1m 16s\n",
      "471:\tlearn: 0.0062660\ttotal: 20m 41s\tremaining: 1m 13s\n",
      "472:\tlearn: 0.0062044\ttotal: 20m 43s\tremaining: 1m 11s\n",
      "473:\tlearn: 0.0061809\ttotal: 20m 46s\tremaining: 1m 8s\n",
      "474:\tlearn: 0.0061534\ttotal: 20m 48s\tremaining: 1m 5s\n",
      "475:\tlearn: 0.0061134\ttotal: 20m 50s\tremaining: 1m 3s\n",
      "476:\tlearn: 0.0060859\ttotal: 20m 52s\tremaining: 1m\n",
      "477:\tlearn: 0.0060348\ttotal: 20m 54s\tremaining: 57.7s\n",
      "478:\tlearn: 0.0059889\ttotal: 20m 56s\tremaining: 55.1s\n",
      "479:\tlearn: 0.0059300\ttotal: 20m 58s\tremaining: 52.4s\n",
      "480:\tlearn: 0.0058859\ttotal: 21m\tremaining: 49.8s\n",
      "481:\tlearn: 0.0058489\ttotal: 21m 2s\tremaining: 47.2s\n",
      "482:\tlearn: 0.0058041\ttotal: 21m 4s\tremaining: 44.5s\n",
      "483:\tlearn: 0.0057838\ttotal: 21m 7s\tremaining: 41.9s\n",
      "484:\tlearn: 0.0057458\ttotal: 21m 9s\tremaining: 39.3s\n",
      "485:\tlearn: 0.0057250\ttotal: 21m 11s\tremaining: 36.6s\n",
      "486:\tlearn: 0.0056886\ttotal: 21m 13s\tremaining: 34s\n",
      "487:\tlearn: 0.0056509\ttotal: 21m 15s\tremaining: 31.4s\n",
      "488:\tlearn: 0.0056277\ttotal: 21m 17s\tremaining: 28.7s\n",
      "489:\tlearn: 0.0055810\ttotal: 21m 19s\tremaining: 26.1s\n",
      "490:\tlearn: 0.0055587\ttotal: 21m 21s\tremaining: 23.5s\n",
      "491:\tlearn: 0.0055167\ttotal: 21m 23s\tremaining: 20.9s\n",
      "492:\tlearn: 0.0054852\ttotal: 21m 26s\tremaining: 18.3s\n",
      "493:\tlearn: 0.0054591\ttotal: 21m 28s\tremaining: 15.6s\n",
      "494:\tlearn: 0.0054365\ttotal: 21m 30s\tremaining: 13s\n",
      "495:\tlearn: 0.0053887\ttotal: 21m 32s\tremaining: 10.4s\n",
      "496:\tlearn: 0.0053752\ttotal: 21m 35s\tremaining: 7.82s\n",
      "497:\tlearn: 0.0053298\ttotal: 21m 37s\tremaining: 5.21s\n",
      "498:\tlearn: 0.0052858\ttotal: 21m 39s\tremaining: 2.6s\n",
      "499:\tlearn: 0.0052455\ttotal: 21m 41s\tremaining: 0us\n",
      "Accuracy: 0.9999721047744671\n",
      "\n",
      "Confusion Matrix:\n",
      " [[250747     14]\n",
      " [     0 251117]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    250761\n",
      "           1       1.00      1.00      1.00    251117\n",
      "\n",
      "    accuracy                           1.00    501878\n",
      "   macro avg       1.00      1.00      1.00    501878\n",
      "weighted avg       1.00      1.00      1.00    501878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Fraud'], axis=1)\n",
    "y = df['Fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a CatBoost Classifier\n",
    "model = CatBoostClassifier(iterations=500, depth=10, learning_rate=0.05, loss_function='MultiClass', random_seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, cat_features=None)  # You can specify categorical features if needed\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/part_D/partd_smote_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"Unnamed: 0.1\",\"PRSCRBR_NPI\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6532906\ttotal: 2.51s\tremaining: 20m 52s\n",
      "1:\tlearn: 0.6188030\ttotal: 4.94s\tremaining: 20m 30s\n",
      "2:\tlearn: 0.5852241\ttotal: 7.35s\tremaining: 20m 18s\n",
      "3:\tlearn: 0.5544856\ttotal: 9.64s\tremaining: 19m 54s\n",
      "4:\tlearn: 0.5260465\ttotal: 11.9s\tremaining: 19m 39s\n",
      "5:\tlearn: 0.4999350\ttotal: 14s\tremaining: 19m 14s\n",
      "6:\tlearn: 0.4757150\ttotal: 15.4s\tremaining: 18m 1s\n",
      "7:\tlearn: 0.4520191\ttotal: 16.6s\tremaining: 16m 59s\n",
      "8:\tlearn: 0.4311870\ttotal: 17.9s\tremaining: 16m 15s\n",
      "9:\tlearn: 0.4099012\ttotal: 19.1s\tremaining: 15m 37s\n",
      "10:\tlearn: 0.3905223\ttotal: 20.4s\tremaining: 15m 6s\n",
      "11:\tlearn: 0.3733039\ttotal: 21.6s\tremaining: 14m 40s\n",
      "12:\tlearn: 0.3571030\ttotal: 22.8s\tremaining: 14m 15s\n",
      "13:\tlearn: 0.3408753\ttotal: 24s\tremaining: 13m 54s\n",
      "14:\tlearn: 0.3262648\ttotal: 25.3s\tremaining: 13m 37s\n",
      "15:\tlearn: 0.3125327\ttotal: 26.5s\tremaining: 13m 22s\n",
      "16:\tlearn: 0.2991384\ttotal: 27.8s\tremaining: 13m 8s\n",
      "17:\tlearn: 0.2869120\ttotal: 29s\tremaining: 12m 56s\n",
      "18:\tlearn: 0.2755689\ttotal: 30.2s\tremaining: 12m 45s\n",
      "19:\tlearn: 0.2642505\ttotal: 31.5s\tremaining: 12m 37s\n",
      "20:\tlearn: 0.2543518\ttotal: 32.8s\tremaining: 12m 28s\n",
      "21:\tlearn: 0.2445034\ttotal: 34.1s\tremaining: 12m 20s\n",
      "22:\tlearn: 0.2349207\ttotal: 35.3s\tremaining: 12m 13s\n",
      "23:\tlearn: 0.2268626\ttotal: 36.7s\tremaining: 12m 7s\n",
      "24:\tlearn: 0.2187515\ttotal: 37.9s\tremaining: 11m 59s\n",
      "25:\tlearn: 0.2098820\ttotal: 39s\tremaining: 11m 51s\n",
      "26:\tlearn: 0.2030797\ttotal: 40.2s\tremaining: 11m 44s\n",
      "27:\tlearn: 0.1964531\ttotal: 41.4s\tremaining: 11m 37s\n",
      "28:\tlearn: 0.1896485\ttotal: 42.6s\tremaining: 11m 31s\n",
      "29:\tlearn: 0.1825127\ttotal: 43.8s\tremaining: 11m 26s\n",
      "30:\tlearn: 0.1760820\ttotal: 45s\tremaining: 11m 21s\n",
      "31:\tlearn: 0.1703001\ttotal: 46.2s\tremaining: 11m 16s\n",
      "32:\tlearn: 0.1650823\ttotal: 47.4s\tremaining: 11m 11s\n",
      "33:\tlearn: 0.1586586\ttotal: 48.6s\tremaining: 11m 6s\n",
      "34:\tlearn: 0.1520901\ttotal: 49.9s\tremaining: 11m 2s\n",
      "35:\tlearn: 0.1466795\ttotal: 51.1s\tremaining: 10m 58s\n",
      "36:\tlearn: 0.1412039\ttotal: 52.3s\tremaining: 10m 54s\n",
      "37:\tlearn: 0.1367510\ttotal: 53.5s\tremaining: 10m 50s\n",
      "38:\tlearn: 0.1328450\ttotal: 54.7s\tremaining: 10m 46s\n",
      "39:\tlearn: 0.1276266\ttotal: 55.9s\tremaining: 10m 43s\n",
      "40:\tlearn: 0.1231087\ttotal: 57.1s\tremaining: 10m 39s\n",
      "41:\tlearn: 0.1184431\ttotal: 58.4s\tremaining: 10m 37s\n",
      "42:\tlearn: 0.1143112\ttotal: 59.6s\tremaining: 10m 33s\n",
      "43:\tlearn: 0.1100969\ttotal: 1m\tremaining: 10m 30s\n",
      "44:\tlearn: 0.1061265\ttotal: 1m 2s\tremaining: 10m 27s\n",
      "45:\tlearn: 0.1025905\ttotal: 1m 3s\tremaining: 10m 24s\n",
      "46:\tlearn: 0.1000792\ttotal: 1m 4s\tremaining: 10m 21s\n",
      "47:\tlearn: 0.0971206\ttotal: 1m 5s\tremaining: 10m 19s\n",
      "48:\tlearn: 0.0940300\ttotal: 1m 6s\tremaining: 10m 16s\n",
      "49:\tlearn: 0.0911429\ttotal: 1m 8s\tremaining: 10m 13s\n",
      "50:\tlearn: 0.0884227\ttotal: 1m 9s\tremaining: 10m 10s\n",
      "51:\tlearn: 0.0861262\ttotal: 1m 10s\tremaining: 10m 7s\n",
      "52:\tlearn: 0.0834364\ttotal: 1m 11s\tremaining: 10m 4s\n",
      "53:\tlearn: 0.0810330\ttotal: 1m 12s\tremaining: 10m 2s\n",
      "54:\tlearn: 0.0784343\ttotal: 1m 14s\tremaining: 10m\n",
      "55:\tlearn: 0.0759486\ttotal: 1m 15s\tremaining: 9m 57s\n",
      "56:\tlearn: 0.0738171\ttotal: 1m 16s\tremaining: 9m 55s\n",
      "57:\tlearn: 0.0718101\ttotal: 1m 17s\tremaining: 9m 53s\n",
      "58:\tlearn: 0.0698722\ttotal: 1m 19s\tremaining: 9m 54s\n",
      "59:\tlearn: 0.0676510\ttotal: 1m 21s\tremaining: 9m 57s\n",
      "60:\tlearn: 0.0655969\ttotal: 1m 22s\tremaining: 9m 56s\n",
      "61:\tlearn: 0.0637132\ttotal: 1m 24s\tremaining: 9m 55s\n",
      "62:\tlearn: 0.0617066\ttotal: 1m 25s\tremaining: 9m 54s\n",
      "63:\tlearn: 0.0605919\ttotal: 1m 26s\tremaining: 9m 52s\n",
      "64:\tlearn: 0.0591744\ttotal: 1m 28s\tremaining: 9m 50s\n",
      "65:\tlearn: 0.0575465\ttotal: 1m 29s\tremaining: 9m 48s\n",
      "66:\tlearn: 0.0558260\ttotal: 1m 30s\tremaining: 9m 46s\n",
      "67:\tlearn: 0.0542576\ttotal: 1m 32s\tremaining: 9m 44s\n",
      "68:\tlearn: 0.0532171\ttotal: 1m 33s\tremaining: 9m 42s\n",
      "69:\tlearn: 0.0519312\ttotal: 1m 34s\tremaining: 9m 40s\n",
      "70:\tlearn: 0.0504713\ttotal: 1m 35s\tremaining: 9m 38s\n",
      "71:\tlearn: 0.0491456\ttotal: 1m 37s\tremaining: 9m 37s\n",
      "72:\tlearn: 0.0480677\ttotal: 1m 38s\tremaining: 9m 35s\n",
      "73:\tlearn: 0.0468277\ttotal: 1m 39s\tremaining: 9m 33s\n",
      "74:\tlearn: 0.0456618\ttotal: 1m 40s\tremaining: 9m 31s\n",
      "75:\tlearn: 0.0447051\ttotal: 1m 42s\tremaining: 9m 29s\n",
      "76:\tlearn: 0.0436855\ttotal: 1m 43s\tremaining: 9m 27s\n",
      "77:\tlearn: 0.0428309\ttotal: 1m 44s\tremaining: 9m 25s\n",
      "78:\tlearn: 0.0414960\ttotal: 1m 45s\tremaining: 9m 24s\n",
      "79:\tlearn: 0.0405442\ttotal: 1m 47s\tremaining: 9m 22s\n",
      "80:\tlearn: 0.0394544\ttotal: 1m 48s\tremaining: 9m 20s\n",
      "81:\tlearn: 0.0386005\ttotal: 1m 49s\tremaining: 9m 19s\n",
      "82:\tlearn: 0.0377448\ttotal: 1m 50s\tremaining: 9m 17s\n",
      "83:\tlearn: 0.0368171\ttotal: 1m 52s\tremaining: 9m 15s\n",
      "84:\tlearn: 0.0359086\ttotal: 1m 53s\tremaining: 9m 13s\n",
      "85:\tlearn: 0.0351477\ttotal: 1m 54s\tremaining: 9m 12s\n",
      "86:\tlearn: 0.0344350\ttotal: 1m 55s\tremaining: 9m 10s\n",
      "87:\tlearn: 0.0338148\ttotal: 1m 57s\tremaining: 9m 8s\n",
      "88:\tlearn: 0.0332812\ttotal: 1m 58s\tremaining: 9m 6s\n",
      "89:\tlearn: 0.0326429\ttotal: 1m 59s\tremaining: 9m 4s\n",
      "90:\tlearn: 0.0320414\ttotal: 2m\tremaining: 9m 3s\n",
      "91:\tlearn: 0.0313659\ttotal: 2m 2s\tremaining: 9m 1s\n",
      "92:\tlearn: 0.0308819\ttotal: 2m 3s\tremaining: 8m 59s\n",
      "93:\tlearn: 0.0302920\ttotal: 2m 4s\tremaining: 8m 58s\n",
      "94:\tlearn: 0.0295613\ttotal: 2m 5s\tremaining: 8m 56s\n",
      "95:\tlearn: 0.0289954\ttotal: 2m 7s\tremaining: 8m 54s\n",
      "96:\tlearn: 0.0285844\ttotal: 2m 8s\tremaining: 8m 53s\n",
      "97:\tlearn: 0.0280527\ttotal: 2m 9s\tremaining: 8m 51s\n",
      "98:\tlearn: 0.0274377\ttotal: 2m 10s\tremaining: 8m 49s\n",
      "99:\tlearn: 0.0270095\ttotal: 2m 11s\tremaining: 8m 47s\n",
      "100:\tlearn: 0.0266503\ttotal: 2m 13s\tremaining: 8m 46s\n",
      "101:\tlearn: 0.0262134\ttotal: 2m 14s\tremaining: 8m 45s\n",
      "102:\tlearn: 0.0256568\ttotal: 2m 15s\tremaining: 8m 43s\n",
      "103:\tlearn: 0.0252351\ttotal: 2m 17s\tremaining: 8m 41s\n",
      "104:\tlearn: 0.0248639\ttotal: 2m 18s\tremaining: 8m 39s\n",
      "105:\tlearn: 0.0243775\ttotal: 2m 19s\tremaining: 8m 38s\n",
      "106:\tlearn: 0.0239397\ttotal: 2m 20s\tremaining: 8m 36s\n",
      "107:\tlearn: 0.0235633\ttotal: 2m 21s\tremaining: 8m 35s\n",
      "108:\tlearn: 0.0230873\ttotal: 2m 23s\tremaining: 8m 33s\n",
      "109:\tlearn: 0.0227181\ttotal: 2m 24s\tremaining: 8m 32s\n",
      "110:\tlearn: 0.0223117\ttotal: 2m 25s\tremaining: 8m 30s\n",
      "111:\tlearn: 0.0220704\ttotal: 2m 26s\tremaining: 8m 29s\n",
      "112:\tlearn: 0.0217094\ttotal: 2m 28s\tremaining: 8m 27s\n",
      "113:\tlearn: 0.0213858\ttotal: 2m 29s\tremaining: 8m 25s\n",
      "114:\tlearn: 0.0210352\ttotal: 2m 30s\tremaining: 8m 24s\n",
      "115:\tlearn: 0.0206326\ttotal: 2m 31s\tremaining: 8m 22s\n",
      "116:\tlearn: 0.0203672\ttotal: 2m 33s\tremaining: 8m 21s\n",
      "117:\tlearn: 0.0200603\ttotal: 2m 34s\tremaining: 8m 19s\n",
      "118:\tlearn: 0.0197881\ttotal: 2m 35s\tremaining: 8m 18s\n",
      "119:\tlearn: 0.0194180\ttotal: 2m 36s\tremaining: 8m 16s\n",
      "120:\tlearn: 0.0192045\ttotal: 2m 38s\tremaining: 8m 15s\n",
      "121:\tlearn: 0.0189107\ttotal: 2m 39s\tremaining: 8m 13s\n",
      "122:\tlearn: 0.0185864\ttotal: 2m 40s\tremaining: 8m 11s\n",
      "123:\tlearn: 0.0183524\ttotal: 2m 41s\tremaining: 8m 10s\n",
      "124:\tlearn: 0.0181374\ttotal: 2m 42s\tremaining: 8m 8s\n",
      "125:\tlearn: 0.0179451\ttotal: 2m 44s\tremaining: 8m 7s\n",
      "126:\tlearn: 0.0176609\ttotal: 2m 45s\tremaining: 8m 5s\n",
      "127:\tlearn: 0.0174543\ttotal: 2m 46s\tremaining: 8m 4s\n",
      "128:\tlearn: 0.0172284\ttotal: 2m 47s\tremaining: 8m 2s\n",
      "129:\tlearn: 0.0169142\ttotal: 2m 49s\tremaining: 8m 1s\n",
      "130:\tlearn: 0.0166490\ttotal: 2m 50s\tremaining: 7m 59s\n",
      "131:\tlearn: 0.0164223\ttotal: 2m 51s\tremaining: 7m 58s\n",
      "132:\tlearn: 0.0161611\ttotal: 2m 52s\tremaining: 7m 57s\n",
      "133:\tlearn: 0.0159735\ttotal: 2m 54s\tremaining: 7m 55s\n",
      "134:\tlearn: 0.0157065\ttotal: 2m 55s\tremaining: 7m 53s\n",
      "135:\tlearn: 0.0154961\ttotal: 2m 56s\tremaining: 7m 52s\n",
      "136:\tlearn: 0.0153121\ttotal: 2m 57s\tremaining: 7m 51s\n",
      "137:\tlearn: 0.0151728\ttotal: 2m 59s\tremaining: 7m 49s\n",
      "138:\tlearn: 0.0150354\ttotal: 3m\tremaining: 7m 48s\n",
      "139:\tlearn: 0.0147725\ttotal: 3m 1s\tremaining: 7m 46s\n",
      "140:\tlearn: 0.0146237\ttotal: 3m 2s\tremaining: 7m 45s\n",
      "141:\tlearn: 0.0143777\ttotal: 3m 3s\tremaining: 7m 43s\n",
      "142:\tlearn: 0.0141311\ttotal: 3m 5s\tremaining: 7m 42s\n",
      "143:\tlearn: 0.0139173\ttotal: 3m 6s\tremaining: 7m 41s\n",
      "144:\tlearn: 0.0137488\ttotal: 3m 7s\tremaining: 7m 39s\n",
      "145:\tlearn: 0.0134866\ttotal: 3m 8s\tremaining: 7m 38s\n",
      "146:\tlearn: 0.0133668\ttotal: 3m 10s\tremaining: 7m 36s\n",
      "147:\tlearn: 0.0132711\ttotal: 3m 11s\tremaining: 7m 35s\n",
      "148:\tlearn: 0.0131367\ttotal: 3m 12s\tremaining: 7m 33s\n",
      "149:\tlearn: 0.0129721\ttotal: 3m 13s\tremaining: 7m 32s\n",
      "150:\tlearn: 0.0127897\ttotal: 3m 15s\tremaining: 7m 31s\n",
      "151:\tlearn: 0.0125862\ttotal: 3m 16s\tremaining: 7m 29s\n",
      "152:\tlearn: 0.0124390\ttotal: 3m 17s\tremaining: 7m 28s\n",
      "153:\tlearn: 0.0122620\ttotal: 3m 18s\tremaining: 7m 26s\n",
      "154:\tlearn: 0.0120920\ttotal: 3m 20s\tremaining: 7m 25s\n",
      "155:\tlearn: 0.0119472\ttotal: 3m 21s\tremaining: 7m 23s\n",
      "156:\tlearn: 0.0118057\ttotal: 3m 22s\tremaining: 7m 22s\n",
      "157:\tlearn: 0.0117197\ttotal: 3m 23s\tremaining: 7m 21s\n",
      "158:\tlearn: 0.0115568\ttotal: 3m 25s\tremaining: 7m 19s\n",
      "159:\tlearn: 0.0114430\ttotal: 3m 26s\tremaining: 7m 18s\n",
      "160:\tlearn: 0.0112565\ttotal: 3m 27s\tremaining: 7m 16s\n",
      "161:\tlearn: 0.0111299\ttotal: 3m 28s\tremaining: 7m 15s\n",
      "162:\tlearn: 0.0109711\ttotal: 3m 29s\tremaining: 7m 14s\n",
      "163:\tlearn: 0.0108007\ttotal: 3m 31s\tremaining: 7m 12s\n",
      "164:\tlearn: 0.0106960\ttotal: 3m 32s\tremaining: 7m 11s\n",
      "165:\tlearn: 0.0106019\ttotal: 3m 33s\tremaining: 7m 10s\n",
      "166:\tlearn: 0.0104468\ttotal: 3m 34s\tremaining: 7m 8s\n",
      "167:\tlearn: 0.0103515\ttotal: 3m 36s\tremaining: 7m 7s\n",
      "168:\tlearn: 0.0101879\ttotal: 3m 37s\tremaining: 7m 5s\n",
      "169:\tlearn: 0.0100966\ttotal: 3m 38s\tremaining: 7m 4s\n",
      "170:\tlearn: 0.0099810\ttotal: 3m 40s\tremaining: 7m 3s\n",
      "171:\tlearn: 0.0098861\ttotal: 3m 41s\tremaining: 7m 1s\n",
      "172:\tlearn: 0.0097781\ttotal: 3m 42s\tremaining: 7m\n",
      "173:\tlearn: 0.0096662\ttotal: 3m 43s\tremaining: 6m 59s\n",
      "174:\tlearn: 0.0095220\ttotal: 3m 44s\tremaining: 6m 57s\n",
      "175:\tlearn: 0.0094185\ttotal: 3m 46s\tremaining: 6m 56s\n",
      "176:\tlearn: 0.0092665\ttotal: 3m 47s\tremaining: 6m 54s\n",
      "177:\tlearn: 0.0091632\ttotal: 3m 48s\tremaining: 6m 53s\n",
      "178:\tlearn: 0.0090516\ttotal: 3m 49s\tremaining: 6m 52s\n",
      "179:\tlearn: 0.0089811\ttotal: 3m 51s\tremaining: 6m 50s\n",
      "180:\tlearn: 0.0088595\ttotal: 3m 52s\tremaining: 6m 49s\n",
      "181:\tlearn: 0.0087664\ttotal: 3m 53s\tremaining: 6m 48s\n",
      "182:\tlearn: 0.0086546\ttotal: 3m 54s\tremaining: 6m 46s\n",
      "183:\tlearn: 0.0085580\ttotal: 3m 56s\tremaining: 6m 45s\n",
      "184:\tlearn: 0.0084671\ttotal: 3m 57s\tremaining: 6m 44s\n",
      "185:\tlearn: 0.0083491\ttotal: 3m 58s\tremaining: 6m 43s\n",
      "186:\tlearn: 0.0082924\ttotal: 4m\tremaining: 6m 42s\n",
      "187:\tlearn: 0.0082221\ttotal: 4m 1s\tremaining: 6m 40s\n",
      "188:\tlearn: 0.0081074\ttotal: 4m 2s\tremaining: 6m 39s\n",
      "189:\tlearn: 0.0080281\ttotal: 4m 4s\tremaining: 6m 38s\n",
      "190:\tlearn: 0.0079528\ttotal: 4m 5s\tremaining: 6m 37s\n",
      "191:\tlearn: 0.0078592\ttotal: 4m 6s\tremaining: 6m 35s\n",
      "192:\tlearn: 0.0077960\ttotal: 4m 8s\tremaining: 6m 34s\n",
      "193:\tlearn: 0.0077344\ttotal: 4m 9s\tremaining: 6m 33s\n",
      "194:\tlearn: 0.0076366\ttotal: 4m 10s\tremaining: 6m 32s\n",
      "195:\tlearn: 0.0075490\ttotal: 4m 11s\tremaining: 6m 30s\n",
      "196:\tlearn: 0.0075005\ttotal: 4m 13s\tremaining: 6m 29s\n",
      "197:\tlearn: 0.0074443\ttotal: 4m 14s\tremaining: 6m 28s\n",
      "198:\tlearn: 0.0073456\ttotal: 4m 15s\tremaining: 6m 26s\n",
      "199:\tlearn: 0.0072362\ttotal: 4m 16s\tremaining: 6m 25s\n",
      "200:\tlearn: 0.0071794\ttotal: 4m 18s\tremaining: 6m 24s\n",
      "201:\tlearn: 0.0071090\ttotal: 4m 19s\tremaining: 6m 22s\n",
      "202:\tlearn: 0.0070789\ttotal: 4m 20s\tremaining: 6m 21s\n",
      "203:\tlearn: 0.0070124\ttotal: 4m 21s\tremaining: 6m 19s\n",
      "204:\tlearn: 0.0069229\ttotal: 4m 23s\tremaining: 6m 18s\n",
      "205:\tlearn: 0.0068603\ttotal: 4m 24s\tremaining: 6m 17s\n",
      "206:\tlearn: 0.0067815\ttotal: 4m 25s\tremaining: 6m 16s\n",
      "207:\tlearn: 0.0067168\ttotal: 4m 27s\tremaining: 6m 14s\n",
      "208:\tlearn: 0.0066507\ttotal: 4m 28s\tremaining: 6m 13s\n",
      "209:\tlearn: 0.0065887\ttotal: 4m 29s\tremaining: 6m 12s\n",
      "210:\tlearn: 0.0065313\ttotal: 4m 30s\tremaining: 6m 10s\n",
      "211:\tlearn: 0.0064462\ttotal: 4m 31s\tremaining: 6m 9s\n",
      "212:\tlearn: 0.0063890\ttotal: 4m 33s\tremaining: 6m 8s\n",
      "213:\tlearn: 0.0063136\ttotal: 4m 34s\tremaining: 6m 6s\n",
      "214:\tlearn: 0.0062738\ttotal: 4m 35s\tremaining: 6m 5s\n",
      "215:\tlearn: 0.0062097\ttotal: 4m 36s\tremaining: 6m 4s\n",
      "216:\tlearn: 0.0061454\ttotal: 4m 38s\tremaining: 6m 2s\n",
      "217:\tlearn: 0.0061128\ttotal: 4m 39s\tremaining: 6m 1s\n",
      "218:\tlearn: 0.0060474\ttotal: 4m 40s\tremaining: 6m\n",
      "219:\tlearn: 0.0059910\ttotal: 4m 41s\tremaining: 5m 58s\n",
      "220:\tlearn: 0.0059491\ttotal: 4m 43s\tremaining: 5m 57s\n",
      "221:\tlearn: 0.0059058\ttotal: 4m 44s\tremaining: 5m 56s\n",
      "222:\tlearn: 0.0058406\ttotal: 4m 45s\tremaining: 5m 54s\n",
      "223:\tlearn: 0.0057868\ttotal: 4m 46s\tremaining: 5m 53s\n",
      "224:\tlearn: 0.0057245\ttotal: 4m 48s\tremaining: 5m 52s\n",
      "225:\tlearn: 0.0056873\ttotal: 4m 49s\tremaining: 5m 50s\n",
      "226:\tlearn: 0.0056246\ttotal: 4m 50s\tremaining: 5m 49s\n",
      "227:\tlearn: 0.0055883\ttotal: 4m 52s\tremaining: 5m 48s\n",
      "228:\tlearn: 0.0055321\ttotal: 4m 53s\tremaining: 5m 47s\n",
      "229:\tlearn: 0.0054678\ttotal: 4m 54s\tremaining: 5m 45s\n",
      "230:\tlearn: 0.0054154\ttotal: 4m 55s\tremaining: 5m 44s\n",
      "231:\tlearn: 0.0053745\ttotal: 4m 56s\tremaining: 5m 43s\n",
      "232:\tlearn: 0.0053195\ttotal: 4m 58s\tremaining: 5m 41s\n",
      "233:\tlearn: 0.0052780\ttotal: 4m 59s\tremaining: 5m 40s\n",
      "234:\tlearn: 0.0052360\ttotal: 5m\tremaining: 5m 38s\n",
      "235:\tlearn: 0.0051738\ttotal: 5m 1s\tremaining: 5m 37s\n",
      "236:\tlearn: 0.0051302\ttotal: 5m 3s\tremaining: 5m 36s\n",
      "237:\tlearn: 0.0050580\ttotal: 5m 4s\tremaining: 5m 34s\n",
      "238:\tlearn: 0.0050002\ttotal: 5m 5s\tremaining: 5m 33s\n",
      "239:\tlearn: 0.0049669\ttotal: 5m 7s\tremaining: 5m 32s\n",
      "240:\tlearn: 0.0049375\ttotal: 5m 8s\tremaining: 5m 31s\n",
      "241:\tlearn: 0.0049002\ttotal: 5m 9s\tremaining: 5m 30s\n",
      "242:\tlearn: 0.0048653\ttotal: 5m 11s\tremaining: 5m 29s\n",
      "243:\tlearn: 0.0048247\ttotal: 5m 12s\tremaining: 5m 28s\n",
      "244:\tlearn: 0.0047731\ttotal: 5m 14s\tremaining: 5m 27s\n",
      "245:\tlearn: 0.0047327\ttotal: 5m 16s\tremaining: 5m 26s\n",
      "246:\tlearn: 0.0046989\ttotal: 5m 17s\tremaining: 5m 24s\n",
      "247:\tlearn: 0.0046349\ttotal: 5m 18s\tremaining: 5m 23s\n",
      "248:\tlearn: 0.0045888\ttotal: 5m 19s\tremaining: 5m 22s\n",
      "249:\tlearn: 0.0045554\ttotal: 5m 21s\tremaining: 5m 21s\n",
      "250:\tlearn: 0.0045052\ttotal: 5m 22s\tremaining: 5m 19s\n",
      "251:\tlearn: 0.0044616\ttotal: 5m 23s\tremaining: 5m 18s\n",
      "252:\tlearn: 0.0044277\ttotal: 5m 24s\tremaining: 5m 17s\n",
      "253:\tlearn: 0.0043979\ttotal: 5m 25s\tremaining: 5m 15s\n",
      "254:\tlearn: 0.0043768\ttotal: 5m 27s\tremaining: 5m 14s\n",
      "255:\tlearn: 0.0043376\ttotal: 5m 28s\tremaining: 5m 12s\n",
      "256:\tlearn: 0.0043001\ttotal: 5m 29s\tremaining: 5m 11s\n",
      "257:\tlearn: 0.0042706\ttotal: 5m 30s\tremaining: 5m 10s\n",
      "258:\tlearn: 0.0042506\ttotal: 5m 32s\tremaining: 5m 8s\n",
      "259:\tlearn: 0.0042139\ttotal: 5m 33s\tremaining: 5m 7s\n",
      "260:\tlearn: 0.0041812\ttotal: 5m 34s\tremaining: 5m 6s\n",
      "261:\tlearn: 0.0041487\ttotal: 5m 35s\tremaining: 5m 4s\n",
      "262:\tlearn: 0.0041223\ttotal: 5m 36s\tremaining: 5m 3s\n",
      "263:\tlearn: 0.0040825\ttotal: 5m 38s\tremaining: 5m 2s\n",
      "264:\tlearn: 0.0040465\ttotal: 5m 39s\tremaining: 5m\n",
      "265:\tlearn: 0.0040188\ttotal: 5m 40s\tremaining: 4m 59s\n",
      "266:\tlearn: 0.0039953\ttotal: 5m 41s\tremaining: 4m 58s\n",
      "267:\tlearn: 0.0039666\ttotal: 5m 42s\tremaining: 4m 56s\n",
      "268:\tlearn: 0.0039448\ttotal: 5m 44s\tremaining: 4m 55s\n",
      "269:\tlearn: 0.0039265\ttotal: 5m 45s\tremaining: 4m 54s\n",
      "270:\tlearn: 0.0039015\ttotal: 5m 46s\tremaining: 4m 52s\n",
      "271:\tlearn: 0.0038793\ttotal: 5m 47s\tremaining: 4m 51s\n",
      "272:\tlearn: 0.0038428\ttotal: 5m 48s\tremaining: 4m 50s\n",
      "273:\tlearn: 0.0038069\ttotal: 5m 50s\tremaining: 4m 48s\n",
      "274:\tlearn: 0.0037701\ttotal: 5m 51s\tremaining: 4m 47s\n",
      "275:\tlearn: 0.0037344\ttotal: 5m 52s\tremaining: 4m 46s\n",
      "276:\tlearn: 0.0036971\ttotal: 5m 53s\tremaining: 4m 44s\n",
      "277:\tlearn: 0.0036826\ttotal: 5m 54s\tremaining: 4m 43s\n",
      "278:\tlearn: 0.0036652\ttotal: 5m 56s\tremaining: 4m 42s\n",
      "279:\tlearn: 0.0036449\ttotal: 5m 57s\tremaining: 4m 40s\n",
      "280:\tlearn: 0.0036151\ttotal: 5m 58s\tremaining: 4m 39s\n",
      "281:\tlearn: 0.0036018\ttotal: 5m 59s\tremaining: 4m 38s\n",
      "282:\tlearn: 0.0035692\ttotal: 6m\tremaining: 4m 36s\n",
      "283:\tlearn: 0.0035410\ttotal: 6m 2s\tremaining: 4m 35s\n",
      "284:\tlearn: 0.0035173\ttotal: 6m 3s\tremaining: 4m 34s\n",
      "285:\tlearn: 0.0034889\ttotal: 6m 4s\tremaining: 4m 32s\n",
      "286:\tlearn: 0.0034546\ttotal: 6m 5s\tremaining: 4m 31s\n",
      "287:\tlearn: 0.0034263\ttotal: 6m 6s\tremaining: 4m 30s\n",
      "288:\tlearn: 0.0033957\ttotal: 6m 8s\tremaining: 4m 28s\n",
      "289:\tlearn: 0.0033775\ttotal: 6m 9s\tremaining: 4m 27s\n",
      "290:\tlearn: 0.0033480\ttotal: 6m 10s\tremaining: 4m 26s\n",
      "291:\tlearn: 0.0033285\ttotal: 6m 11s\tremaining: 4m 24s\n",
      "292:\tlearn: 0.0033123\ttotal: 6m 12s\tremaining: 4m 23s\n",
      "293:\tlearn: 0.0032738\ttotal: 6m 14s\tremaining: 4m 22s\n",
      "294:\tlearn: 0.0032627\ttotal: 6m 15s\tremaining: 4m 20s\n",
      "295:\tlearn: 0.0032396\ttotal: 6m 16s\tremaining: 4m 19s\n",
      "296:\tlearn: 0.0032193\ttotal: 6m 17s\tremaining: 4m 18s\n",
      "297:\tlearn: 0.0032047\ttotal: 6m 19s\tremaining: 4m 16s\n",
      "298:\tlearn: 0.0031727\ttotal: 6m 20s\tremaining: 4m 15s\n",
      "299:\tlearn: 0.0031475\ttotal: 6m 21s\tremaining: 4m 14s\n",
      "300:\tlearn: 0.0031263\ttotal: 6m 22s\tremaining: 4m 12s\n",
      "301:\tlearn: 0.0031111\ttotal: 6m 23s\tremaining: 4m 11s\n",
      "302:\tlearn: 0.0030975\ttotal: 6m 25s\tremaining: 4m 10s\n",
      "303:\tlearn: 0.0030767\ttotal: 6m 26s\tremaining: 4m 9s\n",
      "304:\tlearn: 0.0030492\ttotal: 6m 27s\tremaining: 4m 7s\n",
      "305:\tlearn: 0.0030210\ttotal: 6m 28s\tremaining: 4m 6s\n",
      "306:\tlearn: 0.0030021\ttotal: 6m 29s\tremaining: 4m 5s\n",
      "307:\tlearn: 0.0029852\ttotal: 6m 31s\tremaining: 4m 3s\n",
      "308:\tlearn: 0.0029702\ttotal: 6m 32s\tremaining: 4m 2s\n",
      "309:\tlearn: 0.0029573\ttotal: 6m 33s\tremaining: 4m 1s\n",
      "310:\tlearn: 0.0029357\ttotal: 6m 34s\tremaining: 3m 59s\n",
      "311:\tlearn: 0.0029163\ttotal: 6m 36s\tremaining: 3m 58s\n",
      "312:\tlearn: 0.0028983\ttotal: 6m 37s\tremaining: 3m 57s\n",
      "313:\tlearn: 0.0028712\ttotal: 6m 38s\tremaining: 3m 56s\n",
      "314:\tlearn: 0.0028586\ttotal: 6m 39s\tremaining: 3m 54s\n",
      "315:\tlearn: 0.0028348\ttotal: 6m 40s\tremaining: 3m 53s\n",
      "316:\tlearn: 0.0028210\ttotal: 6m 42s\tremaining: 3m 52s\n",
      "317:\tlearn: 0.0028049\ttotal: 6m 43s\tremaining: 3m 50s\n",
      "318:\tlearn: 0.0027859\ttotal: 6m 44s\tremaining: 3m 49s\n",
      "319:\tlearn: 0.0027534\ttotal: 6m 45s\tremaining: 3m 48s\n",
      "320:\tlearn: 0.0027331\ttotal: 6m 46s\tremaining: 3m 46s\n",
      "321:\tlearn: 0.0027175\ttotal: 6m 48s\tremaining: 3m 45s\n",
      "322:\tlearn: 0.0027020\ttotal: 6m 49s\tremaining: 3m 44s\n",
      "323:\tlearn: 0.0026873\ttotal: 6m 50s\tremaining: 3m 42s\n",
      "324:\tlearn: 0.0026699\ttotal: 6m 51s\tremaining: 3m 41s\n",
      "325:\tlearn: 0.0026560\ttotal: 6m 52s\tremaining: 3m 40s\n",
      "326:\tlearn: 0.0026466\ttotal: 6m 54s\tremaining: 3m 39s\n",
      "327:\tlearn: 0.0026352\ttotal: 6m 55s\tremaining: 3m 37s\n",
      "328:\tlearn: 0.0026186\ttotal: 6m 56s\tremaining: 3m 36s\n",
      "329:\tlearn: 0.0026064\ttotal: 6m 57s\tremaining: 3m 35s\n",
      "330:\tlearn: 0.0025877\ttotal: 6m 58s\tremaining: 3m 33s\n",
      "331:\tlearn: 0.0025761\ttotal: 7m\tremaining: 3m 32s\n",
      "332:\tlearn: 0.0025653\ttotal: 7m 1s\tremaining: 3m 31s\n",
      "333:\tlearn: 0.0025490\ttotal: 7m 2s\tremaining: 3m 29s\n",
      "334:\tlearn: 0.0025384\ttotal: 7m 3s\tremaining: 3m 28s\n",
      "335:\tlearn: 0.0025231\ttotal: 7m 4s\tremaining: 3m 27s\n",
      "336:\tlearn: 0.0025109\ttotal: 7m 5s\tremaining: 3m 26s\n",
      "337:\tlearn: 0.0025013\ttotal: 7m 7s\tremaining: 3m 24s\n",
      "338:\tlearn: 0.0024897\ttotal: 7m 8s\tremaining: 3m 23s\n",
      "339:\tlearn: 0.0024763\ttotal: 7m 9s\tremaining: 3m 22s\n",
      "340:\tlearn: 0.0024589\ttotal: 7m 10s\tremaining: 3m 20s\n",
      "341:\tlearn: 0.0024476\ttotal: 7m 11s\tremaining: 3m 19s\n",
      "342:\tlearn: 0.0024350\ttotal: 7m 13s\tremaining: 3m 18s\n",
      "343:\tlearn: 0.0024214\ttotal: 7m 14s\tremaining: 3m 16s\n",
      "344:\tlearn: 0.0024122\ttotal: 7m 15s\tremaining: 3m 15s\n",
      "345:\tlearn: 0.0024046\ttotal: 7m 16s\tremaining: 3m 14s\n",
      "346:\tlearn: 0.0023968\ttotal: 7m 18s\tremaining: 3m 13s\n",
      "347:\tlearn: 0.0023853\ttotal: 7m 19s\tremaining: 3m 11s\n",
      "348:\tlearn: 0.0023700\ttotal: 7m 20s\tremaining: 3m 10s\n",
      "349:\tlearn: 0.0023559\ttotal: 7m 21s\tremaining: 3m 9s\n",
      "350:\tlearn: 0.0023491\ttotal: 7m 22s\tremaining: 3m 7s\n",
      "351:\tlearn: 0.0023444\ttotal: 7m 24s\tremaining: 3m 6s\n",
      "352:\tlearn: 0.0023291\ttotal: 7m 25s\tremaining: 3m 5s\n",
      "353:\tlearn: 0.0023154\ttotal: 7m 26s\tremaining: 3m 4s\n",
      "354:\tlearn: 0.0023062\ttotal: 7m 27s\tremaining: 3m 2s\n",
      "355:\tlearn: 0.0022826\ttotal: 7m 28s\tremaining: 3m 1s\n",
      "356:\tlearn: 0.0022663\ttotal: 7m 30s\tremaining: 3m\n",
      "357:\tlearn: 0.0022525\ttotal: 7m 31s\tremaining: 2m 59s\n",
      "358:\tlearn: 0.0022410\ttotal: 7m 32s\tremaining: 2m 57s\n",
      "359:\tlearn: 0.0022318\ttotal: 7m 33s\tremaining: 2m 56s\n",
      "360:\tlearn: 0.0022160\ttotal: 7m 35s\tremaining: 2m 55s\n",
      "361:\tlearn: 0.0021997\ttotal: 7m 36s\tremaining: 2m 53s\n",
      "362:\tlearn: 0.0021907\ttotal: 7m 37s\tremaining: 2m 52s\n",
      "363:\tlearn: 0.0021832\ttotal: 7m 38s\tremaining: 2m 51s\n",
      "364:\tlearn: 0.0021756\ttotal: 7m 39s\tremaining: 2m 50s\n",
      "365:\tlearn: 0.0021635\ttotal: 7m 40s\tremaining: 2m 48s\n",
      "366:\tlearn: 0.0021543\ttotal: 7m 42s\tremaining: 2m 47s\n",
      "367:\tlearn: 0.0021361\ttotal: 7m 43s\tremaining: 2m 46s\n",
      "368:\tlearn: 0.0021274\ttotal: 7m 44s\tremaining: 2m 44s\n",
      "369:\tlearn: 0.0021151\ttotal: 7m 45s\tremaining: 2m 43s\n",
      "370:\tlearn: 0.0021080\ttotal: 7m 47s\tremaining: 2m 42s\n",
      "371:\tlearn: 0.0021004\ttotal: 7m 48s\tremaining: 2m 41s\n",
      "372:\tlearn: 0.0020977\ttotal: 7m 49s\tremaining: 2m 39s\n",
      "373:\tlearn: 0.0020876\ttotal: 7m 50s\tremaining: 2m 38s\n",
      "374:\tlearn: 0.0020775\ttotal: 7m 51s\tremaining: 2m 37s\n",
      "375:\tlearn: 0.0020700\ttotal: 7m 53s\tremaining: 2m 36s\n",
      "376:\tlearn: 0.0020541\ttotal: 7m 54s\tremaining: 2m 34s\n",
      "377:\tlearn: 0.0020406\ttotal: 7m 55s\tremaining: 2m 33s\n",
      "378:\tlearn: 0.0020334\ttotal: 7m 56s\tremaining: 2m 32s\n",
      "379:\tlearn: 0.0020184\ttotal: 7m 57s\tremaining: 2m 30s\n",
      "380:\tlearn: 0.0020090\ttotal: 7m 59s\tremaining: 2m 29s\n",
      "381:\tlearn: 0.0019991\ttotal: 8m\tremaining: 2m 28s\n",
      "382:\tlearn: 0.0019923\ttotal: 8m 1s\tremaining: 2m 27s\n",
      "383:\tlearn: 0.0019826\ttotal: 8m 2s\tremaining: 2m 25s\n",
      "384:\tlearn: 0.0019740\ttotal: 8m 3s\tremaining: 2m 24s\n",
      "385:\tlearn: 0.0019685\ttotal: 8m 5s\tremaining: 2m 23s\n",
      "386:\tlearn: 0.0019652\ttotal: 8m 6s\tremaining: 2m 21s\n",
      "387:\tlearn: 0.0019610\ttotal: 8m 7s\tremaining: 2m 20s\n",
      "388:\tlearn: 0.0019571\ttotal: 8m 8s\tremaining: 2m 19s\n",
      "389:\tlearn: 0.0019523\ttotal: 8m 9s\tremaining: 2m 18s\n",
      "390:\tlearn: 0.0019417\ttotal: 8m 11s\tremaining: 2m 16s\n",
      "391:\tlearn: 0.0019361\ttotal: 8m 12s\tremaining: 2m 15s\n",
      "392:\tlearn: 0.0019286\ttotal: 8m 13s\tremaining: 2m 14s\n",
      "393:\tlearn: 0.0019208\ttotal: 8m 14s\tremaining: 2m 13s\n",
      "394:\tlearn: 0.0019142\ttotal: 8m 15s\tremaining: 2m 11s\n",
      "395:\tlearn: 0.0019018\ttotal: 8m 16s\tremaining: 2m 10s\n",
      "396:\tlearn: 0.0018946\ttotal: 8m 18s\tremaining: 2m 9s\n",
      "397:\tlearn: 0.0018889\ttotal: 8m 19s\tremaining: 2m 8s\n",
      "398:\tlearn: 0.0018841\ttotal: 8m 20s\tremaining: 2m 6s\n",
      "399:\tlearn: 0.0018759\ttotal: 8m 21s\tremaining: 2m 5s\n",
      "400:\tlearn: 0.0018674\ttotal: 8m 23s\tremaining: 2m 4s\n",
      "401:\tlearn: 0.0018633\ttotal: 8m 24s\tremaining: 2m 2s\n",
      "402:\tlearn: 0.0018574\ttotal: 8m 25s\tremaining: 2m 1s\n",
      "403:\tlearn: 0.0018516\ttotal: 8m 26s\tremaining: 2m\n",
      "404:\tlearn: 0.0018430\ttotal: 8m 27s\tremaining: 1m 59s\n",
      "405:\tlearn: 0.0018337\ttotal: 8m 29s\tremaining: 1m 57s\n",
      "406:\tlearn: 0.0018216\ttotal: 8m 30s\tremaining: 1m 56s\n",
      "407:\tlearn: 0.0018114\ttotal: 8m 31s\tremaining: 1m 55s\n",
      "408:\tlearn: 0.0018014\ttotal: 8m 32s\tremaining: 1m 54s\n",
      "409:\tlearn: 0.0017970\ttotal: 8m 34s\tremaining: 1m 52s\n",
      "410:\tlearn: 0.0017917\ttotal: 8m 35s\tremaining: 1m 51s\n",
      "411:\tlearn: 0.0017854\ttotal: 8m 36s\tremaining: 1m 50s\n",
      "412:\tlearn: 0.0017824\ttotal: 8m 37s\tremaining: 1m 49s\n",
      "413:\tlearn: 0.0017772\ttotal: 8m 38s\tremaining: 1m 47s\n",
      "414:\tlearn: 0.0017735\ttotal: 8m 40s\tremaining: 1m 46s\n",
      "415:\tlearn: 0.0017669\ttotal: 8m 41s\tremaining: 1m 45s\n",
      "416:\tlearn: 0.0017641\ttotal: 8m 42s\tremaining: 1m 44s\n",
      "417:\tlearn: 0.0017586\ttotal: 8m 43s\tremaining: 1m 42s\n",
      "418:\tlearn: 0.0017511\ttotal: 8m 44s\tremaining: 1m 41s\n",
      "419:\tlearn: 0.0017484\ttotal: 8m 46s\tremaining: 1m 40s\n",
      "420:\tlearn: 0.0017452\ttotal: 8m 47s\tremaining: 1m 38s\n",
      "421:\tlearn: 0.0017403\ttotal: 8m 48s\tremaining: 1m 37s\n",
      "422:\tlearn: 0.0017332\ttotal: 8m 49s\tremaining: 1m 36s\n",
      "423:\tlearn: 0.0017311\ttotal: 8m 50s\tremaining: 1m 35s\n",
      "424:\tlearn: 0.0017197\ttotal: 8m 52s\tremaining: 1m 33s\n",
      "425:\tlearn: 0.0017082\ttotal: 8m 53s\tremaining: 1m 32s\n",
      "426:\tlearn: 0.0017037\ttotal: 8m 54s\tremaining: 1m 31s\n",
      "427:\tlearn: 0.0016985\ttotal: 8m 55s\tremaining: 1m 30s\n",
      "428:\tlearn: 0.0016931\ttotal: 8m 56s\tremaining: 1m 28s\n",
      "429:\tlearn: 0.0016912\ttotal: 8m 58s\tremaining: 1m 27s\n",
      "430:\tlearn: 0.0016850\ttotal: 8m 59s\tremaining: 1m 26s\n",
      "431:\tlearn: 0.0016789\ttotal: 9m\tremaining: 1m 25s\n",
      "432:\tlearn: 0.0016712\ttotal: 9m 1s\tremaining: 1m 23s\n",
      "433:\tlearn: 0.0016688\ttotal: 9m 2s\tremaining: 1m 22s\n",
      "434:\tlearn: 0.0016651\ttotal: 9m 3s\tremaining: 1m 21s\n",
      "435:\tlearn: 0.0016633\ttotal: 9m 5s\tremaining: 1m 20s\n",
      "436:\tlearn: 0.0016571\ttotal: 9m 6s\tremaining: 1m 18s\n",
      "437:\tlearn: 0.0016542\ttotal: 9m 7s\tremaining: 1m 17s\n",
      "438:\tlearn: 0.0016496\ttotal: 9m 8s\tremaining: 1m 16s\n",
      "439:\tlearn: 0.0016432\ttotal: 9m 9s\tremaining: 1m 14s\n",
      "440:\tlearn: 0.0016354\ttotal: 9m 11s\tremaining: 1m 13s\n",
      "441:\tlearn: 0.0016300\ttotal: 9m 12s\tremaining: 1m 12s\n",
      "442:\tlearn: 0.0016264\ttotal: 9m 13s\tremaining: 1m 11s\n",
      "443:\tlearn: 0.0016201\ttotal: 9m 14s\tremaining: 1m 9s\n",
      "444:\tlearn: 0.0016123\ttotal: 9m 15s\tremaining: 1m 8s\n",
      "445:\tlearn: 0.0016096\ttotal: 9m 16s\tremaining: 1m 7s\n",
      "446:\tlearn: 0.0016072\ttotal: 9m 18s\tremaining: 1m 6s\n",
      "447:\tlearn: 0.0016029\ttotal: 9m 19s\tremaining: 1m 4s\n",
      "448:\tlearn: 0.0015986\ttotal: 9m 20s\tremaining: 1m 3s\n",
      "449:\tlearn: 0.0015930\ttotal: 9m 21s\tremaining: 1m 2s\n",
      "450:\tlearn: 0.0015885\ttotal: 9m 22s\tremaining: 1m 1s\n",
      "451:\tlearn: 0.0015843\ttotal: 9m 24s\tremaining: 59.9s\n",
      "452:\tlearn: 0.0015781\ttotal: 9m 25s\tremaining: 58.7s\n",
      "453:\tlearn: 0.0015737\ttotal: 9m 26s\tremaining: 57.4s\n",
      "454:\tlearn: 0.0015720\ttotal: 9m 27s\tremaining: 56.2s\n",
      "455:\tlearn: 0.0015682\ttotal: 9m 28s\tremaining: 54.9s\n",
      "456:\tlearn: 0.0015675\ttotal: 9m 30s\tremaining: 53.6s\n",
      "457:\tlearn: 0.0015644\ttotal: 9m 31s\tremaining: 52.4s\n",
      "458:\tlearn: 0.0015597\ttotal: 9m 32s\tremaining: 51.1s\n",
      "459:\tlearn: 0.0015548\ttotal: 9m 33s\tremaining: 49.9s\n",
      "460:\tlearn: 0.0015488\ttotal: 9m 34s\tremaining: 48.6s\n",
      "461:\tlearn: 0.0015452\ttotal: 9m 36s\tremaining: 47.4s\n",
      "462:\tlearn: 0.0015423\ttotal: 9m 37s\tremaining: 46.1s\n",
      "463:\tlearn: 0.0015379\ttotal: 9m 38s\tremaining: 44.9s\n",
      "464:\tlearn: 0.0015330\ttotal: 9m 39s\tremaining: 43.6s\n",
      "465:\tlearn: 0.0015282\ttotal: 9m 40s\tremaining: 42.4s\n",
      "466:\tlearn: 0.0015206\ttotal: 9m 41s\tremaining: 41.1s\n",
      "467:\tlearn: 0.0015152\ttotal: 9m 43s\tremaining: 39.9s\n",
      "468:\tlearn: 0.0015079\ttotal: 9m 44s\tremaining: 38.6s\n",
      "469:\tlearn: 0.0015035\ttotal: 9m 45s\tremaining: 37.4s\n",
      "470:\tlearn: 0.0015018\ttotal: 9m 46s\tremaining: 36.1s\n",
      "471:\tlearn: 0.0014956\ttotal: 9m 47s\tremaining: 34.9s\n",
      "472:\tlearn: 0.0014923\ttotal: 9m 49s\tremaining: 33.6s\n",
      "473:\tlearn: 0.0014903\ttotal: 9m 50s\tremaining: 32.4s\n",
      "474:\tlearn: 0.0014848\ttotal: 9m 51s\tremaining: 31.1s\n",
      "475:\tlearn: 0.0014798\ttotal: 9m 52s\tremaining: 29.9s\n",
      "476:\tlearn: 0.0014788\ttotal: 9m 53s\tremaining: 28.6s\n",
      "477:\tlearn: 0.0014733\ttotal: 9m 55s\tremaining: 27.4s\n",
      "478:\tlearn: 0.0014692\ttotal: 9m 56s\tremaining: 26.1s\n",
      "479:\tlearn: 0.0014685\ttotal: 9m 57s\tremaining: 24.9s\n",
      "480:\tlearn: 0.0014649\ttotal: 9m 58s\tremaining: 23.7s\n",
      "481:\tlearn: 0.0014625\ttotal: 9m 59s\tremaining: 22.4s\n",
      "482:\tlearn: 0.0014594\ttotal: 10m 1s\tremaining: 21.2s\n",
      "483:\tlearn: 0.0014524\ttotal: 10m 2s\tremaining: 19.9s\n",
      "484:\tlearn: 0.0014494\ttotal: 10m 3s\tremaining: 18.7s\n",
      "485:\tlearn: 0.0014481\ttotal: 10m 4s\tremaining: 17.4s\n",
      "486:\tlearn: 0.0014478\ttotal: 10m 5s\tremaining: 16.2s\n",
      "487:\tlearn: 0.0014414\ttotal: 10m 6s\tremaining: 14.9s\n",
      "488:\tlearn: 0.0014366\ttotal: 10m 7s\tremaining: 13.7s\n",
      "489:\tlearn: 0.0014324\ttotal: 10m 8s\tremaining: 12.4s\n",
      "490:\tlearn: 0.0014297\ttotal: 10m 9s\tremaining: 11.2s\n",
      "491:\tlearn: 0.0014270\ttotal: 10m 11s\tremaining: 9.94s\n",
      "492:\tlearn: 0.0014250\ttotal: 10m 12s\tremaining: 8.69s\n",
      "493:\tlearn: 0.0014191\ttotal: 10m 13s\tremaining: 7.45s\n",
      "494:\tlearn: 0.0014146\ttotal: 10m 14s\tremaining: 6.21s\n",
      "495:\tlearn: 0.0014136\ttotal: 10m 15s\tremaining: 4.96s\n",
      "496:\tlearn: 0.0014129\ttotal: 10m 16s\tremaining: 3.72s\n",
      "497:\tlearn: 0.0014100\ttotal: 10m 17s\tremaining: 2.48s\n",
      "498:\tlearn: 0.0014093\ttotal: 10m 17s\tremaining: 1.24s\n",
      "499:\tlearn: 0.0014043\ttotal: 10m 18s\tremaining: 0us\n",
      "Accuracy: 0.9998709297494827\n",
      "\n",
      "Confusion Matrix:\n",
      " [[245790      2]\n",
      " [    62 250000]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    245792\n",
      "           1       1.00      1.00      1.00    250062\n",
      "\n",
      "    accuracy                           1.00    495854\n",
      "   macro avg       1.00      1.00      1.00    495854\n",
      "weighted avg       1.00      1.00      1.00    495854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Fraud'], axis=1)\n",
    "y = df['Fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a CatBoost Classifier\n",
    "model = CatBoostClassifier(iterations=500, depth=10, learning_rate=0.05, loss_function='MultiClass', random_seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, cat_features=None)  # You can specify categorical features if needed\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/part_D/imputed_partd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"PRSCRBR_NPI\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.0124007\ttotal: 3.66s\tremaining: 14.6s\n",
      "1:\tlearn: 1.6990359\ttotal: 7.82s\tremaining: 11.7s\n",
      "2:\tlearn: 1.4821639\ttotal: 11.6s\tremaining: 7.75s\n",
      "3:\tlearn: 1.3170938\ttotal: 14.6s\tremaining: 3.65s\n",
      "4:\tlearn: 1.1844165\ttotal: 17.9s\tremaining: 0us\n",
      "Accuracy: 0.9997649383660427\n",
      "\n",
      "Confusion Matrix:\n",
      " [[250939      0      0      0      0      0      0      0      0]\n",
      " [    18      0      0      0      0      0      0      0      0]\n",
      " [     3      0      0      0      0      0      0      0      0]\n",
      " [     3      0      0      0      0      0      0      0      0]\n",
      " [     9      0      0      0      0      0      0      0      0]\n",
      " [     9      0      0      0      0      0      0      0      0]\n",
      " [     2      0      0      0      0      0      0      0      0]\n",
      " [    13      0      0      0      0      0      0      0      0]\n",
      " [     2      0      0      0      0      0      0      0      0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    250939\n",
      "           2       0.00      0.00      0.00        18\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         9\n",
      "           8       0.00      0.00      0.00         9\n",
      "           9       0.00      0.00      0.00         2\n",
      "          11       0.00      0.00      0.00        13\n",
      "          12       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           1.00    250998\n",
      "   macro avg       0.11      0.11      0.11    250998\n",
      "weighted avg       1.00      1.00      1.00    250998\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Fraud','FraudType'], axis=1)\n",
    "y = df['FraudType']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a CatBoost Classifier\n",
    "model = CatBoostClassifier(iterations=5, depth=10, learning_rate=0.05, loss_function='MultiClass', random_seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, cat_features=None)  # You can specify categorical features if needed\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/part_D/partd_rus_type_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"Unnamed: 0.1\",\"PRSCRBR_NPI\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.3838753\ttotal: 17.6ms\tremaining: 70.6ms\n",
      "1:\tlearn: 2.3726585\ttotal: 21.4ms\tremaining: 32.1ms\n",
      "2:\tlearn: 2.3583830\ttotal: 34.9ms\tremaining: 23.3ms\n",
      "3:\tlearn: 2.3451491\ttotal: 38.4ms\tremaining: 9.59ms\n",
      "4:\tlearn: 2.3309701\ttotal: 51.5ms\tremaining: 0us\n",
      "Accuracy: 0.0\n",
      "\n",
      "Confusion Matrix:\n",
      " [[0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       1.0\n",
      "           4       0.00      0.00      0.00       0.0\n",
      "           5       0.00      0.00      0.00       0.0\n",
      "           9       0.00      0.00      0.00       1.0\n",
      "          11       0.00      0.00      0.00       1.0\n",
      "          12       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00       3.0\n",
      "   macro avg       0.00      0.00      0.00       3.0\n",
      "weighted avg       0.00      0.00      0.00       3.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['FraudType'], axis=1)\n",
    "y = df['FraudType']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a CatBoost Classifier\n",
    "model = CatBoostClassifier(iterations=5, depth=10, learning_rate=0.05, loss_function='MultiClass', random_seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, cat_features=None)  # You can specify categorical features if needed\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/part_D/partd_ros_type_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"Unnamed: 0.1\",\"PRSCRBR_NPI\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prscrbr_Crdntls</th>\n",
       "      <th>Prscrbr_Gndr</th>\n",
       "      <th>Prscrbr_Type</th>\n",
       "      <th>Prscrbr_Type_src</th>\n",
       "      <th>Tot_Clms</th>\n",
       "      <th>Tot_30day_Fills</th>\n",
       "      <th>Tot_Drug_Cst</th>\n",
       "      <th>Tot_Day_Suply</th>\n",
       "      <th>Tot_Benes</th>\n",
       "      <th>GE65_Sprsn_Flag</th>\n",
       "      <th>...</th>\n",
       "      <th>Bene_Race_Wht_Cnt</th>\n",
       "      <th>Bene_Race_Black_Cnt</th>\n",
       "      <th>Bene_Race_Api_Cnt</th>\n",
       "      <th>Bene_Race_Hspnc_Cnt</th>\n",
       "      <th>Bene_Race_Natind_Cnt</th>\n",
       "      <th>Bene_Race_Othr_Cnt</th>\n",
       "      <th>Bene_Dual_Cnt</th>\n",
       "      <th>Bene_Ndual_Cnt</th>\n",
       "      <th>Bene_Avg_Risk_Scre</th>\n",
       "      <th>FraudType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>369.800000</td>\n",
       "      <td>20606.08</td>\n",
       "      <td>8621.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>67.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2.245800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>2145.666667</td>\n",
       "      <td>79803.65</td>\n",
       "      <td>60953.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>130.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.695165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57.700000</td>\n",
       "      <td>327.34</td>\n",
       "      <td>554.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.006070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3535</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>128.52</td>\n",
       "      <td>181.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.251869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6421</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>3834.98</td>\n",
       "      <td>1366.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.919074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17565725</th>\n",
       "      <td>6109</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>14205.65</td>\n",
       "      <td>4626.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.319562</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17565726</th>\n",
       "      <td>6109</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>14205.65</td>\n",
       "      <td>4626.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.319562</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17565727</th>\n",
       "      <td>6109</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>14205.65</td>\n",
       "      <td>4626.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.319562</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17565728</th>\n",
       "      <td>6109</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>14205.65</td>\n",
       "      <td>4626.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.319562</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17565729</th>\n",
       "      <td>6109</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>14205.65</td>\n",
       "      <td>4626.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.319562</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17565730 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Prscrbr_Crdntls  Prscrbr_Gndr  Prscrbr_Type  Prscrbr_Type_src  \\\n",
       "0                    7632           0.0            86               1.0   \n",
       "1                    7632           0.0             9               1.0   \n",
       "2                    4394           0.0            42               1.0   \n",
       "3                    3535           1.0            42               1.0   \n",
       "4                    6421           1.0           120               1.0   \n",
       "...                   ...           ...           ...               ...   \n",
       "17565725             6109           1.0           158               1.0   \n",
       "17565726             6109           1.0           158               1.0   \n",
       "17565727             6109           1.0           158               1.0   \n",
       "17565728             6109           1.0           158               1.0   \n",
       "17565729             6109           1.0           158               1.0   \n",
       "\n",
       "          Tot_Clms  Tot_30day_Fills  Tot_Drug_Cst  Tot_Day_Suply  Tot_Benes  \\\n",
       "0            324.0       369.800000      20606.08         8621.0      106.0   \n",
       "1           1992.0      2145.666667      79803.65        60953.0      228.0   \n",
       "2             57.0        57.700000        327.34          554.0       43.0   \n",
       "3             18.0        18.000000        128.52          181.0       16.0   \n",
       "4             37.0        47.000000       3834.98         1366.0       17.0   \n",
       "...            ...              ...           ...            ...        ...   \n",
       "17565725     167.0       206.000000      14205.65         4626.0       78.0   \n",
       "17565726     167.0       206.000000      14205.65         4626.0       78.0   \n",
       "17565727     167.0       206.000000      14205.65         4626.0       78.0   \n",
       "17565728     167.0       206.000000      14205.65         4626.0       78.0   \n",
       "17565729     167.0       206.000000      14205.65         4626.0       78.0   \n",
       "\n",
       "          GE65_Sprsn_Flag  ...  Bene_Race_Wht_Cnt  Bene_Race_Black_Cnt  \\\n",
       "0                     1.0  ...               67.0                 27.0   \n",
       "1                     1.0  ...              130.0                 81.0   \n",
       "2                     1.0  ...               41.0                  0.0   \n",
       "3                     1.0  ...               12.0                  0.0   \n",
       "4                     1.0  ...               12.0                  0.0   \n",
       "...                   ...  ...                ...                  ...   \n",
       "17565725              1.0  ...               54.0                 22.0   \n",
       "17565726              1.0  ...               54.0                 22.0   \n",
       "17565727              1.0  ...               54.0                 22.0   \n",
       "17565728              1.0  ...               54.0                 22.0   \n",
       "17565729              1.0  ...               54.0                 22.0   \n",
       "\n",
       "          Bene_Race_Api_Cnt  Bene_Race_Hspnc_Cnt  Bene_Race_Natind_Cnt  \\\n",
       "0                       0.0                 13.0                   0.0   \n",
       "1                       0.0                 12.0                   0.0   \n",
       "2                       0.0                  0.0                   0.0   \n",
       "3                       0.0                  0.0                   0.0   \n",
       "4                       0.0                  0.0                   0.0   \n",
       "...                     ...                  ...                   ...   \n",
       "17565725                0.0                  0.0                   0.0   \n",
       "17565726                0.0                  0.0                   0.0   \n",
       "17565727                0.0                  0.0                   0.0   \n",
       "17565728                0.0                  0.0                   0.0   \n",
       "17565729                0.0                  0.0                   0.0   \n",
       "\n",
       "          Bene_Race_Othr_Cnt  Bene_Dual_Cnt  Bene_Ndual_Cnt  \\\n",
       "0                        0.0           28.0            78.0   \n",
       "1                        0.0          125.0           103.0   \n",
       "2                        0.0            0.0            43.0   \n",
       "3                        0.0            0.0            12.0   \n",
       "4                        0.0           11.0            11.0   \n",
       "...                      ...            ...             ...   \n",
       "17565725                 0.0           13.0            65.0   \n",
       "17565726                 0.0           13.0            65.0   \n",
       "17565727                 0.0           13.0            65.0   \n",
       "17565728                 0.0           13.0            65.0   \n",
       "17565729                 0.0           13.0            65.0   \n",
       "\n",
       "          Bene_Avg_Risk_Scre  FraudType  \n",
       "0                   2.245800          0  \n",
       "1                   1.695165          0  \n",
       "2                   1.006070          0  \n",
       "3                   1.251869          0  \n",
       "4                   4.919074          0  \n",
       "...                      ...        ...  \n",
       "17565725            1.319562         13  \n",
       "17565726            1.319562         13  \n",
       "17565727            1.319562         13  \n",
       "17565728            1.319562         13  \n",
       "17565729            1.319562         13  \n",
       "\n",
       "[17565730 rows x 71 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X = df.drop(['FraudType'], axis=1)\n",
    "y = df['FraudType']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a CatBoost Classifier\n",
    "model = CatBoostClassifier(iterations=3, depth=10, learning_rate=0.05, loss_function='MultiClass', random_seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, cat_features=None)  # You can specify categorical features if needed\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
