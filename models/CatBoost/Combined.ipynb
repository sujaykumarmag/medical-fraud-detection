{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/Combined/imputed_combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Rndrng_Prvdr_Crdntls',\n",
    "'Rndrng_Prvdr_Gndr', \n",
    "'Rndrng_Prvdr_Type',\n",
    "'Rndrng_Prvdr_Mdcr_Prtcptg_Ind', \n",
    "'Tot_HCPCS_Cds', \n",
    "'Tot_Benes_x',\n",
    "'Tot_Srvcs', \n",
    "'Tot_Sbmtd_Chrg', \n",
    "'Tot_Mdcr_Alowd_Amt',\n",
    "'Tot_Mdcr_Pymt_Amt', \n",
    "'Tot_Mdcr_Stdzd_Amt', \n",
    "'Drug_Sprsn_Ind_x',\n",
    "'Drug_Tot_HCPCS_Cds', \n",
    "'Drug_Tot_Benes', \n",
    "'Drug_Tot_Srvcs',\n",
    "'Drug_Sbmtd_Chrg', \n",
    "'Drug_Mdcr_Alowd_Amt', \n",
    "'Drug_Mdcr_Pymt_Amt',\n",
    "       'Drug_Mdcr_Stdzd_Amt', 'Med_Sprsn_Ind', 'Med_Tot_HCPCS_Cds',\n",
    "       'Med_Tot_Benes', 'Med_Tot_Srvcs', 'Med_Sbmtd_Chrg',\n",
    "       'Med_Mdcr_Alowd_Amt', 'Med_Mdcr_Pymt_Amt', 'Med_Mdcr_Stdzd_Amt',\n",
    "       'Bene_Avg_Age_x', 'Bene_Age_LT_65_Cnt_x', 'Bene_Age_65_74_Cnt_x',\n",
    "       'Bene_Age_75_84_Cnt_x', 'Bene_Age_GT_84_Cnt_x', 'Bene_Feml_Cnt_x',\n",
    "       'Bene_Male_Cnt_x', 'Bene_Race_Wht_Cnt_x', 'Bene_Race_Black_Cnt_x',\n",
    "       'Bene_Race_API_Cnt', 'Bene_Race_Hspnc_Cnt_x',\n",
    "       'Bene_Race_NatInd_Cnt', 'Bene_Race_Othr_Cnt_x', 'Bene_Dual_Cnt_x',\n",
    "       'Bene_Ndual_Cnt_x', 'Bene_CC_AF_Pct_x', 'Bene_CC_Alzhmr_Pct_x',\n",
    "       'Bene_CC_Asthma_Pct_x', 'Bene_CC_Cncr_Pct_x', 'Bene_CC_CHF_Pct_x',\n",
    "       'Bene_CC_CKD_Pct_x', 'Bene_CC_COPD_Pct_x', 'Bene_CC_Dprssn_Pct_x',\n",
    "       'Bene_CC_Dbts_Pct_x', 'Bene_CC_Hyplpdma_Pct_x',\n",
    "       'Bene_CC_Hyprtnsn_Pct_x', 'Bene_CC_IHD_Pct_x', 'Bene_CC_Opo_Pct_x',\n",
    "       'Bene_CC_RAOA_Pct_x', 'Bene_CC_Sz_Pct_x', 'Bene_CC_Strok_Pct_x',\n",
    "       'Bene_Avg_Risk_Scre_x', 'Rndrng_NPI', 'Fraud_x', 'FraudType_x',\n",
    "'Prscrbr_Crdntls',\n",
    "       'Prscrbr_Type_src', 'Tot_Clms', 'Tot_30day_Fills',\n",
    "       'Tot_Drug_Cst', 'Tot_Day_Suply', 'GE65_Sprsn_Flag',\n",
    "       'GE65_Tot_Clms', 'GE65_Tot_30day_Fills', 'GE65_Tot_Drug_Cst',\n",
    "       'GE65_Tot_Day_Suply', 'GE65_Bene_Sprsn_Flag', 'GE65_Tot_Benes',\n",
    "       'Brnd_Sprsn_Flag', 'Brnd_Tot_Clms', 'Brnd_Tot_Drug_Cst',\n",
    "       'Gnrc_Sprsn_Flag', 'Gnrc_Tot_Clms', 'Gnrc_Tot_Drug_Cst',\n",
    "       'Othr_Sprsn_Flag', 'Othr_Tot_Clms', 'Othr_Tot_Drug_Cst',\n",
    "       'MAPD_Sprsn_Flag', 'MAPD_Tot_Clms', 'MAPD_Tot_Drug_Cst',\n",
    "       'PDP_Sprsn_Flag', 'PDP_Tot_Clms', 'PDP_Tot_Drug_Cst',\n",
    "       'LIS_Sprsn_Flag', 'LIS_Tot_Clms', 'LIS_Drug_Cst',\n",
    "       'NonLIS_Sprsn_Flag', 'NonLIS_Tot_Clms', 'NonLIS_Drug_Cst',\n",
    "       'Opioid_Tot_Clms', 'Opioid_Tot_Drug_Cst', 'Opioid_Tot_Suply',\n",
    "       'Opioid_Tot_Benes', 'Opioid_Prscrbr_Rate', 'Opioid_LA_Tot_Clms',\n",
    "       'Opioid_LA_Tot_Drug_Cst', 'Opioid_LA_Tot_Suply',\n",
    "       'Opioid_LA_Tot_Benes', 'Opioid_LA_Prscrbr_Rate', 'Antbtc_Tot_Clms',\n",
    "       'Antbtc_Tot_Drug_Cst', 'Antbtc_Tot_Benes',\n",
    "       'Antpsyct_GE65_Sprsn_Flag', 'Antpsyct_GE65_Tot_Clms',\n",
    "       'Antpsyct_GE65_Tot_Drug_Cst', 'Antpsyct_GE65_Tot_Benes',\n",
    "       'Bene_Race_Api_Cnt_x', \n",
    "       'Bene_Race_Natind_Cnt_x', \n",
    "       'Rfrg_Prvdr_Type_Flag', 'Tot_Suplrs', 'Tot_Suplr_HCPCS_Cds',\n",
    "       'Tot_Suplr_Benes', 'Tot_Suplr_Clms', 'Tot_Suplr_Srvcs',\n",
    "       'Suplr_Sbmtd_Chrgs', 'Suplr_Mdcr_Alowd_Amt', 'Suplr_Mdcr_Pymt_Amt',\n",
    "       'Suplr_Mdcr_Stdzd_Pymt_Amt', 'DME_Sprsn_Ind', 'DME_Tot_Suplrs',\n",
    "       'DME_Tot_Suplr_HCPCS_Cds', 'DME_Tot_Suplr_Benes',\n",
    "       'DME_Tot_Suplr_Clms', 'DME_Tot_Suplr_Srvcs',\n",
    "       'DME_Suplr_Sbmtd_Chrgs', 'DME_Suplr_Mdcr_Alowd_Amt',\n",
    "       'DME_Suplr_Mdcr_Pymt_Amt', 'DME_Suplr_Mdcr_Stdzd_Pymt_Amt',\n",
    "       'POS_Sprsn_Ind', 'POS_Tot_Suplrs', 'POS_Tot_Suplr_HCPCS_Cds',\n",
    "       'POS_Tot_Suplr_Benes', 'POS_Tot_Suplr_Clms', 'POS_Tot_Suplr_Srvcs',\n",
    "       'POS_Suplr_Sbmtd_Chrgs', 'POS_Suplr_Mdcr_Alowd_Amt',\n",
    "       'POS_Suplr_Mdcr_Pymt_Amt', 'POS_Suplr_Mdcr_Stdzd_Pymt_Amt',\n",
    "       'Drug_Tot_Suplrs', 'Drug_Tot_Suplr_HCPCS_Cds',\n",
    "       'Drug_Tot_Suplr_Benes', 'Drug_Tot_Suplr_Clms',\n",
    "       'Drug_Tot_Suplr_Srvcs', 'Drug_Suplr_Sbmtd_Chrgs',\n",
    "       'Drug_Suplr_Mdcr_Alowd_Amt', 'Drug_Suplr_Mdcr_Pymt_Amt',\n",
    "       'Drug_Suplr_Mdcr_Stdzd_Pymt_Amt', 'Bene_Avg_Age',\n",
    "       'Fraud', 'FraudType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Fraud_x\",\"FraudType_x\",\"Rndrng_NPI\",],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rndrng_Prvdr_Crdntls</th>\n",
       "      <th>Rndrng_Prvdr_Gndr</th>\n",
       "      <th>Rndrng_Prvdr_Type</th>\n",
       "      <th>Rndrng_Prvdr_Mdcr_Prtcptg_Ind</th>\n",
       "      <th>Tot_HCPCS_Cds</th>\n",
       "      <th>Tot_Benes_x</th>\n",
       "      <th>Tot_Srvcs</th>\n",
       "      <th>Tot_Sbmtd_Chrg</th>\n",
       "      <th>Tot_Mdcr_Alowd_Amt</th>\n",
       "      <th>Tot_Mdcr_Pymt_Amt</th>\n",
       "      <th>...</th>\n",
       "      <th>Drug_Tot_Suplr_Benes</th>\n",
       "      <th>Drug_Tot_Suplr_Clms</th>\n",
       "      <th>Drug_Tot_Suplr_Srvcs</th>\n",
       "      <th>Drug_Suplr_Sbmtd_Chrgs</th>\n",
       "      <th>Drug_Suplr_Mdcr_Alowd_Amt</th>\n",
       "      <th>Drug_Suplr_Mdcr_Pymt_Amt</th>\n",
       "      <th>Drug_Suplr_Mdcr_Stdzd_Pymt_Amt</th>\n",
       "      <th>Bene_Avg_Age</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>FraudType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>402812.00</td>\n",
       "      <td>85319.63</td>\n",
       "      <td>69175.78</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>71.300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>149315.45</td>\n",
       "      <td>49859.16</td>\n",
       "      <td>34786.35</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>7051.88</td>\n",
       "      <td>2010.45</td>\n",
       "      <td>1759.72</td>\n",
       "      <td>1738.48</td>\n",
       "      <td>76.060606</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4737</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>238600.00</td>\n",
       "      <td>149023.89</td>\n",
       "      <td>114975.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>73.105263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>92.0</td>\n",
       "      <td>739.0</td>\n",
       "      <td>3916.0</td>\n",
       "      <td>777162.00</td>\n",
       "      <td>277266.94</td>\n",
       "      <td>210439.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>139700.00</td>\n",
       "      <td>71391.30</td>\n",
       "      <td>52741.85</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>714.00</td>\n",
       "      <td>594.00</td>\n",
       "      <td>445.62</td>\n",
       "      <td>439.79</td>\n",
       "      <td>68.360000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334369</th>\n",
       "      <td>9043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>2272.0</td>\n",
       "      <td>587582.00</td>\n",
       "      <td>203150.57</td>\n",
       "      <td>157754.65</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>462.00</td>\n",
       "      <td>462.00</td>\n",
       "      <td>339.49</td>\n",
       "      <td>336.31</td>\n",
       "      <td>77.434783</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334370</th>\n",
       "      <td>7310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>769.0</td>\n",
       "      <td>109972.88</td>\n",
       "      <td>53888.01</td>\n",
       "      <td>40893.46</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2387.0</td>\n",
       "      <td>2590.96</td>\n",
       "      <td>752.34</td>\n",
       "      <td>525.13</td>\n",
       "      <td>517.40</td>\n",
       "      <td>70.727273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334371</th>\n",
       "      <td>3446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>6097.0</td>\n",
       "      <td>696266.98</td>\n",
       "      <td>513866.65</td>\n",
       "      <td>390895.36</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>7590.00</td>\n",
       "      <td>2046.00</td>\n",
       "      <td>1569.00</td>\n",
       "      <td>1547.27</td>\n",
       "      <td>80.732558</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334372</th>\n",
       "      <td>7310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>182515.00</td>\n",
       "      <td>93505.14</td>\n",
       "      <td>68252.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75.857143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334373</th>\n",
       "      <td>17582</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>884.0</td>\n",
       "      <td>340479.02</td>\n",
       "      <td>90924.61</td>\n",
       "      <td>74063.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>79.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>334374 rows Ã— 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rndrng_Prvdr_Crdntls  Rndrng_Prvdr_Gndr  Rndrng_Prvdr_Type  \\\n",
       "0                       7310                0.0                 39   \n",
       "1                       9043                0.0                 24   \n",
       "2                       4737                1.0                 39   \n",
       "3                       7895                0.0                 91   \n",
       "4                       9043                1.0                 24   \n",
       "...                      ...                ...                ...   \n",
       "334369                  9043                1.0                 39   \n",
       "334370                  7310                0.0                 24   \n",
       "334371                  3446                0.0                 39   \n",
       "334372                  7310                1.0                 39   \n",
       "334373                 17582                1.0                 39   \n",
       "\n",
       "        Rndrng_Prvdr_Mdcr_Prtcptg_Ind  Tot_HCPCS_Cds  Tot_Benes_x  Tot_Srvcs  \\\n",
       "0                                   1           16.0        291.0      764.0   \n",
       "1                                   1           34.0        251.0      660.0   \n",
       "2                                   1           35.0        359.0     1400.0   \n",
       "3                                   1           92.0        739.0     3916.0   \n",
       "4                                   1           43.0        285.0      922.0   \n",
       "...                               ...            ...          ...        ...   \n",
       "334369                              1           37.0        365.0     2272.0   \n",
       "334370                              1           50.0        138.0      769.0   \n",
       "334371                              1           34.0       1215.0     6097.0   \n",
       "334372                              1           40.0        333.0     1093.0   \n",
       "334373                              1           15.0        407.0      884.0   \n",
       "\n",
       "        Tot_Sbmtd_Chrg  Tot_Mdcr_Alowd_Amt  Tot_Mdcr_Pymt_Amt  ...  \\\n",
       "0            402812.00            85319.63           69175.78  ...   \n",
       "1            149315.45            49859.16           34786.35  ...   \n",
       "2            238600.00           149023.89          114975.60  ...   \n",
       "3            777162.00           277266.94          210439.56  ...   \n",
       "4            139700.00            71391.30           52741.85  ...   \n",
       "...                ...                 ...                ...  ...   \n",
       "334369       587582.00           203150.57          157754.65  ...   \n",
       "334370       109972.88            53888.01           40893.46  ...   \n",
       "334371       696266.98           513866.65          390895.36  ...   \n",
       "334372       182515.00            93505.14           68252.03  ...   \n",
       "334373       340479.02            90924.61           74063.76  ...   \n",
       "\n",
       "        Drug_Tot_Suplr_Benes  Drug_Tot_Suplr_Clms  Drug_Tot_Suplr_Srvcs  \\\n",
       "0                        0.0                  0.0                   0.0   \n",
       "1                       17.0                 51.0                2002.0   \n",
       "2                        0.0                  0.0                   0.0   \n",
       "3                        0.0                  0.0                   0.0   \n",
       "4                       11.0                 18.0                  18.0   \n",
       "...                      ...                  ...                   ...   \n",
       "334369                  11.0                 12.0                  12.0   \n",
       "334370                  11.0                 15.0                2387.0   \n",
       "334371                  16.0                 61.0                  61.0   \n",
       "334372                   0.0                  0.0                   0.0   \n",
       "334373                   0.0                  0.0                   0.0   \n",
       "\n",
       "        Drug_Suplr_Sbmtd_Chrgs  Drug_Suplr_Mdcr_Alowd_Amt  \\\n",
       "0                         0.00                       0.00   \n",
       "1                      7051.88                    2010.45   \n",
       "2                         0.00                       0.00   \n",
       "3                         0.00                       0.00   \n",
       "4                       714.00                     594.00   \n",
       "...                        ...                        ...   \n",
       "334369                  462.00                     462.00   \n",
       "334370                 2590.96                     752.34   \n",
       "334371                 7590.00                    2046.00   \n",
       "334372                    0.00                       0.00   \n",
       "334373                    0.00                       0.00   \n",
       "\n",
       "        Drug_Suplr_Mdcr_Pymt_Amt  Drug_Suplr_Mdcr_Stdzd_Pymt_Amt  \\\n",
       "0                           0.00                            0.00   \n",
       "1                        1759.72                         1738.48   \n",
       "2                           0.00                            0.00   \n",
       "3                           0.00                            0.00   \n",
       "4                         445.62                          439.79   \n",
       "...                          ...                             ...   \n",
       "334369                    339.49                          336.31   \n",
       "334370                    525.13                          517.40   \n",
       "334371                   1569.00                         1547.27   \n",
       "334372                      0.00                            0.00   \n",
       "334373                      0.00                            0.00   \n",
       "\n",
       "        Bene_Avg_Age  Fraud  FraudType  \n",
       "0          71.300000      0          0  \n",
       "1          76.060606      0          0  \n",
       "2          73.105263      0          0  \n",
       "3          74.000000      0          0  \n",
       "4          68.360000      0          0  \n",
       "...              ...    ...        ...  \n",
       "334369     77.434783      0          0  \n",
       "334370     70.727273      0          0  \n",
       "334371     80.732558      0          0  \n",
       "334372     75.857143      0          0  \n",
       "334373     79.100000      0          0  \n",
       "\n",
       "[334374 rows x 154 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6444629\ttotal: 897ms\tremaining: 7m 27s\n",
      "1:\tlearn: 0.6005719\ttotal: 1.68s\tremaining: 6m 58s\n",
      "2:\tlearn: 0.5605914\ttotal: 2.58s\tremaining: 7m 8s\n",
      "3:\tlearn: 0.5241069\ttotal: 3.34s\tremaining: 6m 54s\n",
      "4:\tlearn: 0.4906333\ttotal: 4.15s\tremaining: 6m 50s\n",
      "5:\tlearn: 0.4598803\ttotal: 4.99s\tremaining: 6m 51s\n",
      "6:\tlearn: 0.4315481\ttotal: 5.86s\tremaining: 6m 52s\n",
      "7:\tlearn: 0.4053871\ttotal: 6.68s\tremaining: 6m 51s\n",
      "8:\tlearn: 0.3811114\ttotal: 7.56s\tremaining: 6m 52s\n",
      "9:\tlearn: 0.3586078\ttotal: 8.38s\tremaining: 6m 50s\n",
      "10:\tlearn: 0.3376548\ttotal: 9.31s\tremaining: 6m 53s\n",
      "11:\tlearn: 0.3181865\ttotal: 10s\tremaining: 6m 48s\n",
      "12:\tlearn: 0.3000396\ttotal: 10.9s\tremaining: 6m 47s\n",
      "13:\tlearn: 0.2831079\ttotal: 11.8s\tremaining: 6m 48s\n",
      "14:\tlearn: 0.2672055\ttotal: 12.5s\tremaining: 6m 44s\n",
      "15:\tlearn: 0.2523418\ttotal: 13.2s\tremaining: 6m 39s\n",
      "16:\tlearn: 0.2385015\ttotal: 14.2s\tremaining: 6m 44s\n",
      "17:\tlearn: 0.2255560\ttotal: 15.1s\tremaining: 6m 44s\n",
      "18:\tlearn: 0.2133578\ttotal: 15.9s\tremaining: 6m 42s\n",
      "19:\tlearn: 0.2018787\ttotal: 16.8s\tremaining: 6m 42s\n",
      "20:\tlearn: 0.1911304\ttotal: 17.6s\tremaining: 6m 41s\n",
      "21:\tlearn: 0.1810176\ttotal: 18.5s\tremaining: 6m 42s\n",
      "22:\tlearn: 0.1714560\ttotal: 19.5s\tremaining: 6m 43s\n",
      "23:\tlearn: 0.1624171\ttotal: 20.3s\tremaining: 6m 42s\n",
      "24:\tlearn: 0.1538837\ttotal: 21.1s\tremaining: 6m 40s\n",
      "25:\tlearn: 0.1459310\ttotal: 22s\tremaining: 6m 41s\n",
      "26:\tlearn: 0.1384119\ttotal: 22.8s\tremaining: 6m 40s\n",
      "27:\tlearn: 0.1313154\ttotal: 23.7s\tremaining: 6m 39s\n",
      "28:\tlearn: 0.1245508\ttotal: 24.5s\tremaining: 6m 37s\n",
      "29:\tlearn: 0.1181429\ttotal: 25.2s\tremaining: 6m 35s\n",
      "30:\tlearn: 0.1121147\ttotal: 26.2s\tremaining: 6m 35s\n",
      "31:\tlearn: 0.1064149\ttotal: 27s\tremaining: 6m 34s\n",
      "32:\tlearn: 0.1010101\ttotal: 27.8s\tremaining: 6m 32s\n",
      "33:\tlearn: 0.0959414\ttotal: 28.6s\tremaining: 6m 32s\n",
      "34:\tlearn: 0.0910889\ttotal: 29.4s\tremaining: 6m 30s\n",
      "35:\tlearn: 0.0865126\ttotal: 30.3s\tremaining: 6m 30s\n",
      "36:\tlearn: 0.0822169\ttotal: 31.1s\tremaining: 6m 29s\n",
      "37:\tlearn: 0.0781255\ttotal: 31.9s\tremaining: 6m 28s\n",
      "38:\tlearn: 0.0742422\ttotal: 32.8s\tremaining: 6m 28s\n",
      "39:\tlearn: 0.0705454\ttotal: 33.6s\tremaining: 6m 26s\n",
      "40:\tlearn: 0.0670673\ttotal: 34.5s\tremaining: 6m 25s\n",
      "41:\tlearn: 0.0637619\ttotal: 35.2s\tremaining: 6m 24s\n",
      "42:\tlearn: 0.0606572\ttotal: 36.1s\tremaining: 6m 23s\n",
      "43:\tlearn: 0.0577377\ttotal: 37s\tremaining: 6m 23s\n",
      "44:\tlearn: 0.0549497\ttotal: 37.8s\tremaining: 6m 22s\n",
      "45:\tlearn: 0.0522540\ttotal: 38.7s\tremaining: 6m 21s\n",
      "46:\tlearn: 0.0497311\ttotal: 39.6s\tremaining: 6m 21s\n",
      "47:\tlearn: 0.0473225\ttotal: 40.3s\tremaining: 6m 19s\n",
      "48:\tlearn: 0.0450334\ttotal: 41.2s\tremaining: 6m 19s\n",
      "49:\tlearn: 0.0428727\ttotal: 42.1s\tremaining: 6m 18s\n",
      "50:\tlearn: 0.0408350\ttotal: 42.8s\tremaining: 6m 17s\n",
      "51:\tlearn: 0.0389036\ttotal: 43.8s\tremaining: 6m 17s\n",
      "52:\tlearn: 0.0370343\ttotal: 44.6s\tremaining: 6m 16s\n",
      "53:\tlearn: 0.0352801\ttotal: 45.4s\tremaining: 6m 15s\n",
      "54:\tlearn: 0.0335911\ttotal: 46.3s\tremaining: 6m 14s\n",
      "55:\tlearn: 0.0319987\ttotal: 47.2s\tremaining: 6m 13s\n",
      "56:\tlearn: 0.0304967\ttotal: 48s\tremaining: 6m 12s\n",
      "57:\tlearn: 0.0290803\ttotal: 48.9s\tremaining: 6m 12s\n",
      "58:\tlearn: 0.0277113\ttotal: 49.6s\tremaining: 6m 11s\n",
      "59:\tlearn: 0.0264021\ttotal: 50.5s\tremaining: 6m 10s\n",
      "60:\tlearn: 0.0251849\ttotal: 51.4s\tremaining: 6m 9s\n",
      "61:\tlearn: 0.0240162\ttotal: 52.2s\tremaining: 6m 9s\n",
      "62:\tlearn: 0.0229099\ttotal: 53.2s\tremaining: 6m 8s\n",
      "63:\tlearn: 0.0218833\ttotal: 54s\tremaining: 6m 7s\n",
      "64:\tlearn: 0.0208758\ttotal: 54.8s\tremaining: 6m 6s\n",
      "65:\tlearn: 0.0199142\ttotal: 55.7s\tremaining: 6m 6s\n",
      "66:\tlearn: 0.0190144\ttotal: 56.5s\tremaining: 6m 4s\n",
      "67:\tlearn: 0.0181678\ttotal: 57.4s\tremaining: 6m 4s\n",
      "68:\tlearn: 0.0173357\ttotal: 58.1s\tremaining: 6m 3s\n",
      "69:\tlearn: 0.0165533\ttotal: 58.9s\tremaining: 6m 2s\n",
      "70:\tlearn: 0.0158168\ttotal: 59.9s\tremaining: 6m 1s\n",
      "71:\tlearn: 0.0151148\ttotal: 1m\tremaining: 6m\n",
      "72:\tlearn: 0.0144446\ttotal: 1m 1s\tremaining: 5m 59s\n",
      "73:\tlearn: 0.0138101\ttotal: 1m 2s\tremaining: 5m 58s\n",
      "74:\tlearn: 0.0131958\ttotal: 1m 3s\tremaining: 5m 57s\n",
      "75:\tlearn: 0.0126276\ttotal: 1m 4s\tremaining: 5m 57s\n",
      "76:\tlearn: 0.0120911\ttotal: 1m 4s\tremaining: 5m 56s\n",
      "77:\tlearn: 0.0115631\ttotal: 1m 5s\tremaining: 5m 55s\n",
      "78:\tlearn: 0.0110660\ttotal: 1m 6s\tremaining: 5m 54s\n",
      "79:\tlearn: 0.0106021\ttotal: 1m 7s\tremaining: 5m 53s\n",
      "80:\tlearn: 0.0101667\ttotal: 1m 8s\tremaining: 5m 53s\n",
      "81:\tlearn: 0.0097496\ttotal: 1m 9s\tremaining: 5m 52s\n",
      "82:\tlearn: 0.0093539\ttotal: 1m 9s\tremaining: 5m 51s\n",
      "83:\tlearn: 0.0089636\ttotal: 1m 10s\tremaining: 5m 51s\n",
      "84:\tlearn: 0.0085931\ttotal: 1m 11s\tremaining: 5m 50s\n",
      "85:\tlearn: 0.0082474\ttotal: 1m 12s\tremaining: 5m 49s\n",
      "86:\tlearn: 0.0079109\ttotal: 1m 13s\tremaining: 5m 48s\n",
      "87:\tlearn: 0.0075944\ttotal: 1m 14s\tremaining: 5m 48s\n",
      "88:\tlearn: 0.0072917\ttotal: 1m 15s\tremaining: 5m 47s\n",
      "89:\tlearn: 0.0070064\ttotal: 1m 16s\tremaining: 5m 46s\n",
      "90:\tlearn: 0.0067383\ttotal: 1m 16s\tremaining: 5m 45s\n",
      "91:\tlearn: 0.0064806\ttotal: 1m 17s\tremaining: 5m 44s\n",
      "92:\tlearn: 0.0062380\ttotal: 1m 18s\tremaining: 5m 43s\n",
      "93:\tlearn: 0.0060043\ttotal: 1m 19s\tremaining: 5m 42s\n",
      "94:\tlearn: 0.0057777\ttotal: 1m 20s\tremaining: 5m 41s\n",
      "95:\tlearn: 0.0055630\ttotal: 1m 20s\tremaining: 5m 40s\n",
      "96:\tlearn: 0.0053642\ttotal: 1m 21s\tremaining: 5m 39s\n",
      "97:\tlearn: 0.0051815\ttotal: 1m 22s\tremaining: 5m 38s\n",
      "98:\tlearn: 0.0049975\ttotal: 1m 23s\tremaining: 5m 37s\n",
      "99:\tlearn: 0.0048217\ttotal: 1m 24s\tremaining: 5m 36s\n",
      "100:\tlearn: 0.0046570\ttotal: 1m 25s\tremaining: 5m 36s\n",
      "101:\tlearn: 0.0045047\ttotal: 1m 25s\tremaining: 5m 34s\n",
      "102:\tlearn: 0.0043539\ttotal: 1m 26s\tremaining: 5m 34s\n",
      "103:\tlearn: 0.0042124\ttotal: 1m 27s\tremaining: 5m 33s\n",
      "104:\tlearn: 0.0040808\ttotal: 1m 28s\tremaining: 5m 32s\n",
      "105:\tlearn: 0.0039491\ttotal: 1m 29s\tremaining: 5m 31s\n",
      "106:\tlearn: 0.0038255\ttotal: 1m 30s\tremaining: 5m 31s\n",
      "107:\tlearn: 0.0037082\ttotal: 1m 31s\tremaining: 5m 30s\n",
      "108:\tlearn: 0.0035990\ttotal: 1m 31s\tremaining: 5m 29s\n",
      "109:\tlearn: 0.0034928\ttotal: 1m 32s\tremaining: 5m 28s\n",
      "110:\tlearn: 0.0033933\ttotal: 1m 33s\tremaining: 5m 27s\n",
      "111:\tlearn: 0.0033024\ttotal: 1m 34s\tremaining: 5m 26s\n",
      "112:\tlearn: 0.0032116\ttotal: 1m 35s\tremaining: 5m 25s\n",
      "113:\tlearn: 0.0031265\ttotal: 1m 35s\tremaining: 5m 24s\n",
      "114:\tlearn: 0.0030457\ttotal: 1m 36s\tremaining: 5m 24s\n",
      "115:\tlearn: 0.0029694\ttotal: 1m 37s\tremaining: 5m 23s\n",
      "116:\tlearn: 0.0028951\ttotal: 1m 38s\tremaining: 5m 22s\n",
      "117:\tlearn: 0.0028230\ttotal: 1m 39s\tremaining: 5m 21s\n",
      "118:\tlearn: 0.0027553\ttotal: 1m 40s\tremaining: 5m 20s\n",
      "119:\tlearn: 0.0026917\ttotal: 1m 40s\tremaining: 5m 19s\n",
      "120:\tlearn: 0.0026331\ttotal: 1m 41s\tremaining: 5m 19s\n",
      "121:\tlearn: 0.0025745\ttotal: 1m 42s\tremaining: 5m 18s\n",
      "122:\tlearn: 0.0025186\ttotal: 1m 43s\tremaining: 5m 17s\n",
      "123:\tlearn: 0.0024665\ttotal: 1m 44s\tremaining: 5m 16s\n",
      "124:\tlearn: 0.0024200\ttotal: 1m 45s\tremaining: 5m 15s\n",
      "125:\tlearn: 0.0023765\ttotal: 1m 46s\tremaining: 5m 14s\n",
      "126:\tlearn: 0.0023301\ttotal: 1m 46s\tremaining: 5m 13s\n",
      "127:\tlearn: 0.0022880\ttotal: 1m 47s\tremaining: 5m 12s\n",
      "128:\tlearn: 0.0022474\ttotal: 1m 48s\tremaining: 5m 12s\n",
      "129:\tlearn: 0.0022095\ttotal: 1m 49s\tremaining: 5m 11s\n",
      "130:\tlearn: 0.0021719\ttotal: 1m 50s\tremaining: 5m 10s\n",
      "131:\tlearn: 0.0021389\ttotal: 1m 51s\tremaining: 5m 9s\n",
      "132:\tlearn: 0.0021069\ttotal: 1m 51s\tremaining: 5m 8s\n",
      "133:\tlearn: 0.0020770\ttotal: 1m 52s\tremaining: 5m 8s\n",
      "134:\tlearn: 0.0020496\ttotal: 1m 53s\tremaining: 5m 7s\n",
      "135:\tlearn: 0.0020215\ttotal: 1m 54s\tremaining: 5m 6s\n",
      "136:\tlearn: 0.0019952\ttotal: 1m 55s\tremaining: 5m 5s\n",
      "137:\tlearn: 0.0019701\ttotal: 1m 56s\tremaining: 5m 4s\n",
      "138:\tlearn: 0.0019470\ttotal: 1m 56s\tremaining: 5m 3s\n",
      "139:\tlearn: 0.0019237\ttotal: 1m 57s\tremaining: 5m 2s\n",
      "140:\tlearn: 0.0019051\ttotal: 1m 58s\tremaining: 5m 2s\n",
      "141:\tlearn: 0.0018864\ttotal: 1m 59s\tremaining: 5m 1s\n",
      "142:\tlearn: 0.0018662\ttotal: 2m\tremaining: 5m\n",
      "143:\tlearn: 0.0018466\ttotal: 2m 1s\tremaining: 4m 59s\n",
      "144:\tlearn: 0.0018283\ttotal: 2m 2s\tremaining: 4m 58s\n",
      "145:\tlearn: 0.0018108\ttotal: 2m 2s\tremaining: 4m 58s\n",
      "146:\tlearn: 0.0017965\ttotal: 2m 3s\tremaining: 4m 57s\n",
      "147:\tlearn: 0.0017821\ttotal: 2m 4s\tremaining: 4m 56s\n",
      "148:\tlearn: 0.0017668\ttotal: 2m 5s\tremaining: 4m 55s\n",
      "149:\tlearn: 0.0017534\ttotal: 2m 6s\tremaining: 4m 54s\n",
      "150:\tlearn: 0.0017417\ttotal: 2m 7s\tremaining: 4m 53s\n",
      "151:\tlearn: 0.0017298\ttotal: 2m 7s\tremaining: 4m 53s\n",
      "152:\tlearn: 0.0017174\ttotal: 2m 8s\tremaining: 4m 52s\n",
      "153:\tlearn: 0.0017065\ttotal: 2m 9s\tremaining: 4m 51s\n",
      "154:\tlearn: 0.0016948\ttotal: 2m 10s\tremaining: 4m 51s\n",
      "155:\tlearn: 0.0016846\ttotal: 2m 11s\tremaining: 4m 49s\n",
      "156:\tlearn: 0.0016753\ttotal: 2m 12s\tremaining: 4m 49s\n",
      "157:\tlearn: 0.0016664\ttotal: 2m 13s\tremaining: 4m 48s\n",
      "158:\tlearn: 0.0016577\ttotal: 2m 13s\tremaining: 4m 47s\n",
      "159:\tlearn: 0.0016478\ttotal: 2m 14s\tremaining: 4m 46s\n",
      "160:\tlearn: 0.0016391\ttotal: 2m 15s\tremaining: 4m 45s\n",
      "161:\tlearn: 0.0016320\ttotal: 2m 16s\tremaining: 4m 44s\n",
      "162:\tlearn: 0.0016227\ttotal: 2m 17s\tremaining: 4m 43s\n",
      "163:\tlearn: 0.0016150\ttotal: 2m 18s\tremaining: 4m 43s\n",
      "164:\tlearn: 0.0016078\ttotal: 2m 19s\tremaining: 4m 42s\n",
      "165:\tlearn: 0.0016008\ttotal: 2m 20s\tremaining: 4m 41s\n",
      "166:\tlearn: 0.0015944\ttotal: 2m 20s\tremaining: 4m 40s\n",
      "167:\tlearn: 0.0015878\ttotal: 2m 21s\tremaining: 4m 40s\n",
      "168:\tlearn: 0.0015816\ttotal: 2m 22s\tremaining: 4m 39s\n",
      "169:\tlearn: 0.0015761\ttotal: 2m 23s\tremaining: 4m 38s\n",
      "170:\tlearn: 0.0015709\ttotal: 2m 24s\tremaining: 4m 37s\n",
      "171:\tlearn: 0.0015655\ttotal: 2m 25s\tremaining: 4m 36s\n",
      "172:\tlearn: 0.0015618\ttotal: 2m 26s\tremaining: 4m 36s\n",
      "173:\tlearn: 0.0015563\ttotal: 2m 26s\tremaining: 4m 35s\n",
      "174:\tlearn: 0.0015507\ttotal: 2m 27s\tremaining: 4m 34s\n",
      "175:\tlearn: 0.0015469\ttotal: 2m 28s\tremaining: 4m 33s\n",
      "176:\tlearn: 0.0015435\ttotal: 2m 29s\tremaining: 4m 32s\n",
      "177:\tlearn: 0.0015373\ttotal: 2m 30s\tremaining: 4m 31s\n",
      "178:\tlearn: 0.0015327\ttotal: 2m 31s\tremaining: 4m 31s\n",
      "179:\tlearn: 0.0015294\ttotal: 2m 31s\tremaining: 4m 30s\n",
      "180:\tlearn: 0.0015255\ttotal: 2m 32s\tremaining: 4m 29s\n",
      "181:\tlearn: 0.0015217\ttotal: 2m 33s\tremaining: 4m 28s\n",
      "182:\tlearn: 0.0015184\ttotal: 2m 34s\tremaining: 4m 27s\n",
      "183:\tlearn: 0.0015144\ttotal: 2m 35s\tremaining: 4m 26s\n",
      "184:\tlearn: 0.0015108\ttotal: 2m 36s\tremaining: 4m 26s\n",
      "185:\tlearn: 0.0015067\ttotal: 2m 37s\tremaining: 4m 25s\n",
      "186:\tlearn: 0.0015037\ttotal: 2m 37s\tremaining: 4m 24s\n",
      "187:\tlearn: 0.0015006\ttotal: 2m 38s\tremaining: 4m 23s\n",
      "188:\tlearn: 0.0014960\ttotal: 2m 39s\tremaining: 4m 22s\n",
      "189:\tlearn: 0.0014935\ttotal: 2m 40s\tremaining: 4m 21s\n",
      "190:\tlearn: 0.0014908\ttotal: 2m 41s\tremaining: 4m 20s\n",
      "191:\tlearn: 0.0014869\ttotal: 2m 42s\tremaining: 4m 20s\n",
      "192:\tlearn: 0.0014828\ttotal: 2m 43s\tremaining: 4m 19s\n",
      "193:\tlearn: 0.0014800\ttotal: 2m 43s\tremaining: 4m 18s\n",
      "194:\tlearn: 0.0014777\ttotal: 2m 44s\tremaining: 4m 17s\n",
      "195:\tlearn: 0.0014745\ttotal: 2m 45s\tremaining: 4m 16s\n",
      "196:\tlearn: 0.0014715\ttotal: 2m 46s\tremaining: 4m 16s\n",
      "197:\tlearn: 0.0014687\ttotal: 2m 47s\tremaining: 4m 15s\n",
      "198:\tlearn: 0.0014652\ttotal: 2m 48s\tremaining: 4m 14s\n",
      "199:\tlearn: 0.0014630\ttotal: 2m 49s\tremaining: 4m 13s\n",
      "200:\tlearn: 0.0014607\ttotal: 2m 49s\tremaining: 4m 12s\n",
      "201:\tlearn: 0.0014578\ttotal: 2m 50s\tremaining: 4m 12s\n",
      "202:\tlearn: 0.0014562\ttotal: 2m 51s\tremaining: 4m 11s\n",
      "203:\tlearn: 0.0014540\ttotal: 2m 52s\tremaining: 4m 10s\n",
      "204:\tlearn: 0.0014520\ttotal: 2m 53s\tremaining: 4m 9s\n",
      "205:\tlearn: 0.0014500\ttotal: 2m 54s\tremaining: 4m 8s\n",
      "206:\tlearn: 0.0014474\ttotal: 2m 55s\tremaining: 4m 7s\n",
      "207:\tlearn: 0.0014454\ttotal: 2m 55s\tremaining: 4m 6s\n",
      "208:\tlearn: 0.0014431\ttotal: 2m 56s\tremaining: 4m 6s\n",
      "209:\tlearn: 0.0014408\ttotal: 2m 57s\tremaining: 4m 5s\n",
      "210:\tlearn: 0.0014392\ttotal: 2m 58s\tremaining: 4m 4s\n",
      "211:\tlearn: 0.0014366\ttotal: 2m 59s\tremaining: 4m 3s\n",
      "212:\tlearn: 0.0014341\ttotal: 3m\tremaining: 4m 3s\n",
      "213:\tlearn: 0.0014305\ttotal: 3m 1s\tremaining: 4m 2s\n",
      "214:\tlearn: 0.0014293\ttotal: 3m 1s\tremaining: 4m 1s\n",
      "215:\tlearn: 0.0014266\ttotal: 3m 2s\tremaining: 4m\n",
      "216:\tlearn: 0.0014240\ttotal: 3m 3s\tremaining: 3m 59s\n",
      "217:\tlearn: 0.0014218\ttotal: 3m 4s\tremaining: 3m 58s\n",
      "218:\tlearn: 0.0014188\ttotal: 3m 5s\tremaining: 3m 57s\n",
      "219:\tlearn: 0.0014163\ttotal: 3m 6s\tremaining: 3m 57s\n",
      "220:\tlearn: 0.0014136\ttotal: 3m 7s\tremaining: 3m 56s\n",
      "221:\tlearn: 0.0014122\ttotal: 3m 7s\tremaining: 3m 55s\n",
      "222:\tlearn: 0.0014097\ttotal: 3m 8s\tremaining: 3m 54s\n",
      "223:\tlearn: 0.0014069\ttotal: 3m 9s\tremaining: 3m 53s\n",
      "224:\tlearn: 0.0014032\ttotal: 3m 10s\tremaining: 3m 52s\n",
      "225:\tlearn: 0.0014017\ttotal: 3m 11s\tremaining: 3m 52s\n",
      "226:\tlearn: 0.0014000\ttotal: 3m 12s\tremaining: 3m 51s\n",
      "227:\tlearn: 0.0013980\ttotal: 3m 13s\tremaining: 3m 50s\n",
      "228:\tlearn: 0.0013948\ttotal: 3m 14s\tremaining: 3m 49s\n",
      "229:\tlearn: 0.0013930\ttotal: 3m 15s\tremaining: 3m 49s\n",
      "230:\tlearn: 0.0013912\ttotal: 3m 15s\tremaining: 3m 48s\n",
      "231:\tlearn: 0.0013888\ttotal: 3m 16s\tremaining: 3m 47s\n",
      "232:\tlearn: 0.0013864\ttotal: 3m 17s\tremaining: 3m 46s\n",
      "233:\tlearn: 0.0013845\ttotal: 3m 18s\tremaining: 3m 45s\n",
      "234:\tlearn: 0.0013819\ttotal: 3m 19s\tremaining: 3m 44s\n",
      "235:\tlearn: 0.0013801\ttotal: 3m 20s\tremaining: 3m 44s\n",
      "236:\tlearn: 0.0013779\ttotal: 3m 21s\tremaining: 3m 43s\n",
      "237:\tlearn: 0.0013758\ttotal: 3m 22s\tremaining: 3m 42s\n",
      "238:\tlearn: 0.0013730\ttotal: 3m 22s\tremaining: 3m 41s\n",
      "239:\tlearn: 0.0013721\ttotal: 3m 23s\tremaining: 3m 40s\n",
      "240:\tlearn: 0.0013695\ttotal: 3m 24s\tremaining: 3m 40s\n",
      "241:\tlearn: 0.0013688\ttotal: 3m 25s\tremaining: 3m 39s\n",
      "242:\tlearn: 0.0013669\ttotal: 3m 26s\tremaining: 3m 38s\n",
      "243:\tlearn: 0.0013657\ttotal: 3m 27s\tremaining: 3m 37s\n",
      "244:\tlearn: 0.0013627\ttotal: 3m 28s\tremaining: 3m 36s\n",
      "245:\tlearn: 0.0013610\ttotal: 3m 29s\tremaining: 3m 36s\n",
      "246:\tlearn: 0.0013593\ttotal: 3m 30s\tremaining: 3m 35s\n",
      "247:\tlearn: 0.0013560\ttotal: 3m 31s\tremaining: 3m 34s\n",
      "248:\tlearn: 0.0013551\ttotal: 3m 31s\tremaining: 3m 33s\n",
      "249:\tlearn: 0.0013513\ttotal: 3m 32s\tremaining: 3m 32s\n",
      "250:\tlearn: 0.0013499\ttotal: 3m 33s\tremaining: 3m 31s\n",
      "251:\tlearn: 0.0013485\ttotal: 3m 34s\tremaining: 3m 30s\n",
      "252:\tlearn: 0.0013468\ttotal: 3m 35s\tremaining: 3m 30s\n",
      "253:\tlearn: 0.0013440\ttotal: 3m 36s\tremaining: 3m 29s\n",
      "254:\tlearn: 0.0013416\ttotal: 3m 36s\tremaining: 3m 28s\n",
      "255:\tlearn: 0.0013399\ttotal: 3m 37s\tremaining: 3m 27s\n",
      "256:\tlearn: 0.0013382\ttotal: 3m 38s\tremaining: 3m 26s\n",
      "257:\tlearn: 0.0013366\ttotal: 3m 39s\tremaining: 3m 25s\n",
      "258:\tlearn: 0.0013351\ttotal: 3m 40s\tremaining: 3m 24s\n",
      "259:\tlearn: 0.0013317\ttotal: 3m 41s\tremaining: 3m 24s\n",
      "260:\tlearn: 0.0013299\ttotal: 3m 42s\tremaining: 3m 23s\n",
      "261:\tlearn: 0.0013275\ttotal: 3m 42s\tremaining: 3m 22s\n",
      "262:\tlearn: 0.0013248\ttotal: 3m 43s\tremaining: 3m 21s\n",
      "263:\tlearn: 0.0013232\ttotal: 3m 44s\tremaining: 3m 20s\n",
      "264:\tlearn: 0.0013216\ttotal: 3m 45s\tremaining: 3m 20s\n",
      "265:\tlearn: 0.0013191\ttotal: 3m 46s\tremaining: 3m 19s\n",
      "266:\tlearn: 0.0013173\ttotal: 3m 47s\tremaining: 3m 18s\n",
      "267:\tlearn: 0.0013145\ttotal: 3m 48s\tremaining: 3m 17s\n",
      "268:\tlearn: 0.0013135\ttotal: 3m 49s\tremaining: 3m 16s\n",
      "269:\tlearn: 0.0013114\ttotal: 3m 50s\tremaining: 3m 16s\n",
      "270:\tlearn: 0.0013095\ttotal: 3m 50s\tremaining: 3m 15s\n",
      "271:\tlearn: 0.0013075\ttotal: 3m 51s\tremaining: 3m 14s\n",
      "272:\tlearn: 0.0013063\ttotal: 3m 52s\tremaining: 3m 13s\n",
      "273:\tlearn: 0.0013026\ttotal: 3m 53s\tremaining: 3m 12s\n",
      "274:\tlearn: 0.0013011\ttotal: 3m 54s\tremaining: 3m 11s\n",
      "275:\tlearn: 0.0012988\ttotal: 3m 55s\tremaining: 3m 10s\n",
      "276:\tlearn: 0.0012983\ttotal: 3m 56s\tremaining: 3m 10s\n",
      "277:\tlearn: 0.0012973\ttotal: 3m 57s\tremaining: 3m 9s\n",
      "278:\tlearn: 0.0012961\ttotal: 3m 58s\tremaining: 3m 8s\n",
      "279:\tlearn: 0.0012938\ttotal: 3m 58s\tremaining: 3m 7s\n",
      "280:\tlearn: 0.0012896\ttotal: 3m 59s\tremaining: 3m 6s\n",
      "281:\tlearn: 0.0012880\ttotal: 4m\tremaining: 3m 6s\n",
      "282:\tlearn: 0.0012873\ttotal: 4m 1s\tremaining: 3m 5s\n",
      "283:\tlearn: 0.0012849\ttotal: 4m 2s\tremaining: 3m 4s\n",
      "284:\tlearn: 0.0012832\ttotal: 4m 3s\tremaining: 3m 3s\n",
      "285:\tlearn: 0.0012821\ttotal: 4m 3s\tremaining: 3m 2s\n",
      "286:\tlearn: 0.0012810\ttotal: 4m 4s\tremaining: 3m 1s\n",
      "287:\tlearn: 0.0012779\ttotal: 4m 5s\tremaining: 3m\n",
      "288:\tlearn: 0.0012767\ttotal: 4m 5s\tremaining: 2m 59s\n",
      "289:\tlearn: 0.0012751\ttotal: 4m 6s\tremaining: 2m 58s\n",
      "290:\tlearn: 0.0012739\ttotal: 4m 7s\tremaining: 2m 57s\n",
      "291:\tlearn: 0.0012729\ttotal: 4m 8s\tremaining: 2m 56s\n",
      "292:\tlearn: 0.0012715\ttotal: 4m 9s\tremaining: 2m 55s\n",
      "293:\tlearn: 0.0012700\ttotal: 4m 9s\tremaining: 2m 54s\n",
      "294:\tlearn: 0.0012683\ttotal: 4m 10s\tremaining: 2m 54s\n",
      "295:\tlearn: 0.0012666\ttotal: 4m 11s\tremaining: 2m 53s\n",
      "296:\tlearn: 0.0012647\ttotal: 4m 11s\tremaining: 2m 52s\n",
      "297:\tlearn: 0.0012627\ttotal: 4m 12s\tremaining: 2m 51s\n",
      "298:\tlearn: 0.0012609\ttotal: 4m 13s\tremaining: 2m 50s\n",
      "299:\tlearn: 0.0012594\ttotal: 4m 14s\tremaining: 2m 49s\n",
      "300:\tlearn: 0.0012585\ttotal: 4m 14s\tremaining: 2m 48s\n",
      "301:\tlearn: 0.0012576\ttotal: 4m 15s\tremaining: 2m 47s\n",
      "302:\tlearn: 0.0012568\ttotal: 4m 16s\tremaining: 2m 46s\n",
      "303:\tlearn: 0.0012560\ttotal: 4m 17s\tremaining: 2m 45s\n",
      "304:\tlearn: 0.0012545\ttotal: 4m 17s\tremaining: 2m 44s\n",
      "305:\tlearn: 0.0012529\ttotal: 4m 18s\tremaining: 2m 43s\n",
      "306:\tlearn: 0.0012521\ttotal: 4m 19s\tremaining: 2m 42s\n",
      "307:\tlearn: 0.0012502\ttotal: 4m 19s\tremaining: 2m 42s\n",
      "308:\tlearn: 0.0012492\ttotal: 4m 20s\tremaining: 2m 41s\n",
      "309:\tlearn: 0.0012485\ttotal: 4m 21s\tremaining: 2m 40s\n",
      "310:\tlearn: 0.0012475\ttotal: 4m 22s\tremaining: 2m 39s\n",
      "311:\tlearn: 0.0012461\ttotal: 4m 22s\tremaining: 2m 38s\n",
      "312:\tlearn: 0.0012449\ttotal: 4m 23s\tremaining: 2m 37s\n",
      "313:\tlearn: 0.0012440\ttotal: 4m 24s\tremaining: 2m 36s\n",
      "314:\tlearn: 0.0012427\ttotal: 4m 24s\tremaining: 2m 35s\n",
      "315:\tlearn: 0.0012410\ttotal: 4m 25s\tremaining: 2m 34s\n",
      "316:\tlearn: 0.0012395\ttotal: 4m 26s\tremaining: 2m 33s\n",
      "317:\tlearn: 0.0012381\ttotal: 4m 27s\tremaining: 2m 32s\n",
      "318:\tlearn: 0.0012367\ttotal: 4m 27s\tremaining: 2m 32s\n",
      "319:\tlearn: 0.0012349\ttotal: 4m 28s\tremaining: 2m 31s\n",
      "320:\tlearn: 0.0012327\ttotal: 4m 29s\tremaining: 2m 30s\n",
      "321:\tlearn: 0.0012315\ttotal: 4m 30s\tremaining: 2m 29s\n",
      "322:\tlearn: 0.0012305\ttotal: 4m 30s\tremaining: 2m 28s\n",
      "323:\tlearn: 0.0012297\ttotal: 4m 31s\tremaining: 2m 27s\n",
      "324:\tlearn: 0.0012285\ttotal: 4m 32s\tremaining: 2m 26s\n",
      "325:\tlearn: 0.0012273\ttotal: 4m 33s\tremaining: 2m 25s\n",
      "326:\tlearn: 0.0012265\ttotal: 4m 33s\tremaining: 2m 24s\n",
      "327:\tlearn: 0.0012239\ttotal: 4m 34s\tremaining: 2m 24s\n",
      "328:\tlearn: 0.0012217\ttotal: 4m 35s\tremaining: 2m 23s\n",
      "329:\tlearn: 0.0012207\ttotal: 4m 36s\tremaining: 2m 22s\n",
      "330:\tlearn: 0.0012190\ttotal: 4m 36s\tremaining: 2m 21s\n",
      "331:\tlearn: 0.0012176\ttotal: 4m 37s\tremaining: 2m 20s\n",
      "332:\tlearn: 0.0012159\ttotal: 4m 38s\tremaining: 2m 19s\n",
      "333:\tlearn: 0.0012144\ttotal: 4m 39s\tremaining: 2m 18s\n",
      "334:\tlearn: 0.0012129\ttotal: 4m 39s\tremaining: 2m 17s\n",
      "335:\tlearn: 0.0012116\ttotal: 4m 40s\tremaining: 2m 16s\n",
      "336:\tlearn: 0.0012102\ttotal: 4m 41s\tremaining: 2m 16s\n",
      "337:\tlearn: 0.0012090\ttotal: 4m 42s\tremaining: 2m 15s\n",
      "338:\tlearn: 0.0012082\ttotal: 4m 42s\tremaining: 2m 14s\n",
      "339:\tlearn: 0.0012065\ttotal: 4m 43s\tremaining: 2m 13s\n",
      "340:\tlearn: 0.0012054\ttotal: 4m 44s\tremaining: 2m 12s\n",
      "341:\tlearn: 0.0012044\ttotal: 4m 44s\tremaining: 2m 11s\n",
      "342:\tlearn: 0.0012031\ttotal: 4m 45s\tremaining: 2m 10s\n",
      "343:\tlearn: 0.0012024\ttotal: 4m 46s\tremaining: 2m 9s\n",
      "344:\tlearn: 0.0012016\ttotal: 4m 46s\tremaining: 2m 8s\n",
      "345:\tlearn: 0.0011999\ttotal: 4m 47s\tremaining: 2m 8s\n",
      "346:\tlearn: 0.0011990\ttotal: 4m 48s\tremaining: 2m 7s\n",
      "347:\tlearn: 0.0011980\ttotal: 4m 48s\tremaining: 2m 6s\n",
      "348:\tlearn: 0.0011968\ttotal: 4m 49s\tremaining: 2m 5s\n",
      "349:\tlearn: 0.0011955\ttotal: 4m 50s\tremaining: 2m 4s\n",
      "350:\tlearn: 0.0011943\ttotal: 4m 50s\tremaining: 2m 3s\n",
      "351:\tlearn: 0.0011937\ttotal: 4m 51s\tremaining: 2m 2s\n",
      "352:\tlearn: 0.0011916\ttotal: 4m 52s\tremaining: 2m 1s\n",
      "353:\tlearn: 0.0011898\ttotal: 4m 52s\tremaining: 2m\n",
      "354:\tlearn: 0.0011866\ttotal: 4m 53s\tremaining: 1m 59s\n",
      "355:\tlearn: 0.0011851\ttotal: 4m 54s\tremaining: 1m 58s\n",
      "356:\tlearn: 0.0011841\ttotal: 4m 54s\tremaining: 1m 58s\n",
      "357:\tlearn: 0.0011822\ttotal: 4m 55s\tremaining: 1m 57s\n",
      "358:\tlearn: 0.0011801\ttotal: 4m 55s\tremaining: 1m 56s\n",
      "359:\tlearn: 0.0011795\ttotal: 4m 56s\tremaining: 1m 55s\n",
      "360:\tlearn: 0.0011772\ttotal: 4m 57s\tremaining: 1m 54s\n",
      "361:\tlearn: 0.0011753\ttotal: 4m 57s\tremaining: 1m 53s\n",
      "362:\tlearn: 0.0011749\ttotal: 4m 58s\tremaining: 1m 52s\n",
      "363:\tlearn: 0.0011742\ttotal: 4m 59s\tremaining: 1m 51s\n",
      "364:\tlearn: 0.0011733\ttotal: 4m 59s\tremaining: 1m 50s\n",
      "365:\tlearn: 0.0011729\ttotal: 5m\tremaining: 1m 50s\n",
      "366:\tlearn: 0.0011699\ttotal: 5m 1s\tremaining: 1m 49s\n",
      "367:\tlearn: 0.0011692\ttotal: 5m 2s\tremaining: 1m 48s\n",
      "368:\tlearn: 0.0011685\ttotal: 5m 2s\tremaining: 1m 47s\n",
      "369:\tlearn: 0.0011672\ttotal: 5m 3s\tremaining: 1m 46s\n",
      "370:\tlearn: 0.0011657\ttotal: 5m 4s\tremaining: 1m 45s\n",
      "371:\tlearn: 0.0011648\ttotal: 5m 5s\tremaining: 1m 45s\n",
      "372:\tlearn: 0.0011639\ttotal: 5m 6s\tremaining: 1m 44s\n",
      "373:\tlearn: 0.0011635\ttotal: 5m 7s\tremaining: 1m 43s\n",
      "374:\tlearn: 0.0011622\ttotal: 5m 8s\tremaining: 1m 42s\n",
      "375:\tlearn: 0.0011618\ttotal: 5m 9s\tremaining: 1m 41s\n",
      "376:\tlearn: 0.0011604\ttotal: 5m 10s\tremaining: 1m 41s\n",
      "377:\tlearn: 0.0011594\ttotal: 5m 11s\tremaining: 1m 40s\n",
      "378:\tlearn: 0.0011574\ttotal: 5m 12s\tremaining: 1m 39s\n",
      "379:\tlearn: 0.0011565\ttotal: 5m 13s\tremaining: 1m 38s\n",
      "380:\tlearn: 0.0011560\ttotal: 5m 14s\tremaining: 1m 38s\n",
      "381:\tlearn: 0.0011553\ttotal: 5m 15s\tremaining: 1m 37s\n",
      "382:\tlearn: 0.0011551\ttotal: 5m 16s\tremaining: 1m 36s\n",
      "383:\tlearn: 0.0011542\ttotal: 5m 17s\tremaining: 1m 35s\n",
      "384:\tlearn: 0.0011527\ttotal: 5m 18s\tremaining: 1m 35s\n",
      "385:\tlearn: 0.0011520\ttotal: 5m 19s\tremaining: 1m 34s\n",
      "386:\tlearn: 0.0011494\ttotal: 5m 20s\tremaining: 1m 33s\n",
      "387:\tlearn: 0.0011480\ttotal: 5m 20s\tremaining: 1m 32s\n",
      "388:\tlearn: 0.0011475\ttotal: 5m 21s\tremaining: 1m 31s\n",
      "389:\tlearn: 0.0011467\ttotal: 5m 22s\tremaining: 1m 31s\n",
      "390:\tlearn: 0.0011452\ttotal: 5m 23s\tremaining: 1m 30s\n",
      "391:\tlearn: 0.0011442\ttotal: 5m 24s\tremaining: 1m 29s\n",
      "392:\tlearn: 0.0011419\ttotal: 5m 25s\tremaining: 1m 28s\n",
      "393:\tlearn: 0.0011388\ttotal: 5m 26s\tremaining: 1m 27s\n",
      "394:\tlearn: 0.0011382\ttotal: 5m 27s\tremaining: 1m 27s\n",
      "395:\tlearn: 0.0011377\ttotal: 5m 28s\tremaining: 1m 26s\n",
      "396:\tlearn: 0.0011364\ttotal: 5m 29s\tremaining: 1m 25s\n",
      "397:\tlearn: 0.0011337\ttotal: 5m 30s\tremaining: 1m 24s\n",
      "398:\tlearn: 0.0011326\ttotal: 5m 31s\tremaining: 1m 23s\n",
      "399:\tlearn: 0.0011310\ttotal: 5m 31s\tremaining: 1m 22s\n",
      "400:\tlearn: 0.0011290\ttotal: 5m 32s\tremaining: 1m 22s\n",
      "401:\tlearn: 0.0011264\ttotal: 5m 33s\tremaining: 1m 21s\n",
      "402:\tlearn: 0.0011255\ttotal: 5m 34s\tremaining: 1m 20s\n",
      "403:\tlearn: 0.0011240\ttotal: 5m 35s\tremaining: 1m 19s\n",
      "404:\tlearn: 0.0011226\ttotal: 5m 36s\tremaining: 1m 18s\n",
      "405:\tlearn: 0.0011212\ttotal: 5m 37s\tremaining: 1m 18s\n",
      "406:\tlearn: 0.0011197\ttotal: 5m 38s\tremaining: 1m 17s\n",
      "407:\tlearn: 0.0011179\ttotal: 5m 39s\tremaining: 1m 16s\n",
      "408:\tlearn: 0.0011165\ttotal: 5m 40s\tremaining: 1m 15s\n",
      "409:\tlearn: 0.0011144\ttotal: 5m 41s\tremaining: 1m 14s\n",
      "410:\tlearn: 0.0011125\ttotal: 5m 42s\tremaining: 1m 14s\n",
      "411:\tlearn: 0.0011118\ttotal: 5m 43s\tremaining: 1m 13s\n",
      "412:\tlearn: 0.0011112\ttotal: 5m 44s\tremaining: 1m 12s\n",
      "413:\tlearn: 0.0011105\ttotal: 5m 44s\tremaining: 1m 11s\n",
      "414:\tlearn: 0.0011096\ttotal: 5m 45s\tremaining: 1m 10s\n",
      "415:\tlearn: 0.0011076\ttotal: 5m 46s\tremaining: 1m 10s\n",
      "416:\tlearn: 0.0011053\ttotal: 5m 47s\tremaining: 1m 9s\n",
      "417:\tlearn: 0.0011045\ttotal: 5m 48s\tremaining: 1m 8s\n",
      "418:\tlearn: 0.0011023\ttotal: 5m 49s\tremaining: 1m 7s\n",
      "419:\tlearn: 0.0011020\ttotal: 5m 50s\tremaining: 1m 6s\n",
      "420:\tlearn: 0.0011019\ttotal: 5m 51s\tremaining: 1m 5s\n",
      "421:\tlearn: 0.0011007\ttotal: 5m 52s\tremaining: 1m 5s\n",
      "422:\tlearn: 0.0010997\ttotal: 5m 53s\tremaining: 1m 4s\n",
      "423:\tlearn: 0.0010964\ttotal: 5m 54s\tremaining: 1m 3s\n",
      "424:\tlearn: 0.0010935\ttotal: 5m 55s\tremaining: 1m 2s\n",
      "425:\tlearn: 0.0010925\ttotal: 5m 55s\tremaining: 1m 1s\n",
      "426:\tlearn: 0.0010904\ttotal: 5m 56s\tremaining: 1m\n",
      "427:\tlearn: 0.0010891\ttotal: 5m 57s\tremaining: 1m\n",
      "428:\tlearn: 0.0010879\ttotal: 5m 58s\tremaining: 59.3s\n",
      "429:\tlearn: 0.0010872\ttotal: 5m 59s\tremaining: 58.5s\n",
      "430:\tlearn: 0.0010852\ttotal: 6m\tremaining: 57.7s\n",
      "431:\tlearn: 0.0010836\ttotal: 6m 1s\tremaining: 56.9s\n",
      "432:\tlearn: 0.0010804\ttotal: 6m 2s\tremaining: 56.1s\n",
      "433:\tlearn: 0.0010783\ttotal: 6m 3s\tremaining: 55.3s\n",
      "434:\tlearn: 0.0010741\ttotal: 6m 4s\tremaining: 54.4s\n",
      "435:\tlearn: 0.0010737\ttotal: 6m 5s\tremaining: 53.6s\n",
      "436:\tlearn: 0.0010731\ttotal: 6m 6s\tremaining: 52.8s\n",
      "437:\tlearn: 0.0010717\ttotal: 6m 6s\tremaining: 51.9s\n",
      "438:\tlearn: 0.0010711\ttotal: 6m 7s\tremaining: 51.1s\n",
      "439:\tlearn: 0.0010695\ttotal: 6m 8s\tremaining: 50.3s\n",
      "440:\tlearn: 0.0010685\ttotal: 6m 9s\tremaining: 49.5s\n",
      "441:\tlearn: 0.0010674\ttotal: 6m 10s\tremaining: 48.6s\n",
      "442:\tlearn: 0.0010657\ttotal: 6m 11s\tremaining: 47.8s\n",
      "443:\tlearn: 0.0010641\ttotal: 6m 12s\tremaining: 47s\n",
      "444:\tlearn: 0.0010620\ttotal: 6m 13s\tremaining: 46.1s\n",
      "445:\tlearn: 0.0010592\ttotal: 6m 14s\tremaining: 45.3s\n",
      "446:\tlearn: 0.0010576\ttotal: 6m 15s\tremaining: 44.5s\n",
      "447:\tlearn: 0.0010568\ttotal: 6m 16s\tremaining: 43.6s\n",
      "448:\tlearn: 0.0010539\ttotal: 6m 17s\tremaining: 42.8s\n",
      "449:\tlearn: 0.0010525\ttotal: 6m 17s\tremaining: 42s\n",
      "450:\tlearn: 0.0010505\ttotal: 6m 18s\tremaining: 41.2s\n",
      "451:\tlearn: 0.0010499\ttotal: 6m 19s\tremaining: 40.3s\n",
      "452:\tlearn: 0.0010486\ttotal: 6m 20s\tremaining: 39.5s\n",
      "453:\tlearn: 0.0010470\ttotal: 6m 21s\tremaining: 38.7s\n",
      "454:\tlearn: 0.0010465\ttotal: 6m 22s\tremaining: 37.8s\n",
      "455:\tlearn: 0.0010453\ttotal: 6m 23s\tremaining: 37s\n",
      "456:\tlearn: 0.0010450\ttotal: 6m 24s\tremaining: 36.2s\n",
      "457:\tlearn: 0.0010443\ttotal: 6m 25s\tremaining: 35.3s\n",
      "458:\tlearn: 0.0010435\ttotal: 6m 26s\tremaining: 34.5s\n",
      "459:\tlearn: 0.0010423\ttotal: 6m 27s\tremaining: 33.7s\n",
      "460:\tlearn: 0.0010403\ttotal: 6m 28s\tremaining: 32.8s\n",
      "461:\tlearn: 0.0010385\ttotal: 6m 29s\tremaining: 32s\n",
      "462:\tlearn: 0.0010369\ttotal: 6m 30s\tremaining: 31.2s\n",
      "463:\tlearn: 0.0010363\ttotal: 6m 31s\tremaining: 30.3s\n",
      "464:\tlearn: 0.0010356\ttotal: 6m 31s\tremaining: 29.5s\n",
      "465:\tlearn: 0.0010339\ttotal: 6m 32s\tremaining: 28.7s\n",
      "466:\tlearn: 0.0010322\ttotal: 6m 33s\tremaining: 27.8s\n",
      "467:\tlearn: 0.0010311\ttotal: 6m 34s\tremaining: 27s\n",
      "468:\tlearn: 0.0010290\ttotal: 6m 35s\tremaining: 26.2s\n",
      "469:\tlearn: 0.0010275\ttotal: 6m 36s\tremaining: 25.3s\n",
      "470:\tlearn: 0.0010264\ttotal: 6m 37s\tremaining: 24.5s\n",
      "471:\tlearn: 0.0010247\ttotal: 6m 38s\tremaining: 23.6s\n",
      "472:\tlearn: 0.0010238\ttotal: 6m 39s\tremaining: 22.8s\n",
      "473:\tlearn: 0.0010233\ttotal: 6m 40s\tremaining: 22s\n",
      "474:\tlearn: 0.0010229\ttotal: 6m 41s\tremaining: 21.1s\n",
      "475:\tlearn: 0.0010226\ttotal: 6m 42s\tremaining: 20.3s\n",
      "476:\tlearn: 0.0010218\ttotal: 6m 43s\tremaining: 19.4s\n",
      "477:\tlearn: 0.0010208\ttotal: 6m 44s\tremaining: 18.6s\n",
      "478:\tlearn: 0.0010200\ttotal: 6m 45s\tremaining: 17.8s\n",
      "479:\tlearn: 0.0010190\ttotal: 6m 45s\tremaining: 16.9s\n",
      "480:\tlearn: 0.0010178\ttotal: 6m 46s\tremaining: 16.1s\n",
      "481:\tlearn: 0.0010163\ttotal: 6m 47s\tremaining: 15.2s\n",
      "482:\tlearn: 0.0010144\ttotal: 6m 48s\tremaining: 14.4s\n",
      "483:\tlearn: 0.0010139\ttotal: 6m 49s\tremaining: 13.5s\n",
      "484:\tlearn: 0.0010128\ttotal: 6m 50s\tremaining: 12.7s\n",
      "485:\tlearn: 0.0010116\ttotal: 6m 51s\tremaining: 11.8s\n",
      "486:\tlearn: 0.0010108\ttotal: 6m 52s\tremaining: 11s\n",
      "487:\tlearn: 0.0010093\ttotal: 6m 53s\tremaining: 10.2s\n",
      "488:\tlearn: 0.0010085\ttotal: 6m 54s\tremaining: 9.31s\n",
      "489:\tlearn: 0.0010076\ttotal: 6m 54s\tremaining: 8.47s\n",
      "490:\tlearn: 0.0010073\ttotal: 6m 55s\tremaining: 7.63s\n",
      "491:\tlearn: 0.0010066\ttotal: 6m 56s\tremaining: 6.78s\n",
      "492:\tlearn: 0.0010052\ttotal: 6m 57s\tremaining: 5.93s\n",
      "493:\tlearn: 0.0010036\ttotal: 6m 58s\tremaining: 5.08s\n",
      "494:\tlearn: 0.0010015\ttotal: 6m 59s\tremaining: 4.24s\n",
      "495:\tlearn: 0.0010001\ttotal: 7m\tremaining: 3.39s\n",
      "496:\tlearn: 0.0009988\ttotal: 7m 1s\tremaining: 2.54s\n",
      "497:\tlearn: 0.0009974\ttotal: 7m 2s\tremaining: 1.7s\n",
      "498:\tlearn: 0.0009954\ttotal: 7m 3s\tremaining: 848ms\n",
      "499:\tlearn: 0.0009935\ttotal: 7m 4s\tremaining: 0us\n",
      "Accuracy: 0.9998953271028037\n",
      "\n",
      "Confusion Matrix:\n",
      " [[66868     0]\n",
      " [    7     0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     66868\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           1.00     66875\n",
      "   macro avg       0.50      0.50      0.50     66875\n",
      "weighted avg       1.00      1.00      1.00     66875\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Fraud','FraudType'], axis=1)\n",
    "y = df['Fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a CatBoost Classifier\n",
    "model = CatBoostClassifier(iterations=500, depth=10, learning_rate=0.05, loss_function='MultiClass', random_seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, cat_features=None)  # You can specify categorical features if needed\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/combined/combined_rus_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"Fraud_x\",\"FraudType_x\",\"Rndrng_NPI\",],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6822169\ttotal: 154ms\tremaining: 1m 16s\n",
      "1:\tlearn: 0.6716437\ttotal: 308ms\tremaining: 1m 16s\n",
      "2:\tlearn: 0.6624516\ttotal: 427ms\tremaining: 1m 10s\n",
      "3:\tlearn: 0.6543503\ttotal: 540ms\tremaining: 1m 6s\n",
      "4:\tlearn: 0.6472799\ttotal: 660ms\tremaining: 1m 5s\n",
      "5:\tlearn: 0.6411597\ttotal: 797ms\tremaining: 1m 5s\n",
      "6:\tlearn: 0.6313988\ttotal: 922ms\tremaining: 1m 4s\n",
      "7:\tlearn: 0.6230534\ttotal: 952ms\tremaining: 58.5s\n",
      "8:\tlearn: 0.6151469\ttotal: 1.12s\tremaining: 1m 1s\n",
      "9:\tlearn: 0.6091734\ttotal: 1.23s\tremaining: 1m\n",
      "10:\tlearn: 0.6013802\ttotal: 1.33s\tremaining: 59.3s\n",
      "11:\tlearn: 0.5937559\ttotal: 1.49s\tremaining: 1m\n",
      "12:\tlearn: 0.5868433\ttotal: 1.62s\tremaining: 1m\n",
      "13:\tlearn: 0.5814423\ttotal: 1.71s\tremaining: 59.2s\n",
      "14:\tlearn: 0.5749508\ttotal: 1.84s\tremaining: 59.6s\n",
      "15:\tlearn: 0.5699630\ttotal: 1.99s\tremaining: 1m\n",
      "16:\tlearn: 0.5638682\ttotal: 2.12s\tremaining: 1m\n",
      "17:\tlearn: 0.5581616\ttotal: 2.2s\tremaining: 59s\n",
      "18:\tlearn: 0.5517586\ttotal: 2.3s\tremaining: 58.3s\n",
      "19:\tlearn: 0.5455495\ttotal: 2.47s\tremaining: 59.3s\n",
      "20:\tlearn: 0.5382391\ttotal: 2.62s\tremaining: 59.8s\n",
      "21:\tlearn: 0.5324282\ttotal: 2.74s\tremaining: 59.6s\n",
      "22:\tlearn: 0.5281771\ttotal: 2.85s\tremaining: 59.1s\n",
      "23:\tlearn: 0.5223319\ttotal: 2.98s\tremaining: 59.2s\n",
      "24:\tlearn: 0.5173663\ttotal: 3.1s\tremaining: 59s\n",
      "25:\tlearn: 0.5113716\ttotal: 3.2s\tremaining: 58.4s\n",
      "26:\tlearn: 0.5060694\ttotal: 3.4s\tremaining: 59.6s\n",
      "27:\tlearn: 0.5001901\ttotal: 3.51s\tremaining: 59.2s\n",
      "28:\tlearn: 0.4962268\ttotal: 3.62s\tremaining: 58.9s\n",
      "29:\tlearn: 0.4896646\ttotal: 3.79s\tremaining: 59.4s\n",
      "30:\tlearn: 0.4835786\ttotal: 3.94s\tremaining: 59.7s\n",
      "31:\tlearn: 0.4789291\ttotal: 4.05s\tremaining: 59.2s\n",
      "32:\tlearn: 0.4736628\ttotal: 4.2s\tremaining: 59.4s\n",
      "33:\tlearn: 0.4685959\ttotal: 4.34s\tremaining: 59.5s\n",
      "34:\tlearn: 0.4640471\ttotal: 4.45s\tremaining: 59.1s\n",
      "35:\tlearn: 0.4590592\ttotal: 4.58s\tremaining: 59s\n",
      "36:\tlearn: 0.4553140\ttotal: 4.75s\tremaining: 59.5s\n",
      "37:\tlearn: 0.4509761\ttotal: 4.88s\tremaining: 59.4s\n",
      "38:\tlearn: 0.4470363\ttotal: 5.01s\tremaining: 59.2s\n",
      "39:\tlearn: 0.4425318\ttotal: 5.11s\tremaining: 58.8s\n",
      "40:\tlearn: 0.4387352\ttotal: 5.21s\tremaining: 58.3s\n",
      "41:\tlearn: 0.4341933\ttotal: 5.35s\tremaining: 58.4s\n",
      "42:\tlearn: 0.4295312\ttotal: 5.45s\tremaining: 58s\n",
      "43:\tlearn: 0.4247889\ttotal: 5.58s\tremaining: 57.9s\n",
      "44:\tlearn: 0.4211216\ttotal: 5.71s\tremaining: 57.7s\n",
      "45:\tlearn: 0.4170725\ttotal: 5.85s\tremaining: 57.7s\n",
      "46:\tlearn: 0.4127263\ttotal: 6.01s\tremaining: 57.9s\n",
      "47:\tlearn: 0.4093945\ttotal: 6.16s\tremaining: 58s\n",
      "48:\tlearn: 0.4053080\ttotal: 6.28s\tremaining: 57.8s\n",
      "49:\tlearn: 0.4013495\ttotal: 6.38s\tremaining: 57.4s\n",
      "50:\tlearn: 0.3979058\ttotal: 6.55s\tremaining: 57.7s\n",
      "51:\tlearn: 0.3940005\ttotal: 6.65s\tremaining: 57.3s\n",
      "52:\tlearn: 0.3899265\ttotal: 6.72s\tremaining: 56.7s\n",
      "53:\tlearn: 0.3855675\ttotal: 6.83s\tremaining: 56.4s\n",
      "54:\tlearn: 0.3806589\ttotal: 6.98s\tremaining: 56.4s\n",
      "55:\tlearn: 0.3763055\ttotal: 7.13s\tremaining: 56.6s\n",
      "56:\tlearn: 0.3725969\ttotal: 7.24s\tremaining: 56.3s\n",
      "57:\tlearn: 0.3698133\ttotal: 7.41s\tremaining: 56.5s\n",
      "58:\tlearn: 0.3652625\ttotal: 7.53s\tremaining: 56.3s\n",
      "59:\tlearn: 0.3618943\ttotal: 7.63s\tremaining: 55.9s\n",
      "60:\tlearn: 0.3582863\ttotal: 7.74s\tremaining: 55.7s\n",
      "61:\tlearn: 0.3549875\ttotal: 7.85s\tremaining: 55.4s\n",
      "62:\tlearn: 0.3518960\ttotal: 7.96s\tremaining: 55.2s\n",
      "63:\tlearn: 0.3480776\ttotal: 8.04s\tremaining: 54.7s\n",
      "64:\tlearn: 0.3454076\ttotal: 8.18s\tremaining: 54.8s\n",
      "65:\tlearn: 0.3421746\ttotal: 8.3s\tremaining: 54.6s\n",
      "66:\tlearn: 0.3387608\ttotal: 8.42s\tremaining: 54.4s\n",
      "67:\tlearn: 0.3359108\ttotal: 8.55s\tremaining: 54.3s\n",
      "68:\tlearn: 0.3331488\ttotal: 8.65s\tremaining: 54s\n",
      "69:\tlearn: 0.3306020\ttotal: 8.74s\tremaining: 53.7s\n",
      "70:\tlearn: 0.3267995\ttotal: 8.78s\tremaining: 53s\n",
      "71:\tlearn: 0.3243142\ttotal: 8.96s\tremaining: 53.3s\n",
      "72:\tlearn: 0.3214243\ttotal: 9.11s\tremaining: 53.3s\n",
      "73:\tlearn: 0.3187939\ttotal: 9.27s\tremaining: 53.4s\n",
      "74:\tlearn: 0.3163697\ttotal: 9.42s\tremaining: 53.4s\n",
      "75:\tlearn: 0.3134852\ttotal: 9.56s\tremaining: 53.3s\n",
      "76:\tlearn: 0.3103260\ttotal: 9.66s\tremaining: 53.1s\n",
      "77:\tlearn: 0.3078163\ttotal: 9.8s\tremaining: 53s\n",
      "78:\tlearn: 0.3048064\ttotal: 9.92s\tremaining: 52.9s\n",
      "79:\tlearn: 0.3027606\ttotal: 10s\tremaining: 52.7s\n",
      "80:\tlearn: 0.3004010\ttotal: 10.2s\tremaining: 52.7s\n",
      "81:\tlearn: 0.2979877\ttotal: 10.3s\tremaining: 52.7s\n",
      "82:\tlearn: 0.2955867\ttotal: 10.5s\tremaining: 52.6s\n",
      "83:\tlearn: 0.2928578\ttotal: 10.6s\tremaining: 52.6s\n",
      "84:\tlearn: 0.2904460\ttotal: 10.8s\tremaining: 52.5s\n",
      "85:\tlearn: 0.2879087\ttotal: 10.9s\tremaining: 52.3s\n",
      "86:\tlearn: 0.2857909\ttotal: 11s\tremaining: 52.3s\n",
      "87:\tlearn: 0.2827818\ttotal: 11.1s\tremaining: 52.2s\n",
      "88:\tlearn: 0.2803519\ttotal: 11.3s\tremaining: 52s\n",
      "89:\tlearn: 0.2779204\ttotal: 11.4s\tremaining: 51.9s\n",
      "90:\tlearn: 0.2759527\ttotal: 11.6s\tremaining: 51.9s\n",
      "91:\tlearn: 0.2741669\ttotal: 11.7s\tremaining: 51.7s\n",
      "92:\tlearn: 0.2722945\ttotal: 11.8s\tremaining: 51.6s\n",
      "93:\tlearn: 0.2696551\ttotal: 12s\tremaining: 51.7s\n",
      "94:\tlearn: 0.2674751\ttotal: 12.1s\tremaining: 51.7s\n",
      "95:\tlearn: 0.2654930\ttotal: 12.2s\tremaining: 51.5s\n",
      "96:\tlearn: 0.2638834\ttotal: 12.3s\tremaining: 51s\n",
      "97:\tlearn: 0.2621036\ttotal: 12.4s\tremaining: 50.9s\n",
      "98:\tlearn: 0.2591468\ttotal: 12.6s\tremaining: 50.9s\n",
      "99:\tlearn: 0.2566924\ttotal: 12.8s\tremaining: 51s\n",
      "100:\tlearn: 0.2547821\ttotal: 12.9s\tremaining: 50.8s\n",
      "101:\tlearn: 0.2530440\ttotal: 13s\tremaining: 50.7s\n",
      "102:\tlearn: 0.2505003\ttotal: 13.1s\tremaining: 50.6s\n",
      "103:\tlearn: 0.2480836\ttotal: 13.2s\tremaining: 50.3s\n",
      "104:\tlearn: 0.2463547\ttotal: 13.4s\tremaining: 50.3s\n",
      "105:\tlearn: 0.2444623\ttotal: 13.5s\tremaining: 50.1s\n",
      "106:\tlearn: 0.2426937\ttotal: 13.6s\tremaining: 49.8s\n",
      "107:\tlearn: 0.2410183\ttotal: 13.7s\tremaining: 49.6s\n",
      "108:\tlearn: 0.2394655\ttotal: 13.8s\tremaining: 49.5s\n",
      "109:\tlearn: 0.2373293\ttotal: 13.9s\tremaining: 49.4s\n",
      "110:\tlearn: 0.2352911\ttotal: 14s\tremaining: 49.2s\n",
      "111:\tlearn: 0.2334641\ttotal: 14.1s\tremaining: 49s\n",
      "112:\tlearn: 0.2319731\ttotal: 14.3s\tremaining: 48.9s\n",
      "113:\tlearn: 0.2302469\ttotal: 14.4s\tremaining: 48.8s\n",
      "114:\tlearn: 0.2281382\ttotal: 14.5s\tremaining: 48.7s\n",
      "115:\tlearn: 0.2258684\ttotal: 14.6s\tremaining: 48.4s\n",
      "116:\tlearn: 0.2236979\ttotal: 14.7s\tremaining: 48.2s\n",
      "117:\tlearn: 0.2223566\ttotal: 14.9s\tremaining: 48.1s\n",
      "118:\tlearn: 0.2207368\ttotal: 14.9s\tremaining: 47.8s\n",
      "119:\tlearn: 0.2178633\ttotal: 15.1s\tremaining: 47.8s\n",
      "120:\tlearn: 0.2161406\ttotal: 15.2s\tremaining: 47.8s\n",
      "121:\tlearn: 0.2141110\ttotal: 15.4s\tremaining: 47.6s\n",
      "122:\tlearn: 0.2124848\ttotal: 15.5s\tremaining: 47.4s\n",
      "123:\tlearn: 0.2108238\ttotal: 15.6s\tremaining: 47.4s\n",
      "124:\tlearn: 0.2091483\ttotal: 15.8s\tremaining: 47.4s\n",
      "125:\tlearn: 0.2074348\ttotal: 15.9s\tremaining: 47.3s\n",
      "126:\tlearn: 0.2058586\ttotal: 16s\tremaining: 47.1s\n",
      "127:\tlearn: 0.2042397\ttotal: 16.1s\tremaining: 46.9s\n",
      "128:\tlearn: 0.2023853\ttotal: 16.3s\tremaining: 46.8s\n",
      "129:\tlearn: 0.2008546\ttotal: 16.4s\tremaining: 46.8s\n",
      "130:\tlearn: 0.1991989\ttotal: 16.5s\tremaining: 46.6s\n",
      "131:\tlearn: 0.1973657\ttotal: 16.7s\tremaining: 46.4s\n",
      "132:\tlearn: 0.1961369\ttotal: 16.8s\tremaining: 46.3s\n",
      "133:\tlearn: 0.1942950\ttotal: 16.9s\tremaining: 46.2s\n",
      "134:\tlearn: 0.1930146\ttotal: 17.1s\tremaining: 46.2s\n",
      "135:\tlearn: 0.1912921\ttotal: 17.2s\tremaining: 46.1s\n",
      "136:\tlearn: 0.1893733\ttotal: 17.3s\tremaining: 45.9s\n",
      "137:\tlearn: 0.1881360\ttotal: 17.5s\tremaining: 45.9s\n",
      "138:\tlearn: 0.1867486\ttotal: 17.6s\tremaining: 45.7s\n",
      "139:\tlearn: 0.1852607\ttotal: 17.7s\tremaining: 45.6s\n",
      "140:\tlearn: 0.1832478\ttotal: 17.8s\tremaining: 45.4s\n",
      "141:\tlearn: 0.1821161\ttotal: 18s\tremaining: 45.3s\n",
      "142:\tlearn: 0.1803072\ttotal: 18.1s\tremaining: 45.2s\n",
      "143:\tlearn: 0.1790244\ttotal: 18.3s\tremaining: 45.2s\n",
      "144:\tlearn: 0.1771607\ttotal: 18.4s\tremaining: 44.9s\n",
      "145:\tlearn: 0.1759177\ttotal: 18.4s\tremaining: 44.6s\n",
      "146:\tlearn: 0.1745804\ttotal: 18.6s\tremaining: 44.6s\n",
      "147:\tlearn: 0.1732406\ttotal: 18.7s\tremaining: 44.4s\n",
      "148:\tlearn: 0.1719174\ttotal: 18.8s\tremaining: 44.3s\n",
      "149:\tlearn: 0.1705981\ttotal: 18.9s\tremaining: 44.2s\n",
      "150:\tlearn: 0.1694163\ttotal: 19.1s\tremaining: 44.1s\n",
      "151:\tlearn: 0.1681437\ttotal: 19.2s\tremaining: 44s\n",
      "152:\tlearn: 0.1665268\ttotal: 19.4s\tremaining: 44s\n",
      "153:\tlearn: 0.1651326\ttotal: 19.5s\tremaining: 43.8s\n",
      "154:\tlearn: 0.1635510\ttotal: 19.6s\tremaining: 43.6s\n",
      "155:\tlearn: 0.1625870\ttotal: 19.7s\tremaining: 43.4s\n",
      "156:\tlearn: 0.1610571\ttotal: 19.8s\tremaining: 43.3s\n",
      "157:\tlearn: 0.1596952\ttotal: 20s\tremaining: 43.4s\n",
      "158:\tlearn: 0.1582547\ttotal: 20.1s\tremaining: 43.1s\n",
      "159:\tlearn: 0.1572663\ttotal: 20.2s\tremaining: 43s\n",
      "160:\tlearn: 0.1554395\ttotal: 20.3s\tremaining: 42.8s\n",
      "161:\tlearn: 0.1540742\ttotal: 20.5s\tremaining: 42.7s\n",
      "162:\tlearn: 0.1524121\ttotal: 20.6s\tremaining: 42.6s\n",
      "163:\tlearn: 0.1514008\ttotal: 20.8s\tremaining: 42.5s\n",
      "164:\tlearn: 0.1501369\ttotal: 20.9s\tremaining: 42.3s\n",
      "165:\tlearn: 0.1487985\ttotal: 20.9s\tremaining: 42.1s\n",
      "166:\tlearn: 0.1475072\ttotal: 21s\tremaining: 41.9s\n",
      "167:\tlearn: 0.1462780\ttotal: 21.1s\tremaining: 41.8s\n",
      "168:\tlearn: 0.1451969\ttotal: 21.3s\tremaining: 41.7s\n",
      "169:\tlearn: 0.1438970\ttotal: 21.4s\tremaining: 41.6s\n",
      "170:\tlearn: 0.1429648\ttotal: 21.6s\tremaining: 41.5s\n",
      "171:\tlearn: 0.1418655\ttotal: 21.7s\tremaining: 41.4s\n",
      "172:\tlearn: 0.1408530\ttotal: 21.8s\tremaining: 41.2s\n",
      "173:\tlearn: 0.1396132\ttotal: 21.9s\tremaining: 41.1s\n",
      "174:\tlearn: 0.1382135\ttotal: 22.1s\tremaining: 41s\n",
      "175:\tlearn: 0.1372260\ttotal: 22.1s\tremaining: 40.8s\n",
      "176:\tlearn: 0.1360191\ttotal: 22.2s\tremaining: 40.6s\n",
      "177:\tlearn: 0.1352613\ttotal: 22.4s\tremaining: 40.5s\n",
      "178:\tlearn: 0.1341886\ttotal: 22.6s\tremaining: 40.4s\n",
      "179:\tlearn: 0.1333562\ttotal: 22.6s\tremaining: 40.3s\n",
      "180:\tlearn: 0.1323289\ttotal: 22.8s\tremaining: 40.2s\n",
      "181:\tlearn: 0.1312174\ttotal: 22.9s\tremaining: 40.1s\n",
      "182:\tlearn: 0.1301663\ttotal: 23s\tremaining: 39.9s\n",
      "183:\tlearn: 0.1290934\ttotal: 23.2s\tremaining: 39.8s\n",
      "184:\tlearn: 0.1278797\ttotal: 23.3s\tremaining: 39.6s\n",
      "185:\tlearn: 0.1266048\ttotal: 23.4s\tremaining: 39.5s\n",
      "186:\tlearn: 0.1258253\ttotal: 23.5s\tremaining: 39.3s\n",
      "187:\tlearn: 0.1248951\ttotal: 23.6s\tremaining: 39.2s\n",
      "188:\tlearn: 0.1234459\ttotal: 23.7s\tremaining: 39.1s\n",
      "189:\tlearn: 0.1226193\ttotal: 23.9s\tremaining: 38.9s\n",
      "190:\tlearn: 0.1213957\ttotal: 24s\tremaining: 38.8s\n",
      "191:\tlearn: 0.1205509\ttotal: 24.1s\tremaining: 38.7s\n",
      "192:\tlearn: 0.1196248\ttotal: 24.2s\tremaining: 38.6s\n",
      "193:\tlearn: 0.1189289\ttotal: 24.3s\tremaining: 38.4s\n",
      "194:\tlearn: 0.1183454\ttotal: 24.4s\tremaining: 38.2s\n",
      "195:\tlearn: 0.1174201\ttotal: 24.5s\tremaining: 38s\n",
      "196:\tlearn: 0.1165501\ttotal: 24.7s\tremaining: 38s\n",
      "197:\tlearn: 0.1150293\ttotal: 24.9s\tremaining: 37.9s\n",
      "198:\tlearn: 0.1142141\ttotal: 25s\tremaining: 37.8s\n",
      "199:\tlearn: 0.1131167\ttotal: 25.1s\tremaining: 37.7s\n",
      "200:\tlearn: 0.1124506\ttotal: 25.2s\tremaining: 37.5s\n",
      "201:\tlearn: 0.1118226\ttotal: 25.4s\tremaining: 37.5s\n",
      "202:\tlearn: 0.1112514\ttotal: 25.5s\tremaining: 37.4s\n",
      "203:\tlearn: 0.1103147\ttotal: 25.6s\tremaining: 37.2s\n",
      "204:\tlearn: 0.1097066\ttotal: 25.7s\tremaining: 37s\n",
      "205:\tlearn: 0.1091085\ttotal: 25.9s\tremaining: 36.9s\n",
      "206:\tlearn: 0.1085038\ttotal: 26s\tremaining: 36.9s\n",
      "207:\tlearn: 0.1077737\ttotal: 26.2s\tremaining: 36.7s\n",
      "208:\tlearn: 0.1071028\ttotal: 26.3s\tremaining: 36.6s\n",
      "209:\tlearn: 0.1063505\ttotal: 26.4s\tremaining: 36.5s\n",
      "210:\tlearn: 0.1054922\ttotal: 26.6s\tremaining: 36.4s\n",
      "211:\tlearn: 0.1049827\ttotal: 26.7s\tremaining: 36.3s\n",
      "212:\tlearn: 0.1041845\ttotal: 26.8s\tremaining: 36.1s\n",
      "213:\tlearn: 0.1034475\ttotal: 26.9s\tremaining: 36s\n",
      "214:\tlearn: 0.1028374\ttotal: 27s\tremaining: 35.8s\n",
      "215:\tlearn: 0.1021581\ttotal: 27.1s\tremaining: 35.7s\n",
      "216:\tlearn: 0.1015143\ttotal: 27.3s\tremaining: 35.6s\n",
      "217:\tlearn: 0.1008842\ttotal: 27.4s\tremaining: 35.4s\n",
      "218:\tlearn: 0.1000274\ttotal: 27.5s\tremaining: 35.3s\n",
      "219:\tlearn: 0.0994001\ttotal: 27.6s\tremaining: 35.2s\n",
      "220:\tlearn: 0.0987942\ttotal: 27.8s\tremaining: 35.1s\n",
      "221:\tlearn: 0.0979452\ttotal: 27.9s\tremaining: 34.9s\n",
      "222:\tlearn: 0.0973991\ttotal: 28s\tremaining: 34.8s\n",
      "223:\tlearn: 0.0967845\ttotal: 28.1s\tremaining: 34.6s\n",
      "224:\tlearn: 0.0962403\ttotal: 28.2s\tremaining: 34.5s\n",
      "225:\tlearn: 0.0955219\ttotal: 28.4s\tremaining: 34.4s\n",
      "226:\tlearn: 0.0949386\ttotal: 28.5s\tremaining: 34.2s\n",
      "227:\tlearn: 0.0944761\ttotal: 28.6s\tremaining: 34.1s\n",
      "228:\tlearn: 0.0939272\ttotal: 28.8s\tremaining: 34s\n",
      "229:\tlearn: 0.0934440\ttotal: 28.9s\tremaining: 33.9s\n",
      "230:\tlearn: 0.0930270\ttotal: 29s\tremaining: 33.7s\n",
      "231:\tlearn: 0.0925021\ttotal: 29.1s\tremaining: 33.6s\n",
      "232:\tlearn: 0.0920021\ttotal: 29.2s\tremaining: 33.4s\n",
      "233:\tlearn: 0.0915493\ttotal: 29.3s\tremaining: 33.3s\n",
      "234:\tlearn: 0.0910103\ttotal: 29.4s\tremaining: 33.2s\n",
      "235:\tlearn: 0.0901814\ttotal: 29.5s\tremaining: 33s\n",
      "236:\tlearn: 0.0897057\ttotal: 29.7s\tremaining: 32.9s\n",
      "237:\tlearn: 0.0890419\ttotal: 29.8s\tremaining: 32.8s\n",
      "238:\tlearn: 0.0885337\ttotal: 29.9s\tremaining: 32.7s\n",
      "239:\tlearn: 0.0879446\ttotal: 30.1s\tremaining: 32.6s\n",
      "240:\tlearn: 0.0875240\ttotal: 30.2s\tremaining: 32.4s\n",
      "241:\tlearn: 0.0870190\ttotal: 30.3s\tremaining: 32.3s\n",
      "242:\tlearn: 0.0864710\ttotal: 30.6s\tremaining: 32.3s\n",
      "243:\tlearn: 0.0860084\ttotal: 30.7s\tremaining: 32.2s\n",
      "244:\tlearn: 0.0854829\ttotal: 30.7s\tremaining: 32s\n",
      "245:\tlearn: 0.0850227\ttotal: 30.7s\tremaining: 31.7s\n",
      "246:\tlearn: 0.0845883\ttotal: 30.9s\tremaining: 31.6s\n",
      "247:\tlearn: 0.0841258\ttotal: 31s\tremaining: 31.5s\n",
      "248:\tlearn: 0.0837675\ttotal: 31.2s\tremaining: 31.4s\n",
      "249:\tlearn: 0.0833708\ttotal: 31.3s\tremaining: 31.3s\n",
      "250:\tlearn: 0.0830397\ttotal: 31.5s\tremaining: 31.2s\n",
      "251:\tlearn: 0.0826244\ttotal: 31.6s\tremaining: 31.1s\n",
      "252:\tlearn: 0.0819863\ttotal: 31.7s\tremaining: 30.9s\n",
      "253:\tlearn: 0.0815979\ttotal: 31.8s\tremaining: 30.8s\n",
      "254:\tlearn: 0.0811997\ttotal: 31.9s\tremaining: 30.7s\n",
      "255:\tlearn: 0.0806282\ttotal: 32s\tremaining: 30.5s\n",
      "256:\tlearn: 0.0802503\ttotal: 32.2s\tremaining: 30.4s\n",
      "257:\tlearn: 0.0798289\ttotal: 32.3s\tremaining: 30.3s\n",
      "258:\tlearn: 0.0793549\ttotal: 32.5s\tremaining: 30.2s\n",
      "259:\tlearn: 0.0789006\ttotal: 32.6s\tremaining: 30.1s\n",
      "260:\tlearn: 0.0785437\ttotal: 32.7s\tremaining: 30s\n",
      "261:\tlearn: 0.0782746\ttotal: 32.8s\tremaining: 29.8s\n",
      "262:\tlearn: 0.0778685\ttotal: 32.9s\tremaining: 29.7s\n",
      "263:\tlearn: 0.0775269\ttotal: 33.1s\tremaining: 29.6s\n",
      "264:\tlearn: 0.0771771\ttotal: 33.2s\tremaining: 29.4s\n",
      "265:\tlearn: 0.0767274\ttotal: 33.2s\tremaining: 29.2s\n",
      "266:\tlearn: 0.0763793\ttotal: 33.4s\tremaining: 29.2s\n",
      "267:\tlearn: 0.0760578\ttotal: 33.5s\tremaining: 29s\n",
      "268:\tlearn: 0.0756159\ttotal: 33.7s\tremaining: 28.9s\n",
      "269:\tlearn: 0.0752742\ttotal: 33.8s\tremaining: 28.8s\n",
      "270:\tlearn: 0.0748545\ttotal: 33.9s\tremaining: 28.7s\n",
      "271:\tlearn: 0.0745366\ttotal: 34.1s\tremaining: 28.6s\n",
      "272:\tlearn: 0.0742360\ttotal: 34.2s\tremaining: 28.4s\n",
      "273:\tlearn: 0.0739027\ttotal: 34.3s\tremaining: 28.3s\n",
      "274:\tlearn: 0.0734933\ttotal: 34.4s\tremaining: 28.2s\n",
      "275:\tlearn: 0.0730776\ttotal: 34.6s\tremaining: 28.1s\n",
      "276:\tlearn: 0.0727229\ttotal: 34.8s\tremaining: 28s\n",
      "277:\tlearn: 0.0723794\ttotal: 34.8s\tremaining: 27.8s\n",
      "278:\tlearn: 0.0720249\ttotal: 34.9s\tremaining: 27.7s\n",
      "279:\tlearn: 0.0716882\ttotal: 35s\tremaining: 27.5s\n",
      "280:\tlearn: 0.0713304\ttotal: 35.1s\tremaining: 27.4s\n",
      "281:\tlearn: 0.0709447\ttotal: 35.2s\tremaining: 27.2s\n",
      "282:\tlearn: 0.0704463\ttotal: 35.3s\tremaining: 27.1s\n",
      "283:\tlearn: 0.0701756\ttotal: 35.4s\tremaining: 26.9s\n",
      "284:\tlearn: 0.0698671\ttotal: 35.5s\tremaining: 26.8s\n",
      "285:\tlearn: 0.0694989\ttotal: 35.6s\tremaining: 26.6s\n",
      "286:\tlearn: 0.0692273\ttotal: 35.7s\tremaining: 26.5s\n",
      "287:\tlearn: 0.0689493\ttotal: 35.8s\tremaining: 26.4s\n",
      "288:\tlearn: 0.0686373\ttotal: 36s\tremaining: 26.3s\n",
      "289:\tlearn: 0.0682599\ttotal: 36.1s\tremaining: 26.1s\n",
      "290:\tlearn: 0.0680107\ttotal: 36.2s\tremaining: 26s\n",
      "291:\tlearn: 0.0677018\ttotal: 36.3s\tremaining: 25.9s\n",
      "292:\tlearn: 0.0674245\ttotal: 36.4s\tremaining: 25.7s\n",
      "293:\tlearn: 0.0671381\ttotal: 36.5s\tremaining: 25.6s\n",
      "294:\tlearn: 0.0668908\ttotal: 36.6s\tremaining: 25.5s\n",
      "295:\tlearn: 0.0666509\ttotal: 36.8s\tremaining: 25.3s\n",
      "296:\tlearn: 0.0663762\ttotal: 36.9s\tremaining: 25.2s\n",
      "297:\tlearn: 0.0660244\ttotal: 37s\tremaining: 25.1s\n",
      "298:\tlearn: 0.0657003\ttotal: 37.1s\tremaining: 24.9s\n",
      "299:\tlearn: 0.0654900\ttotal: 37.2s\tremaining: 24.8s\n",
      "300:\tlearn: 0.0651488\ttotal: 37.3s\tremaining: 24.7s\n",
      "301:\tlearn: 0.0649314\ttotal: 37.4s\tremaining: 24.5s\n",
      "302:\tlearn: 0.0646122\ttotal: 37.5s\tremaining: 24.4s\n",
      "303:\tlearn: 0.0642646\ttotal: 37.7s\tremaining: 24.3s\n",
      "304:\tlearn: 0.0640587\ttotal: 37.8s\tremaining: 24.1s\n",
      "305:\tlearn: 0.0638895\ttotal: 37.9s\tremaining: 24s\n",
      "306:\tlearn: 0.0634878\ttotal: 38s\tremaining: 23.9s\n",
      "307:\tlearn: 0.0632668\ttotal: 38.2s\tremaining: 23.8s\n",
      "308:\tlearn: 0.0629689\ttotal: 38.3s\tremaining: 23.7s\n",
      "309:\tlearn: 0.0626999\ttotal: 38.4s\tremaining: 23.5s\n",
      "310:\tlearn: 0.0624619\ttotal: 38.5s\tremaining: 23.4s\n",
      "311:\tlearn: 0.0622218\ttotal: 38.6s\tremaining: 23.3s\n",
      "312:\tlearn: 0.0620286\ttotal: 38.7s\tremaining: 23.1s\n",
      "313:\tlearn: 0.0616952\ttotal: 38.8s\tremaining: 23s\n",
      "314:\tlearn: 0.0614355\ttotal: 38.9s\tremaining: 22.9s\n",
      "315:\tlearn: 0.0610822\ttotal: 39.1s\tremaining: 22.7s\n",
      "316:\tlearn: 0.0608005\ttotal: 39.2s\tremaining: 22.6s\n",
      "317:\tlearn: 0.0604968\ttotal: 39.2s\tremaining: 22.5s\n",
      "318:\tlearn: 0.0602972\ttotal: 39.3s\tremaining: 22.3s\n",
      "319:\tlearn: 0.0600682\ttotal: 39.4s\tremaining: 22.2s\n",
      "320:\tlearn: 0.0598368\ttotal: 39.6s\tremaining: 22.1s\n",
      "321:\tlearn: 0.0595834\ttotal: 39.7s\tremaining: 21.9s\n",
      "322:\tlearn: 0.0593521\ttotal: 39.8s\tremaining: 21.8s\n",
      "323:\tlearn: 0.0590954\ttotal: 39.9s\tremaining: 21.7s\n",
      "324:\tlearn: 0.0588919\ttotal: 40s\tremaining: 21.5s\n",
      "325:\tlearn: 0.0586752\ttotal: 40.1s\tremaining: 21.4s\n",
      "326:\tlearn: 0.0584763\ttotal: 40.2s\tremaining: 21.3s\n",
      "327:\tlearn: 0.0582643\ttotal: 40.3s\tremaining: 21.1s\n",
      "328:\tlearn: 0.0580544\ttotal: 40.4s\tremaining: 21s\n",
      "329:\tlearn: 0.0578510\ttotal: 40.5s\tremaining: 20.9s\n",
      "330:\tlearn: 0.0576008\ttotal: 40.7s\tremaining: 20.8s\n",
      "331:\tlearn: 0.0573224\ttotal: 40.7s\tremaining: 20.6s\n",
      "332:\tlearn: 0.0571206\ttotal: 40.8s\tremaining: 20.5s\n",
      "333:\tlearn: 0.0568811\ttotal: 40.9s\tremaining: 20.4s\n",
      "334:\tlearn: 0.0566839\ttotal: 41.1s\tremaining: 20.2s\n",
      "335:\tlearn: 0.0564867\ttotal: 41.2s\tremaining: 20.1s\n",
      "336:\tlearn: 0.0562797\ttotal: 41.3s\tremaining: 20s\n",
      "337:\tlearn: 0.0560882\ttotal: 41.5s\tremaining: 19.9s\n",
      "338:\tlearn: 0.0558546\ttotal: 41.5s\tremaining: 19.7s\n",
      "339:\tlearn: 0.0556177\ttotal: 41.6s\tremaining: 19.6s\n",
      "340:\tlearn: 0.0553175\ttotal: 41.7s\tremaining: 19.5s\n",
      "341:\tlearn: 0.0551134\ttotal: 41.9s\tremaining: 19.3s\n",
      "342:\tlearn: 0.0549410\ttotal: 42s\tremaining: 19.2s\n",
      "343:\tlearn: 0.0547666\ttotal: 42.1s\tremaining: 19.1s\n",
      "344:\tlearn: 0.0545785\ttotal: 42.2s\tremaining: 19s\n",
      "345:\tlearn: 0.0543666\ttotal: 42.3s\tremaining: 18.8s\n",
      "346:\tlearn: 0.0541203\ttotal: 42.4s\tremaining: 18.7s\n",
      "347:\tlearn: 0.0538848\ttotal: 42.6s\tremaining: 18.6s\n",
      "348:\tlearn: 0.0536756\ttotal: 42.7s\tremaining: 18.5s\n",
      "349:\tlearn: 0.0534533\ttotal: 42.8s\tremaining: 18.3s\n",
      "350:\tlearn: 0.0532342\ttotal: 42.9s\tremaining: 18.2s\n",
      "351:\tlearn: 0.0530768\ttotal: 43s\tremaining: 18.1s\n",
      "352:\tlearn: 0.0528753\ttotal: 43.1s\tremaining: 17.9s\n",
      "353:\tlearn: 0.0526726\ttotal: 43.2s\tremaining: 17.8s\n",
      "354:\tlearn: 0.0524910\ttotal: 43.3s\tremaining: 17.7s\n",
      "355:\tlearn: 0.0522967\ttotal: 43.4s\tremaining: 17.5s\n",
      "356:\tlearn: 0.0520741\ttotal: 43.5s\tremaining: 17.4s\n",
      "357:\tlearn: 0.0518035\ttotal: 43.6s\tremaining: 17.3s\n",
      "358:\tlearn: 0.0515727\ttotal: 43.7s\tremaining: 17.2s\n",
      "359:\tlearn: 0.0514355\ttotal: 43.8s\tremaining: 17s\n",
      "360:\tlearn: 0.0512118\ttotal: 43.9s\tremaining: 16.9s\n",
      "361:\tlearn: 0.0510802\ttotal: 44s\tremaining: 16.8s\n",
      "362:\tlearn: 0.0509081\ttotal: 44.1s\tremaining: 16.6s\n",
      "363:\tlearn: 0.0507663\ttotal: 44.2s\tremaining: 16.5s\n",
      "364:\tlearn: 0.0506157\ttotal: 44.3s\tremaining: 16.4s\n",
      "365:\tlearn: 0.0504780\ttotal: 44.4s\tremaining: 16.3s\n",
      "366:\tlearn: 0.0502731\ttotal: 44.5s\tremaining: 16.1s\n",
      "367:\tlearn: 0.0501270\ttotal: 44.6s\tremaining: 16s\n",
      "368:\tlearn: 0.0498697\ttotal: 44.8s\tremaining: 15.9s\n",
      "369:\tlearn: 0.0497242\ttotal: 44.9s\tremaining: 15.8s\n",
      "370:\tlearn: 0.0495193\ttotal: 45s\tremaining: 15.6s\n",
      "371:\tlearn: 0.0493416\ttotal: 45.1s\tremaining: 15.5s\n",
      "372:\tlearn: 0.0492061\ttotal: 45.2s\tremaining: 15.4s\n",
      "373:\tlearn: 0.0490463\ttotal: 45.3s\tremaining: 15.3s\n",
      "374:\tlearn: 0.0487931\ttotal: 45.4s\tremaining: 15.1s\n",
      "375:\tlearn: 0.0485904\ttotal: 45.6s\tremaining: 15s\n",
      "376:\tlearn: 0.0484381\ttotal: 45.7s\tremaining: 14.9s\n",
      "377:\tlearn: 0.0482423\ttotal: 45.8s\tremaining: 14.8s\n",
      "378:\tlearn: 0.0480309\ttotal: 45.9s\tremaining: 14.7s\n",
      "379:\tlearn: 0.0478457\ttotal: 46.1s\tremaining: 14.5s\n",
      "380:\tlearn: 0.0476682\ttotal: 46.1s\tremaining: 14.4s\n",
      "381:\tlearn: 0.0474388\ttotal: 46.2s\tremaining: 14.3s\n",
      "382:\tlearn: 0.0471988\ttotal: 46.3s\tremaining: 14.2s\n",
      "383:\tlearn: 0.0470850\ttotal: 46.5s\tremaining: 14s\n",
      "384:\tlearn: 0.0468915\ttotal: 46.6s\tremaining: 13.9s\n",
      "385:\tlearn: 0.0467094\ttotal: 46.7s\tremaining: 13.8s\n",
      "386:\tlearn: 0.0464940\ttotal: 46.8s\tremaining: 13.7s\n",
      "387:\tlearn: 0.0462730\ttotal: 46.9s\tremaining: 13.5s\n",
      "388:\tlearn: 0.0461393\ttotal: 46.9s\tremaining: 13.4s\n",
      "389:\tlearn: 0.0459758\ttotal: 47.1s\tremaining: 13.3s\n",
      "390:\tlearn: 0.0457917\ttotal: 47.1s\tremaining: 13.1s\n",
      "391:\tlearn: 0.0456540\ttotal: 47.3s\tremaining: 13s\n",
      "392:\tlearn: 0.0455000\ttotal: 47.4s\tremaining: 12.9s\n",
      "393:\tlearn: 0.0453475\ttotal: 47.5s\tremaining: 12.8s\n",
      "394:\tlearn: 0.0452086\ttotal: 47.6s\tremaining: 12.7s\n",
      "395:\tlearn: 0.0450801\ttotal: 47.7s\tremaining: 12.5s\n",
      "396:\tlearn: 0.0449572\ttotal: 47.8s\tremaining: 12.4s\n",
      "397:\tlearn: 0.0447955\ttotal: 47.9s\tremaining: 12.3s\n",
      "398:\tlearn: 0.0446704\ttotal: 48.1s\tremaining: 12.2s\n",
      "399:\tlearn: 0.0445575\ttotal: 48.2s\tremaining: 12.1s\n",
      "400:\tlearn: 0.0444323\ttotal: 48.3s\tremaining: 11.9s\n",
      "401:\tlearn: 0.0442815\ttotal: 48.4s\tremaining: 11.8s\n",
      "402:\tlearn: 0.0441169\ttotal: 48.6s\tremaining: 11.7s\n",
      "403:\tlearn: 0.0439645\ttotal: 48.6s\tremaining: 11.6s\n",
      "404:\tlearn: 0.0437770\ttotal: 48.8s\tremaining: 11.4s\n",
      "405:\tlearn: 0.0436267\ttotal: 48.9s\tremaining: 11.3s\n",
      "406:\tlearn: 0.0434880\ttotal: 49s\tremaining: 11.2s\n",
      "407:\tlearn: 0.0433662\ttotal: 49.1s\tremaining: 11.1s\n",
      "408:\tlearn: 0.0432664\ttotal: 49.3s\tremaining: 11s\n",
      "409:\tlearn: 0.0431610\ttotal: 49.4s\tremaining: 10.8s\n",
      "410:\tlearn: 0.0430289\ttotal: 49.5s\tremaining: 10.7s\n",
      "411:\tlearn: 0.0429143\ttotal: 49.6s\tremaining: 10.6s\n",
      "412:\tlearn: 0.0428026\ttotal: 49.7s\tremaining: 10.5s\n",
      "413:\tlearn: 0.0426413\ttotal: 49.8s\tremaining: 10.3s\n",
      "414:\tlearn: 0.0425347\ttotal: 49.9s\tremaining: 10.2s\n",
      "415:\tlearn: 0.0423945\ttotal: 50s\tremaining: 10.1s\n",
      "416:\tlearn: 0.0422345\ttotal: 50.1s\tremaining: 9.98s\n",
      "417:\tlearn: 0.0421037\ttotal: 50.3s\tremaining: 9.86s\n",
      "418:\tlearn: 0.0419869\ttotal: 50.4s\tremaining: 9.74s\n",
      "419:\tlearn: 0.0418733\ttotal: 50.5s\tremaining: 9.61s\n",
      "420:\tlearn: 0.0417699\ttotal: 50.6s\tremaining: 9.49s\n",
      "421:\tlearn: 0.0416380\ttotal: 50.6s\tremaining: 9.36s\n",
      "422:\tlearn: 0.0415232\ttotal: 50.8s\tremaining: 9.24s\n",
      "423:\tlearn: 0.0413780\ttotal: 50.8s\tremaining: 9.11s\n",
      "424:\tlearn: 0.0412041\ttotal: 51s\tremaining: 8.99s\n",
      "425:\tlearn: 0.0410903\ttotal: 51.1s\tremaining: 8.88s\n",
      "426:\tlearn: 0.0409993\ttotal: 51.2s\tremaining: 8.75s\n",
      "427:\tlearn: 0.0408616\ttotal: 51.3s\tremaining: 8.63s\n",
      "428:\tlearn: 0.0407666\ttotal: 51.4s\tremaining: 8.5s\n",
      "429:\tlearn: 0.0406296\ttotal: 51.5s\tremaining: 8.38s\n",
      "430:\tlearn: 0.0405154\ttotal: 51.6s\tremaining: 8.26s\n",
      "431:\tlearn: 0.0404245\ttotal: 51.7s\tremaining: 8.14s\n",
      "432:\tlearn: 0.0402976\ttotal: 51.8s\tremaining: 8.02s\n",
      "433:\tlearn: 0.0401790\ttotal: 52s\tremaining: 7.9s\n",
      "434:\tlearn: 0.0400526\ttotal: 52.1s\tremaining: 7.78s\n",
      "435:\tlearn: 0.0399242\ttotal: 52.2s\tremaining: 7.66s\n",
      "436:\tlearn: 0.0398052\ttotal: 52.3s\tremaining: 7.53s\n",
      "437:\tlearn: 0.0397006\ttotal: 52.3s\tremaining: 7.41s\n",
      "438:\tlearn: 0.0395841\ttotal: 52.5s\tremaining: 7.29s\n",
      "439:\tlearn: 0.0394869\ttotal: 52.6s\tremaining: 7.17s\n",
      "440:\tlearn: 0.0393826\ttotal: 52.7s\tremaining: 7.05s\n",
      "441:\tlearn: 0.0392308\ttotal: 52.8s\tremaining: 6.92s\n",
      "442:\tlearn: 0.0391174\ttotal: 52.8s\tremaining: 6.8s\n",
      "443:\tlearn: 0.0390242\ttotal: 53s\tremaining: 6.68s\n",
      "444:\tlearn: 0.0389205\ttotal: 53.1s\tremaining: 6.56s\n",
      "445:\tlearn: 0.0388208\ttotal: 53.2s\tremaining: 6.44s\n",
      "446:\tlearn: 0.0387161\ttotal: 53.3s\tremaining: 6.32s\n",
      "447:\tlearn: 0.0386310\ttotal: 53.4s\tremaining: 6.2s\n",
      "448:\tlearn: 0.0384754\ttotal: 53.5s\tremaining: 6.08s\n",
      "449:\tlearn: 0.0383754\ttotal: 53.6s\tremaining: 5.95s\n",
      "450:\tlearn: 0.0382729\ttotal: 53.7s\tremaining: 5.83s\n",
      "451:\tlearn: 0.0380843\ttotal: 53.8s\tremaining: 5.71s\n",
      "452:\tlearn: 0.0379831\ttotal: 53.9s\tremaining: 5.6s\n",
      "453:\tlearn: 0.0378795\ttotal: 54.1s\tremaining: 5.48s\n",
      "454:\tlearn: 0.0377637\ttotal: 54.2s\tremaining: 5.36s\n",
      "455:\tlearn: 0.0376494\ttotal: 54.3s\tremaining: 5.23s\n",
      "456:\tlearn: 0.0375560\ttotal: 54.3s\tremaining: 5.11s\n",
      "457:\tlearn: 0.0374532\ttotal: 54.4s\tremaining: 4.99s\n",
      "458:\tlearn: 0.0373734\ttotal: 54.5s\tremaining: 4.87s\n",
      "459:\tlearn: 0.0372823\ttotal: 54.6s\tremaining: 4.75s\n",
      "460:\tlearn: 0.0371984\ttotal: 54.8s\tremaining: 4.63s\n",
      "461:\tlearn: 0.0370771\ttotal: 54.9s\tremaining: 4.51s\n",
      "462:\tlearn: 0.0369509\ttotal: 55s\tremaining: 4.39s\n",
      "463:\tlearn: 0.0368589\ttotal: 55.1s\tremaining: 4.27s\n",
      "464:\tlearn: 0.0367693\ttotal: 55.1s\tremaining: 4.15s\n",
      "465:\tlearn: 0.0366913\ttotal: 55.3s\tremaining: 4.03s\n",
      "466:\tlearn: 0.0365996\ttotal: 55.4s\tremaining: 3.91s\n",
      "467:\tlearn: 0.0365083\ttotal: 55.5s\tremaining: 3.79s\n",
      "468:\tlearn: 0.0364108\ttotal: 55.6s\tremaining: 3.67s\n",
      "469:\tlearn: 0.0363170\ttotal: 55.7s\tremaining: 3.56s\n",
      "470:\tlearn: 0.0361968\ttotal: 55.8s\tremaining: 3.43s\n",
      "471:\tlearn: 0.0361002\ttotal: 55.9s\tremaining: 3.32s\n",
      "472:\tlearn: 0.0359991\ttotal: 56s\tremaining: 3.2s\n",
      "473:\tlearn: 0.0359202\ttotal: 56.2s\tremaining: 3.08s\n",
      "474:\tlearn: 0.0357983\ttotal: 56.3s\tremaining: 2.96s\n",
      "475:\tlearn: 0.0357274\ttotal: 56.4s\tremaining: 2.84s\n",
      "476:\tlearn: 0.0356084\ttotal: 56.5s\tremaining: 2.72s\n",
      "477:\tlearn: 0.0355247\ttotal: 56.5s\tremaining: 2.6s\n",
      "478:\tlearn: 0.0354186\ttotal: 56.7s\tremaining: 2.49s\n",
      "479:\tlearn: 0.0353323\ttotal: 56.8s\tremaining: 2.37s\n",
      "480:\tlearn: 0.0352590\ttotal: 56.9s\tremaining: 2.25s\n",
      "481:\tlearn: 0.0351968\ttotal: 57s\tremaining: 2.13s\n",
      "482:\tlearn: 0.0350107\ttotal: 57.1s\tremaining: 2.01s\n",
      "483:\tlearn: 0.0349437\ttotal: 57.2s\tremaining: 1.89s\n",
      "484:\tlearn: 0.0348478\ttotal: 57.3s\tremaining: 1.77s\n",
      "485:\tlearn: 0.0347254\ttotal: 57.4s\tremaining: 1.65s\n",
      "486:\tlearn: 0.0346590\ttotal: 57.5s\tremaining: 1.53s\n",
      "487:\tlearn: 0.0345849\ttotal: 57.7s\tremaining: 1.42s\n",
      "488:\tlearn: 0.0345088\ttotal: 57.8s\tremaining: 1.3s\n",
      "489:\tlearn: 0.0344140\ttotal: 57.9s\tremaining: 1.18s\n",
      "490:\tlearn: 0.0343290\ttotal: 58s\tremaining: 1.06s\n",
      "491:\tlearn: 0.0342526\ttotal: 58.1s\tremaining: 944ms\n",
      "492:\tlearn: 0.0341804\ttotal: 58.2s\tremaining: 826ms\n",
      "493:\tlearn: 0.0341041\ttotal: 58.3s\tremaining: 708ms\n",
      "494:\tlearn: 0.0340273\ttotal: 58.4s\tremaining: 590ms\n",
      "495:\tlearn: 0.0339491\ttotal: 58.5s\tremaining: 472ms\n",
      "496:\tlearn: 0.0338825\ttotal: 58.7s\tremaining: 354ms\n",
      "497:\tlearn: 0.0337910\ttotal: 58.8s\tremaining: 236ms\n",
      "498:\tlearn: 0.0337173\ttotal: 58.9s\tremaining: 118ms\n",
      "499:\tlearn: 0.0336376\ttotal: 59s\tremaining: 0us\n",
      "Accuracy: 0.5652173913043478\n",
      "\n",
      "Confusion Matrix:\n",
      " [[8 7]\n",
      " [3 5]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.53      0.62        15\n",
      "           1       0.42      0.62      0.50         8\n",
      "\n",
      "    accuracy                           0.57        23\n",
      "   macro avg       0.57      0.58      0.56        23\n",
      "weighted avg       0.62      0.57      0.58        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Fraud'], axis=1)\n",
    "y = df['Fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a CatBoost Classifier\n",
    "model = CatBoostClassifier(iterations=500, depth=10, learning_rate=0.05, loss_function='MultiClass', random_seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, cat_features=None)  # You can specify categorical features if needed\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/combined/combined_ros_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"Fraud_x\",\"FraudType_x\",\"Rndrng_NPI\",],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6514469\ttotal: 1.57s\tremaining: 13m 4s\n",
      "1:\tlearn: 0.6131925\ttotal: 2.97s\tremaining: 12m 19s\n",
      "2:\tlearn: 0.5798374\ttotal: 4.35s\tremaining: 12m\n",
      "3:\tlearn: 0.5486465\ttotal: 5.82s\tremaining: 12m 2s\n",
      "4:\tlearn: 0.5172231\ttotal: 7.18s\tremaining: 11m 50s\n",
      "5:\tlearn: 0.4896572\ttotal: 8.7s\tremaining: 11m 55s\n",
      "6:\tlearn: 0.4637551\ttotal: 9.98s\tremaining: 11m 42s\n",
      "7:\tlearn: 0.4387899\ttotal: 11.2s\tremaining: 11m 28s\n",
      "8:\tlearn: 0.4174396\ttotal: 12.3s\tremaining: 11m 10s\n",
      "9:\tlearn: 0.3964792\ttotal: 13.5s\tremaining: 11m 1s\n",
      "10:\tlearn: 0.3784300\ttotal: 14.6s\tremaining: 10m 49s\n",
      "11:\tlearn: 0.3607901\ttotal: 15.7s\tremaining: 10m 37s\n",
      "12:\tlearn: 0.3426458\ttotal: 16.9s\tremaining: 10m 33s\n",
      "13:\tlearn: 0.3260755\ttotal: 18.1s\tremaining: 10m 26s\n",
      "14:\tlearn: 0.3108150\ttotal: 19.3s\tremaining: 10m 23s\n",
      "15:\tlearn: 0.2974944\ttotal: 20.4s\tremaining: 10m 16s\n",
      "16:\tlearn: 0.2832565\ttotal: 21.6s\tremaining: 10m 14s\n",
      "17:\tlearn: 0.2713062\ttotal: 22.7s\tremaining: 10m 8s\n",
      "18:\tlearn: 0.2596308\ttotal: 23.9s\tremaining: 10m 4s\n",
      "19:\tlearn: 0.2493104\ttotal: 25s\tremaining: 10m 1s\n",
      "20:\tlearn: 0.2382995\ttotal: 26.1s\tremaining: 9m 56s\n",
      "21:\tlearn: 0.2279310\ttotal: 27.4s\tremaining: 9m 55s\n",
      "22:\tlearn: 0.2181054\ttotal: 28.6s\tremaining: 9m 52s\n",
      "23:\tlearn: 0.2083764\ttotal: 29.7s\tremaining: 9m 49s\n",
      "24:\tlearn: 0.1993655\ttotal: 30.9s\tremaining: 9m 46s\n",
      "25:\tlearn: 0.1903429\ttotal: 32.1s\tremaining: 9m 44s\n",
      "26:\tlearn: 0.1816322\ttotal: 33.3s\tremaining: 9m 43s\n",
      "27:\tlearn: 0.1741323\ttotal: 34.4s\tremaining: 9m 40s\n",
      "28:\tlearn: 0.1666669\ttotal: 35.7s\tremaining: 9m 39s\n",
      "29:\tlearn: 0.1593275\ttotal: 36.7s\tremaining: 9m 35s\n",
      "30:\tlearn: 0.1529543\ttotal: 38s\tremaining: 9m 35s\n",
      "31:\tlearn: 0.1466383\ttotal: 39.2s\tremaining: 9m 33s\n",
      "32:\tlearn: 0.1408005\ttotal: 40.3s\tremaining: 9m 30s\n",
      "33:\tlearn: 0.1355958\ttotal: 41.4s\tremaining: 9m 27s\n",
      "34:\tlearn: 0.1297103\ttotal: 42.6s\tremaining: 9m 25s\n",
      "35:\tlearn: 0.1246751\ttotal: 43.7s\tremaining: 9m 23s\n",
      "36:\tlearn: 0.1195392\ttotal: 44.8s\tremaining: 9m 20s\n",
      "37:\tlearn: 0.1149705\ttotal: 45.8s\tremaining: 9m 17s\n",
      "38:\tlearn: 0.1106426\ttotal: 47.1s\tremaining: 9m 17s\n",
      "39:\tlearn: 0.1064809\ttotal: 48.3s\tremaining: 9m 15s\n",
      "40:\tlearn: 0.1024622\ttotal: 49.5s\tremaining: 9m 14s\n",
      "41:\tlearn: 0.0985180\ttotal: 50.7s\tremaining: 9m 13s\n",
      "42:\tlearn: 0.0946348\ttotal: 51.9s\tremaining: 9m 11s\n",
      "43:\tlearn: 0.0910330\ttotal: 53s\tremaining: 9m 9s\n",
      "44:\tlearn: 0.0873892\ttotal: 54.1s\tremaining: 9m 7s\n",
      "45:\tlearn: 0.0840094\ttotal: 55.3s\tremaining: 9m 5s\n",
      "46:\tlearn: 0.0806017\ttotal: 56.4s\tremaining: 9m 3s\n",
      "47:\tlearn: 0.0777090\ttotal: 57.6s\tremaining: 9m 2s\n",
      "48:\tlearn: 0.0749281\ttotal: 58.7s\tremaining: 9m\n",
      "49:\tlearn: 0.0719801\ttotal: 1m\tremaining: 9m\n",
      "50:\tlearn: 0.0693785\ttotal: 1m 1s\tremaining: 8m 58s\n",
      "51:\tlearn: 0.0668974\ttotal: 1m 2s\tremaining: 8m 55s\n",
      "52:\tlearn: 0.0645456\ttotal: 1m 3s\tremaining: 8m 56s\n",
      "53:\tlearn: 0.0621340\ttotal: 1m 4s\tremaining: 8m 54s\n",
      "54:\tlearn: 0.0598537\ttotal: 1m 6s\tremaining: 8m 56s\n",
      "55:\tlearn: 0.0581322\ttotal: 1m 7s\tremaining: 8m 58s\n",
      "56:\tlearn: 0.0561127\ttotal: 1m 9s\tremaining: 8m 58s\n",
      "57:\tlearn: 0.0542250\ttotal: 1m 10s\tremaining: 8m 57s\n",
      "58:\tlearn: 0.0522082\ttotal: 1m 11s\tremaining: 8m 56s\n",
      "59:\tlearn: 0.0502074\ttotal: 1m 12s\tremaining: 8m 55s\n",
      "60:\tlearn: 0.0483561\ttotal: 1m 14s\tremaining: 8m 53s\n",
      "61:\tlearn: 0.0465956\ttotal: 1m 15s\tremaining: 8m 52s\n",
      "62:\tlearn: 0.0447918\ttotal: 1m 16s\tremaining: 8m 53s\n",
      "63:\tlearn: 0.0433572\ttotal: 1m 18s\tremaining: 8m 54s\n",
      "64:\tlearn: 0.0419295\ttotal: 1m 20s\tremaining: 8m 55s\n",
      "65:\tlearn: 0.0404733\ttotal: 1m 21s\tremaining: 8m 56s\n",
      "66:\tlearn: 0.0391741\ttotal: 1m 23s\tremaining: 8m 56s\n",
      "67:\tlearn: 0.0377485\ttotal: 1m 24s\tremaining: 8m 57s\n",
      "68:\tlearn: 0.0363806\ttotal: 1m 26s\tremaining: 9m\n",
      "69:\tlearn: 0.0352232\ttotal: 1m 28s\tremaining: 9m\n",
      "70:\tlearn: 0.0341045\ttotal: 1m 29s\tremaining: 9m 2s\n",
      "71:\tlearn: 0.0329070\ttotal: 1m 31s\tremaining: 9m 2s\n",
      "72:\tlearn: 0.0317897\ttotal: 1m 32s\tremaining: 9m 3s\n",
      "73:\tlearn: 0.0306801\ttotal: 1m 34s\tremaining: 9m 5s\n",
      "74:\tlearn: 0.0297858\ttotal: 1m 36s\tremaining: 9m 5s\n",
      "75:\tlearn: 0.0288600\ttotal: 1m 37s\tremaining: 9m 5s\n",
      "76:\tlearn: 0.0278870\ttotal: 1m 39s\tremaining: 9m 5s\n",
      "77:\tlearn: 0.0270247\ttotal: 1m 40s\tremaining: 9m 6s\n",
      "78:\tlearn: 0.0262701\ttotal: 1m 42s\tremaining: 9m 6s\n",
      "79:\tlearn: 0.0254270\ttotal: 1m 44s\tremaining: 9m 6s\n",
      "80:\tlearn: 0.0248778\ttotal: 1m 45s\tremaining: 9m 7s\n",
      "81:\tlearn: 0.0241298\ttotal: 1m 47s\tremaining: 9m 7s\n",
      "82:\tlearn: 0.0233731\ttotal: 1m 49s\tremaining: 9m 8s\n",
      "83:\tlearn: 0.0226664\ttotal: 1m 50s\tremaining: 9m 8s\n",
      "84:\tlearn: 0.0219926\ttotal: 1m 52s\tremaining: 9m 8s\n",
      "85:\tlearn: 0.0213208\ttotal: 1m 53s\tremaining: 9m 8s\n",
      "86:\tlearn: 0.0207539\ttotal: 1m 55s\tremaining: 9m 7s\n",
      "87:\tlearn: 0.0202173\ttotal: 1m 57s\tremaining: 9m 9s\n",
      "88:\tlearn: 0.0196624\ttotal: 1m 58s\tremaining: 9m 8s\n",
      "89:\tlearn: 0.0191934\ttotal: 2m\tremaining: 9m 8s\n",
      "90:\tlearn: 0.0187347\ttotal: 2m 2s\tremaining: 9m 8s\n",
      "91:\tlearn: 0.0182048\ttotal: 2m 3s\tremaining: 9m 7s\n",
      "92:\tlearn: 0.0178122\ttotal: 2m 5s\tremaining: 9m 8s\n",
      "93:\tlearn: 0.0173484\ttotal: 2m 6s\tremaining: 9m 8s\n",
      "94:\tlearn: 0.0169513\ttotal: 2m 8s\tremaining: 9m 8s\n",
      "95:\tlearn: 0.0164946\ttotal: 2m 9s\tremaining: 9m 6s\n",
      "96:\tlearn: 0.0161058\ttotal: 2m 11s\tremaining: 9m 7s\n",
      "97:\tlearn: 0.0156832\ttotal: 2m 13s\tremaining: 9m 7s\n",
      "98:\tlearn: 0.0153251\ttotal: 2m 14s\tremaining: 9m 6s\n",
      "99:\tlearn: 0.0149255\ttotal: 2m 16s\tremaining: 9m 6s\n",
      "100:\tlearn: 0.0145783\ttotal: 2m 18s\tremaining: 9m 5s\n",
      "101:\tlearn: 0.0142065\ttotal: 2m 19s\tremaining: 9m 4s\n",
      "102:\tlearn: 0.0138929\ttotal: 2m 21s\tremaining: 9m 4s\n",
      "103:\tlearn: 0.0135454\ttotal: 2m 22s\tremaining: 9m 3s\n",
      "104:\tlearn: 0.0132733\ttotal: 2m 24s\tremaining: 9m 3s\n",
      "105:\tlearn: 0.0129857\ttotal: 2m 26s\tremaining: 9m 2s\n",
      "106:\tlearn: 0.0127039\ttotal: 2m 27s\tremaining: 9m 1s\n",
      "107:\tlearn: 0.0124444\ttotal: 2m 29s\tremaining: 9m 1s\n",
      "108:\tlearn: 0.0121700\ttotal: 2m 30s\tremaining: 9m 1s\n",
      "109:\tlearn: 0.0118409\ttotal: 2m 32s\tremaining: 9m\n",
      "110:\tlearn: 0.0115626\ttotal: 2m 34s\tremaining: 9m\n",
      "111:\tlearn: 0.0113161\ttotal: 2m 35s\tremaining: 8m 59s\n",
      "112:\tlearn: 0.0111080\ttotal: 2m 37s\tremaining: 8m 59s\n",
      "113:\tlearn: 0.0109048\ttotal: 2m 39s\tremaining: 8m 58s\n",
      "114:\tlearn: 0.0106355\ttotal: 2m 40s\tremaining: 8m 58s\n",
      "115:\tlearn: 0.0104817\ttotal: 2m 42s\tremaining: 8m 57s\n",
      "116:\tlearn: 0.0102563\ttotal: 2m 43s\tremaining: 8m 56s\n",
      "117:\tlearn: 0.0100338\ttotal: 2m 45s\tremaining: 8m 55s\n",
      "118:\tlearn: 0.0097625\ttotal: 2m 47s\tremaining: 8m 55s\n",
      "119:\tlearn: 0.0096043\ttotal: 2m 48s\tremaining: 8m 54s\n",
      "120:\tlearn: 0.0093522\ttotal: 2m 50s\tremaining: 8m 53s\n",
      "121:\tlearn: 0.0091427\ttotal: 2m 52s\tremaining: 8m 53s\n",
      "122:\tlearn: 0.0089701\ttotal: 2m 53s\tremaining: 8m 52s\n",
      "123:\tlearn: 0.0087832\ttotal: 2m 55s\tremaining: 8m 51s\n",
      "124:\tlearn: 0.0085583\ttotal: 2m 56s\tremaining: 8m 50s\n",
      "125:\tlearn: 0.0084585\ttotal: 2m 58s\tremaining: 8m 49s\n",
      "126:\tlearn: 0.0082783\ttotal: 3m\tremaining: 8m 49s\n",
      "127:\tlearn: 0.0081147\ttotal: 3m 1s\tremaining: 8m 48s\n",
      "128:\tlearn: 0.0079144\ttotal: 3m 3s\tremaining: 8m 47s\n",
      "129:\tlearn: 0.0077845\ttotal: 3m 4s\tremaining: 8m 46s\n",
      "130:\tlearn: 0.0076175\ttotal: 3m 6s\tremaining: 8m 45s\n",
      "131:\tlearn: 0.0074225\ttotal: 3m 8s\tremaining: 8m 44s\n",
      "132:\tlearn: 0.0072503\ttotal: 3m 9s\tremaining: 8m 43s\n",
      "133:\tlearn: 0.0071109\ttotal: 3m 11s\tremaining: 8m 42s\n",
      "134:\tlearn: 0.0069749\ttotal: 3m 12s\tremaining: 8m 41s\n",
      "135:\tlearn: 0.0068534\ttotal: 3m 14s\tremaining: 8m 40s\n",
      "136:\tlearn: 0.0067604\ttotal: 3m 16s\tremaining: 8m 39s\n",
      "137:\tlearn: 0.0066268\ttotal: 3m 17s\tremaining: 8m 38s\n",
      "138:\tlearn: 0.0064782\ttotal: 3m 19s\tremaining: 8m 38s\n",
      "139:\tlearn: 0.0063784\ttotal: 3m 20s\tremaining: 8m 36s\n",
      "140:\tlearn: 0.0062457\ttotal: 3m 22s\tremaining: 8m 35s\n",
      "141:\tlearn: 0.0061307\ttotal: 3m 24s\tremaining: 8m 34s\n",
      "142:\tlearn: 0.0060094\ttotal: 3m 25s\tremaining: 8m 33s\n",
      "143:\tlearn: 0.0059094\ttotal: 3m 27s\tremaining: 8m 32s\n",
      "144:\tlearn: 0.0058154\ttotal: 3m 28s\tremaining: 8m 31s\n",
      "145:\tlearn: 0.0057373\ttotal: 3m 30s\tremaining: 8m 30s\n",
      "146:\tlearn: 0.0056093\ttotal: 3m 32s\tremaining: 8m 29s\n",
      "147:\tlearn: 0.0054870\ttotal: 3m 33s\tremaining: 8m 28s\n",
      "148:\tlearn: 0.0053679\ttotal: 3m 35s\tremaining: 8m 26s\n",
      "149:\tlearn: 0.0052683\ttotal: 3m 36s\tremaining: 8m 26s\n",
      "150:\tlearn: 0.0051596\ttotal: 3m 38s\tremaining: 8m 24s\n",
      "151:\tlearn: 0.0050512\ttotal: 3m 40s\tremaining: 8m 24s\n",
      "152:\tlearn: 0.0049937\ttotal: 3m 41s\tremaining: 8m 22s\n",
      "153:\tlearn: 0.0048964\ttotal: 3m 43s\tremaining: 8m 21s\n",
      "154:\tlearn: 0.0048215\ttotal: 3m 44s\tremaining: 8m 20s\n",
      "155:\tlearn: 0.0047620\ttotal: 3m 46s\tremaining: 8m 19s\n",
      "156:\tlearn: 0.0046638\ttotal: 3m 48s\tremaining: 8m 18s\n",
      "157:\tlearn: 0.0045794\ttotal: 3m 49s\tremaining: 8m 17s\n",
      "158:\tlearn: 0.0044784\ttotal: 3m 51s\tremaining: 8m 16s\n",
      "159:\tlearn: 0.0044133\ttotal: 3m 52s\tremaining: 8m 14s\n",
      "160:\tlearn: 0.0043261\ttotal: 3m 54s\tremaining: 8m 13s\n",
      "161:\tlearn: 0.0042479\ttotal: 3m 56s\tremaining: 8m 12s\n",
      "162:\tlearn: 0.0041870\ttotal: 3m 57s\tremaining: 8m 11s\n",
      "163:\tlearn: 0.0041068\ttotal: 3m 59s\tremaining: 8m 10s\n",
      "164:\tlearn: 0.0040289\ttotal: 4m 1s\tremaining: 8m 9s\n",
      "165:\tlearn: 0.0039269\ttotal: 4m 2s\tremaining: 8m 8s\n",
      "166:\tlearn: 0.0038508\ttotal: 4m 4s\tremaining: 8m 7s\n",
      "167:\tlearn: 0.0037559\ttotal: 4m 5s\tremaining: 8m 5s\n",
      "168:\tlearn: 0.0037007\ttotal: 4m 7s\tremaining: 8m 4s\n",
      "169:\tlearn: 0.0036340\ttotal: 4m 9s\tremaining: 8m 3s\n",
      "170:\tlearn: 0.0035609\ttotal: 4m 10s\tremaining: 8m 2s\n",
      "171:\tlearn: 0.0035164\ttotal: 4m 12s\tremaining: 8m 1s\n",
      "172:\tlearn: 0.0034387\ttotal: 4m 13s\tremaining: 8m\n",
      "173:\tlearn: 0.0033961\ttotal: 4m 15s\tremaining: 7m 58s\n",
      "174:\tlearn: 0.0033474\ttotal: 4m 17s\tremaining: 7m 57s\n",
      "175:\tlearn: 0.0032853\ttotal: 4m 18s\tremaining: 7m 56s\n",
      "176:\tlearn: 0.0032449\ttotal: 4m 20s\tremaining: 7m 55s\n",
      "177:\tlearn: 0.0032077\ttotal: 4m 22s\tremaining: 7m 53s\n",
      "178:\tlearn: 0.0031655\ttotal: 4m 23s\tremaining: 7m 52s\n",
      "179:\tlearn: 0.0031078\ttotal: 4m 25s\tremaining: 7m 51s\n",
      "180:\tlearn: 0.0030667\ttotal: 4m 26s\tremaining: 7m 50s\n",
      "181:\tlearn: 0.0030127\ttotal: 4m 28s\tremaining: 7m 49s\n",
      "182:\tlearn: 0.0029529\ttotal: 4m 29s\tremaining: 7m 47s\n",
      "183:\tlearn: 0.0028984\ttotal: 4m 31s\tremaining: 7m 46s\n",
      "184:\tlearn: 0.0028347\ttotal: 4m 33s\tremaining: 7m 45s\n",
      "185:\tlearn: 0.0027934\ttotal: 4m 34s\tremaining: 7m 43s\n",
      "186:\tlearn: 0.0027623\ttotal: 4m 36s\tremaining: 7m 42s\n",
      "187:\tlearn: 0.0027203\ttotal: 4m 38s\tremaining: 7m 41s\n",
      "188:\tlearn: 0.0026714\ttotal: 4m 39s\tremaining: 7m 40s\n",
      "189:\tlearn: 0.0026123\ttotal: 4m 41s\tremaining: 7m 38s\n",
      "190:\tlearn: 0.0025752\ttotal: 4m 42s\tremaining: 7m 37s\n",
      "191:\tlearn: 0.0025318\ttotal: 4m 44s\tremaining: 7m 36s\n",
      "192:\tlearn: 0.0024930\ttotal: 4m 45s\tremaining: 7m 34s\n",
      "193:\tlearn: 0.0024608\ttotal: 4m 47s\tremaining: 7m 33s\n",
      "194:\tlearn: 0.0024207\ttotal: 4m 49s\tremaining: 7m 32s\n",
      "195:\tlearn: 0.0023915\ttotal: 4m 50s\tremaining: 7m 30s\n",
      "196:\tlearn: 0.0023586\ttotal: 4m 52s\tremaining: 7m 29s\n",
      "197:\tlearn: 0.0023233\ttotal: 4m 53s\tremaining: 7m 28s\n",
      "198:\tlearn: 0.0022760\ttotal: 4m 55s\tremaining: 7m 27s\n",
      "199:\tlearn: 0.0022362\ttotal: 4m 57s\tremaining: 7m 25s\n",
      "200:\tlearn: 0.0022034\ttotal: 4m 58s\tremaining: 7m 24s\n",
      "201:\tlearn: 0.0021738\ttotal: 5m\tremaining: 7m 23s\n",
      "202:\tlearn: 0.0021424\ttotal: 5m 2s\tremaining: 7m 22s\n",
      "203:\tlearn: 0.0021139\ttotal: 5m 3s\tremaining: 7m 20s\n",
      "204:\tlearn: 0.0020845\ttotal: 5m 5s\tremaining: 7m 19s\n",
      "205:\tlearn: 0.0020583\ttotal: 5m 6s\tremaining: 7m 17s\n",
      "206:\tlearn: 0.0020333\ttotal: 5m 7s\tremaining: 7m 15s\n",
      "207:\tlearn: 0.0020101\ttotal: 5m 8s\tremaining: 7m 13s\n",
      "208:\tlearn: 0.0019934\ttotal: 5m 10s\tremaining: 7m 11s\n",
      "209:\tlearn: 0.0019729\ttotal: 5m 11s\tremaining: 7m 9s\n",
      "210:\tlearn: 0.0019472\ttotal: 5m 12s\tremaining: 7m 8s\n",
      "211:\tlearn: 0.0019255\ttotal: 5m 13s\tremaining: 7m 6s\n",
      "212:\tlearn: 0.0019084\ttotal: 5m 15s\tremaining: 7m 4s\n",
      "213:\tlearn: 0.0018827\ttotal: 5m 16s\tremaining: 7m 2s\n",
      "214:\tlearn: 0.0018649\ttotal: 5m 17s\tremaining: 7m\n",
      "215:\tlearn: 0.0018500\ttotal: 5m 18s\tremaining: 6m 59s\n",
      "216:\tlearn: 0.0018174\ttotal: 5m 19s\tremaining: 6m 57s\n",
      "217:\tlearn: 0.0018030\ttotal: 5m 21s\tremaining: 6m 55s\n",
      "218:\tlearn: 0.0017817\ttotal: 5m 22s\tremaining: 6m 53s\n",
      "219:\tlearn: 0.0017553\ttotal: 5m 23s\tremaining: 6m 51s\n",
      "220:\tlearn: 0.0017238\ttotal: 5m 24s\tremaining: 6m 49s\n",
      "221:\tlearn: 0.0016990\ttotal: 5m 25s\tremaining: 6m 48s\n",
      "222:\tlearn: 0.0016810\ttotal: 5m 27s\tremaining: 6m 46s\n",
      "223:\tlearn: 0.0016625\ttotal: 5m 28s\tremaining: 6m 44s\n",
      "224:\tlearn: 0.0016346\ttotal: 5m 29s\tremaining: 6m 42s\n",
      "225:\tlearn: 0.0016123\ttotal: 5m 30s\tremaining: 6m 41s\n",
      "226:\tlearn: 0.0015927\ttotal: 5m 32s\tremaining: 6m 39s\n",
      "227:\tlearn: 0.0015701\ttotal: 5m 33s\tremaining: 6m 38s\n",
      "228:\tlearn: 0.0015542\ttotal: 5m 35s\tremaining: 6m 37s\n",
      "229:\tlearn: 0.0015379\ttotal: 5m 37s\tremaining: 6m 35s\n",
      "230:\tlearn: 0.0015186\ttotal: 5m 38s\tremaining: 6m 34s\n",
      "231:\tlearn: 0.0014996\ttotal: 5m 40s\tremaining: 6m 33s\n",
      "232:\tlearn: 0.0014946\ttotal: 5m 42s\tremaining: 6m 32s\n",
      "233:\tlearn: 0.0014794\ttotal: 5m 43s\tremaining: 6m 30s\n",
      "234:\tlearn: 0.0014528\ttotal: 5m 45s\tremaining: 6m 29s\n",
      "235:\tlearn: 0.0014389\ttotal: 5m 47s\tremaining: 6m 28s\n",
      "236:\tlearn: 0.0014214\ttotal: 5m 48s\tremaining: 6m 26s\n",
      "237:\tlearn: 0.0014024\ttotal: 5m 50s\tremaining: 6m 25s\n",
      "238:\tlearn: 0.0013800\ttotal: 5m 51s\tremaining: 6m 24s\n",
      "239:\tlearn: 0.0013664\ttotal: 5m 53s\tremaining: 6m 23s\n",
      "240:\tlearn: 0.0013534\ttotal: 5m 55s\tremaining: 6m 21s\n",
      "241:\tlearn: 0.0013352\ttotal: 5m 56s\tremaining: 6m 20s\n",
      "242:\tlearn: 0.0013163\ttotal: 5m 58s\tremaining: 6m 18s\n",
      "243:\tlearn: 0.0012937\ttotal: 6m\tremaining: 6m 17s\n",
      "244:\tlearn: 0.0012820\ttotal: 6m 1s\tremaining: 6m 16s\n",
      "245:\tlearn: 0.0012656\ttotal: 6m 3s\tremaining: 6m 15s\n",
      "246:\tlearn: 0.0012509\ttotal: 6m 4s\tremaining: 6m 13s\n",
      "247:\tlearn: 0.0012332\ttotal: 6m 6s\tremaining: 6m 12s\n",
      "248:\tlearn: 0.0012168\ttotal: 6m 8s\tremaining: 6m 11s\n",
      "249:\tlearn: 0.0011973\ttotal: 6m 9s\tremaining: 6m 9s\n",
      "250:\tlearn: 0.0011808\ttotal: 6m 11s\tremaining: 6m 8s\n",
      "251:\tlearn: 0.0011674\ttotal: 6m 13s\tremaining: 6m 7s\n",
      "252:\tlearn: 0.0011561\ttotal: 6m 14s\tremaining: 6m 5s\n",
      "253:\tlearn: 0.0011387\ttotal: 6m 16s\tremaining: 6m 4s\n",
      "254:\tlearn: 0.0011241\ttotal: 6m 18s\tremaining: 6m 3s\n",
      "255:\tlearn: 0.0011076\ttotal: 6m 19s\tremaining: 6m 1s\n",
      "256:\tlearn: 0.0010967\ttotal: 6m 21s\tremaining: 6m\n",
      "257:\tlearn: 0.0010836\ttotal: 6m 22s\tremaining: 5m 59s\n",
      "258:\tlearn: 0.0010715\ttotal: 6m 24s\tremaining: 5m 57s\n",
      "259:\tlearn: 0.0010590\ttotal: 6m 26s\tremaining: 5m 56s\n",
      "260:\tlearn: 0.0010493\ttotal: 6m 27s\tremaining: 5m 55s\n",
      "261:\tlearn: 0.0010392\ttotal: 6m 29s\tremaining: 5m 53s\n",
      "262:\tlearn: 0.0010267\ttotal: 6m 31s\tremaining: 5m 52s\n",
      "263:\tlearn: 0.0010176\ttotal: 6m 32s\tremaining: 5m 50s\n",
      "264:\tlearn: 0.0010095\ttotal: 6m 34s\tremaining: 5m 49s\n",
      "265:\tlearn: 0.0009994\ttotal: 6m 35s\tremaining: 5m 48s\n",
      "266:\tlearn: 0.0009870\ttotal: 6m 37s\tremaining: 5m 46s\n",
      "267:\tlearn: 0.0009726\ttotal: 6m 39s\tremaining: 5m 45s\n",
      "268:\tlearn: 0.0009597\ttotal: 6m 40s\tremaining: 5m 44s\n",
      "269:\tlearn: 0.0009505\ttotal: 6m 42s\tremaining: 5m 42s\n",
      "270:\tlearn: 0.0009399\ttotal: 6m 43s\tremaining: 5m 41s\n",
      "271:\tlearn: 0.0009298\ttotal: 6m 45s\tremaining: 5m 40s\n",
      "272:\tlearn: 0.0009177\ttotal: 6m 47s\tremaining: 5m 38s\n",
      "273:\tlearn: 0.0009077\ttotal: 6m 48s\tremaining: 5m 37s\n",
      "274:\tlearn: 0.0008997\ttotal: 6m 50s\tremaining: 5m 35s\n",
      "275:\tlearn: 0.0008891\ttotal: 6m 52s\tremaining: 5m 34s\n",
      "276:\tlearn: 0.0008763\ttotal: 6m 53s\tremaining: 5m 32s\n",
      "277:\tlearn: 0.0008700\ttotal: 6m 55s\tremaining: 5m 31s\n",
      "278:\tlearn: 0.0008607\ttotal: 6m 56s\tremaining: 5m 30s\n",
      "279:\tlearn: 0.0008509\ttotal: 6m 58s\tremaining: 5m 28s\n",
      "280:\tlearn: 0.0008447\ttotal: 7m\tremaining: 5m 27s\n",
      "281:\tlearn: 0.0008359\ttotal: 7m 1s\tremaining: 5m 26s\n",
      "282:\tlearn: 0.0008282\ttotal: 7m 3s\tremaining: 5m 24s\n",
      "283:\tlearn: 0.0008204\ttotal: 7m 5s\tremaining: 5m 23s\n",
      "284:\tlearn: 0.0008122\ttotal: 7m 6s\tremaining: 5m 21s\n",
      "285:\tlearn: 0.0008008\ttotal: 7m 8s\tremaining: 5m 20s\n",
      "286:\tlearn: 0.0007941\ttotal: 7m 9s\tremaining: 5m 19s\n",
      "287:\tlearn: 0.0007872\ttotal: 7m 11s\tremaining: 5m 17s\n",
      "288:\tlearn: 0.0007805\ttotal: 7m 13s\tremaining: 5m 16s\n",
      "289:\tlearn: 0.0007702\ttotal: 7m 14s\tremaining: 5m 14s\n",
      "290:\tlearn: 0.0007622\ttotal: 7m 16s\tremaining: 5m 13s\n",
      "291:\tlearn: 0.0007538\ttotal: 7m 18s\tremaining: 5m 12s\n",
      "292:\tlearn: 0.0007498\ttotal: 7m 19s\tremaining: 5m 10s\n",
      "293:\tlearn: 0.0007447\ttotal: 7m 21s\tremaining: 5m 9s\n",
      "294:\tlearn: 0.0007388\ttotal: 7m 23s\tremaining: 5m 7s\n",
      "295:\tlearn: 0.0007298\ttotal: 7m 24s\tremaining: 5m 6s\n",
      "296:\tlearn: 0.0007199\ttotal: 7m 26s\tremaining: 5m 5s\n",
      "297:\tlearn: 0.0007113\ttotal: 7m 27s\tremaining: 5m 3s\n",
      "298:\tlearn: 0.0007033\ttotal: 7m 29s\tremaining: 5m 2s\n",
      "299:\tlearn: 0.0006988\ttotal: 7m 31s\tremaining: 5m\n",
      "300:\tlearn: 0.0006883\ttotal: 7m 32s\tremaining: 4m 59s\n",
      "301:\tlearn: 0.0006826\ttotal: 7m 34s\tremaining: 4m 57s\n",
      "302:\tlearn: 0.0006772\ttotal: 7m 36s\tremaining: 4m 56s\n",
      "303:\tlearn: 0.0006725\ttotal: 7m 37s\tremaining: 4m 55s\n",
      "304:\tlearn: 0.0006653\ttotal: 7m 39s\tremaining: 4m 53s\n",
      "305:\tlearn: 0.0006577\ttotal: 7m 41s\tremaining: 4m 52s\n",
      "306:\tlearn: 0.0006497\ttotal: 7m 42s\tremaining: 4m 50s\n",
      "307:\tlearn: 0.0006439\ttotal: 7m 44s\tremaining: 4m 49s\n",
      "308:\tlearn: 0.0006370\ttotal: 7m 45s\tremaining: 4m 47s\n",
      "309:\tlearn: 0.0006312\ttotal: 7m 47s\tremaining: 4m 46s\n",
      "310:\tlearn: 0.0006273\ttotal: 7m 49s\tremaining: 4m 45s\n",
      "311:\tlearn: 0.0006236\ttotal: 7m 50s\tremaining: 4m 43s\n",
      "312:\tlearn: 0.0006195\ttotal: 7m 52s\tremaining: 4m 42s\n",
      "313:\tlearn: 0.0006114\ttotal: 7m 54s\tremaining: 4m 40s\n",
      "314:\tlearn: 0.0006063\ttotal: 7m 55s\tremaining: 4m 39s\n",
      "315:\tlearn: 0.0005977\ttotal: 7m 57s\tremaining: 4m 38s\n",
      "316:\tlearn: 0.0005938\ttotal: 7m 59s\tremaining: 4m 36s\n",
      "317:\tlearn: 0.0005884\ttotal: 8m\tremaining: 4m 35s\n",
      "318:\tlearn: 0.0005857\ttotal: 8m 2s\tremaining: 4m 33s\n",
      "319:\tlearn: 0.0005809\ttotal: 8m 4s\tremaining: 4m 32s\n",
      "320:\tlearn: 0.0005746\ttotal: 8m 5s\tremaining: 4m 30s\n",
      "321:\tlearn: 0.0005687\ttotal: 8m 7s\tremaining: 4m 29s\n",
      "322:\tlearn: 0.0005627\ttotal: 8m 8s\tremaining: 4m 27s\n",
      "323:\tlearn: 0.0005578\ttotal: 8m 10s\tremaining: 4m 26s\n",
      "324:\tlearn: 0.0005528\ttotal: 8m 12s\tremaining: 4m 24s\n",
      "325:\tlearn: 0.0005468\ttotal: 8m 13s\tremaining: 4m 23s\n",
      "326:\tlearn: 0.0005434\ttotal: 8m 15s\tremaining: 4m 22s\n",
      "327:\tlearn: 0.0005405\ttotal: 8m 16s\tremaining: 4m 20s\n",
      "328:\tlearn: 0.0005370\ttotal: 8m 18s\tremaining: 4m 19s\n",
      "329:\tlearn: 0.0005326\ttotal: 8m 20s\tremaining: 4m 17s\n",
      "330:\tlearn: 0.0005276\ttotal: 8m 21s\tremaining: 4m 16s\n",
      "331:\tlearn: 0.0005235\ttotal: 8m 23s\tremaining: 4m 14s\n",
      "332:\tlearn: 0.0005186\ttotal: 8m 25s\tremaining: 4m 13s\n",
      "333:\tlearn: 0.0005158\ttotal: 8m 26s\tremaining: 4m 11s\n",
      "334:\tlearn: 0.0005131\ttotal: 8m 28s\tremaining: 4m 10s\n",
      "335:\tlearn: 0.0005092\ttotal: 8m 29s\tremaining: 4m 8s\n",
      "336:\tlearn: 0.0005038\ttotal: 8m 31s\tremaining: 4m 7s\n",
      "337:\tlearn: 0.0004994\ttotal: 8m 33s\tremaining: 4m 5s\n",
      "338:\tlearn: 0.0004962\ttotal: 8m 34s\tremaining: 4m 4s\n",
      "339:\tlearn: 0.0004925\ttotal: 8m 36s\tremaining: 4m 2s\n",
      "340:\tlearn: 0.0004905\ttotal: 8m 38s\tremaining: 4m 1s\n",
      "341:\tlearn: 0.0004862\ttotal: 8m 39s\tremaining: 4m\n",
      "342:\tlearn: 0.0004837\ttotal: 8m 41s\tremaining: 3m 58s\n",
      "343:\tlearn: 0.0004803\ttotal: 8m 42s\tremaining: 3m 57s\n",
      "344:\tlearn: 0.0004751\ttotal: 8m 44s\tremaining: 3m 55s\n",
      "345:\tlearn: 0.0004701\ttotal: 8m 46s\tremaining: 3m 54s\n",
      "346:\tlearn: 0.0004655\ttotal: 8m 47s\tremaining: 3m 52s\n",
      "347:\tlearn: 0.0004613\ttotal: 8m 49s\tremaining: 3m 51s\n",
      "348:\tlearn: 0.0004589\ttotal: 8m 50s\tremaining: 3m 49s\n",
      "349:\tlearn: 0.0004559\ttotal: 8m 52s\tremaining: 3m 48s\n",
      "350:\tlearn: 0.0004511\ttotal: 8m 54s\tremaining: 3m 46s\n",
      "351:\tlearn: 0.0004493\ttotal: 8m 55s\tremaining: 3m 45s\n",
      "352:\tlearn: 0.0004441\ttotal: 8m 57s\tremaining: 3m 43s\n",
      "353:\tlearn: 0.0004400\ttotal: 8m 58s\tremaining: 3m 42s\n",
      "354:\tlearn: 0.0004376\ttotal: 9m\tremaining: 3m 40s\n",
      "355:\tlearn: 0.0004338\ttotal: 9m 1s\tremaining: 3m 39s\n",
      "356:\tlearn: 0.0004306\ttotal: 9m 3s\tremaining: 3m 37s\n",
      "357:\tlearn: 0.0004253\ttotal: 9m 5s\tremaining: 3m 36s\n",
      "358:\tlearn: 0.0004231\ttotal: 9m 6s\tremaining: 3m 34s\n",
      "359:\tlearn: 0.0004193\ttotal: 9m 8s\tremaining: 3m 33s\n",
      "360:\tlearn: 0.0004165\ttotal: 9m 10s\tremaining: 3m 31s\n",
      "361:\tlearn: 0.0004132\ttotal: 9m 11s\tremaining: 3m 30s\n",
      "362:\tlearn: 0.0004099\ttotal: 9m 13s\tremaining: 3m 28s\n",
      "363:\tlearn: 0.0004067\ttotal: 9m 15s\tremaining: 3m 27s\n",
      "364:\tlearn: 0.0004031\ttotal: 9m 16s\tremaining: 3m 25s\n",
      "365:\tlearn: 0.0003995\ttotal: 9m 18s\tremaining: 3m 24s\n",
      "366:\tlearn: 0.0003962\ttotal: 9m 20s\tremaining: 3m 22s\n",
      "367:\tlearn: 0.0003940\ttotal: 9m 21s\tremaining: 3m 21s\n",
      "368:\tlearn: 0.0003906\ttotal: 9m 23s\tremaining: 3m 19s\n",
      "369:\tlearn: 0.0003869\ttotal: 9m 24s\tremaining: 3m 18s\n",
      "370:\tlearn: 0.0003831\ttotal: 9m 26s\tremaining: 3m 16s\n",
      "371:\tlearn: 0.0003794\ttotal: 9m 28s\tremaining: 3m 15s\n",
      "372:\tlearn: 0.0003778\ttotal: 9m 29s\tremaining: 3m 14s\n",
      "373:\tlearn: 0.0003760\ttotal: 9m 31s\tremaining: 3m 12s\n",
      "374:\tlearn: 0.0003724\ttotal: 9m 33s\tremaining: 3m 11s\n",
      "375:\tlearn: 0.0003705\ttotal: 9m 34s\tremaining: 3m 9s\n",
      "376:\tlearn: 0.0003677\ttotal: 9m 36s\tremaining: 3m 8s\n",
      "377:\tlearn: 0.0003641\ttotal: 9m 37s\tremaining: 3m 6s\n",
      "378:\tlearn: 0.0003623\ttotal: 9m 39s\tremaining: 3m 5s\n",
      "379:\tlearn: 0.0003609\ttotal: 9m 41s\tremaining: 3m 3s\n",
      "380:\tlearn: 0.0003593\ttotal: 9m 42s\tremaining: 3m 2s\n",
      "381:\tlearn: 0.0003554\ttotal: 9m 44s\tremaining: 3m\n",
      "382:\tlearn: 0.0003542\ttotal: 9m 46s\tremaining: 2m 59s\n",
      "383:\tlearn: 0.0003510\ttotal: 9m 47s\tremaining: 2m 57s\n",
      "384:\tlearn: 0.0003477\ttotal: 9m 49s\tremaining: 2m 55s\n",
      "385:\tlearn: 0.0003451\ttotal: 9m 50s\tremaining: 2m 54s\n",
      "386:\tlearn: 0.0003416\ttotal: 9m 52s\tremaining: 2m 53s\n",
      "387:\tlearn: 0.0003403\ttotal: 9m 54s\tremaining: 2m 51s\n",
      "388:\tlearn: 0.0003383\ttotal: 9m 55s\tremaining: 2m 49s\n",
      "389:\tlearn: 0.0003355\ttotal: 9m 57s\tremaining: 2m 48s\n",
      "390:\tlearn: 0.0003337\ttotal: 9m 58s\tremaining: 2m 46s\n",
      "391:\tlearn: 0.0003327\ttotal: 10m\tremaining: 2m 45s\n",
      "392:\tlearn: 0.0003312\ttotal: 10m 1s\tremaining: 2m 43s\n",
      "393:\tlearn: 0.0003293\ttotal: 10m 3s\tremaining: 2m 42s\n",
      "394:\tlearn: 0.0003279\ttotal: 10m 5s\tremaining: 2m 40s\n",
      "395:\tlearn: 0.0003267\ttotal: 10m 6s\tremaining: 2m 39s\n",
      "396:\tlearn: 0.0003238\ttotal: 10m 8s\tremaining: 2m 37s\n",
      "397:\tlearn: 0.0003216\ttotal: 10m 10s\tremaining: 2m 36s\n",
      "398:\tlearn: 0.0003189\ttotal: 10m 11s\tremaining: 2m 34s\n",
      "399:\tlearn: 0.0003168\ttotal: 10m 13s\tremaining: 2m 33s\n",
      "400:\tlearn: 0.0003144\ttotal: 10m 14s\tremaining: 2m 31s\n",
      "401:\tlearn: 0.0003131\ttotal: 10m 16s\tremaining: 2m 30s\n",
      "402:\tlearn: 0.0003117\ttotal: 10m 18s\tremaining: 2m 28s\n",
      "403:\tlearn: 0.0003100\ttotal: 10m 19s\tremaining: 2m 27s\n",
      "404:\tlearn: 0.0003085\ttotal: 10m 21s\tremaining: 2m 25s\n",
      "405:\tlearn: 0.0003063\ttotal: 10m 23s\tremaining: 2m 24s\n",
      "406:\tlearn: 0.0003040\ttotal: 10m 24s\tremaining: 2m 22s\n",
      "407:\tlearn: 0.0003013\ttotal: 10m 26s\tremaining: 2m 21s\n",
      "408:\tlearn: 0.0002995\ttotal: 10m 27s\tremaining: 2m 19s\n",
      "409:\tlearn: 0.0002978\ttotal: 10m 29s\tremaining: 2m 18s\n",
      "410:\tlearn: 0.0002969\ttotal: 10m 31s\tremaining: 2m 16s\n",
      "411:\tlearn: 0.0002953\ttotal: 10m 32s\tremaining: 2m 15s\n",
      "412:\tlearn: 0.0002940\ttotal: 10m 34s\tremaining: 2m 13s\n",
      "413:\tlearn: 0.0002927\ttotal: 10m 35s\tremaining: 2m 12s\n",
      "414:\tlearn: 0.0002912\ttotal: 10m 37s\tremaining: 2m 10s\n",
      "415:\tlearn: 0.0002886\ttotal: 10m 38s\tremaining: 2m 9s\n",
      "416:\tlearn: 0.0002873\ttotal: 10m 40s\tremaining: 2m 7s\n",
      "417:\tlearn: 0.0002866\ttotal: 10m 42s\tremaining: 2m 6s\n",
      "418:\tlearn: 0.0002857\ttotal: 10m 44s\tremaining: 2m 4s\n",
      "419:\tlearn: 0.0002839\ttotal: 10m 45s\tremaining: 2m 2s\n",
      "420:\tlearn: 0.0002821\ttotal: 10m 47s\tremaining: 2m 1s\n",
      "421:\tlearn: 0.0002806\ttotal: 10m 48s\tremaining: 1m 59s\n",
      "422:\tlearn: 0.0002791\ttotal: 10m 50s\tremaining: 1m 58s\n",
      "423:\tlearn: 0.0002780\ttotal: 10m 51s\tremaining: 1m 56s\n",
      "424:\tlearn: 0.0002772\ttotal: 10m 53s\tremaining: 1m 55s\n",
      "425:\tlearn: 0.0002762\ttotal: 10m 55s\tremaining: 1m 53s\n",
      "426:\tlearn: 0.0002758\ttotal: 10m 57s\tremaining: 1m 52s\n",
      "427:\tlearn: 0.0002739\ttotal: 10m 58s\tremaining: 1m 50s\n",
      "428:\tlearn: 0.0002715\ttotal: 11m\tremaining: 1m 49s\n",
      "429:\tlearn: 0.0002693\ttotal: 11m 2s\tremaining: 1m 47s\n",
      "430:\tlearn: 0.0002677\ttotal: 11m 3s\tremaining: 1m 46s\n",
      "431:\tlearn: 0.0002666\ttotal: 11m 5s\tremaining: 1m 44s\n",
      "432:\tlearn: 0.0002645\ttotal: 11m 6s\tremaining: 1m 43s\n",
      "433:\tlearn: 0.0002632\ttotal: 11m 8s\tremaining: 1m 41s\n",
      "434:\tlearn: 0.0002618\ttotal: 11m 10s\tremaining: 1m 40s\n",
      "435:\tlearn: 0.0002603\ttotal: 11m 11s\tremaining: 1m 38s\n",
      "436:\tlearn: 0.0002586\ttotal: 11m 13s\tremaining: 1m 37s\n",
      "437:\tlearn: 0.0002569\ttotal: 11m 14s\tremaining: 1m 35s\n",
      "438:\tlearn: 0.0002557\ttotal: 11m 16s\tremaining: 1m 33s\n",
      "439:\tlearn: 0.0002545\ttotal: 11m 18s\tremaining: 1m 32s\n",
      "440:\tlearn: 0.0002527\ttotal: 11m 19s\tremaining: 1m 30s\n",
      "441:\tlearn: 0.0002513\ttotal: 11m 21s\tremaining: 1m 29s\n",
      "442:\tlearn: 0.0002502\ttotal: 11m 23s\tremaining: 1m 27s\n",
      "443:\tlearn: 0.0002486\ttotal: 11m 24s\tremaining: 1m 26s\n",
      "444:\tlearn: 0.0002478\ttotal: 11m 26s\tremaining: 1m 24s\n",
      "445:\tlearn: 0.0002467\ttotal: 11m 28s\tremaining: 1m 23s\n",
      "446:\tlearn: 0.0002457\ttotal: 11m 29s\tremaining: 1m 21s\n",
      "447:\tlearn: 0.0002442\ttotal: 11m 31s\tremaining: 1m 20s\n",
      "448:\tlearn: 0.0002427\ttotal: 11m 32s\tremaining: 1m 18s\n",
      "449:\tlearn: 0.0002423\ttotal: 11m 34s\tremaining: 1m 17s\n",
      "450:\tlearn: 0.0002413\ttotal: 11m 36s\tremaining: 1m 15s\n",
      "451:\tlearn: 0.0002399\ttotal: 11m 37s\tremaining: 1m 14s\n",
      "452:\tlearn: 0.0002389\ttotal: 11m 39s\tremaining: 1m 12s\n",
      "453:\tlearn: 0.0002376\ttotal: 11m 40s\tremaining: 1m 11s\n",
      "454:\tlearn: 0.0002364\ttotal: 11m 42s\tremaining: 1m 9s\n",
      "455:\tlearn: 0.0002351\ttotal: 11m 44s\tremaining: 1m 7s\n",
      "456:\tlearn: 0.0002340\ttotal: 11m 46s\tremaining: 1m 6s\n",
      "457:\tlearn: 0.0002327\ttotal: 11m 47s\tremaining: 1m 4s\n",
      "458:\tlearn: 0.0002304\ttotal: 11m 49s\tremaining: 1m 3s\n",
      "459:\tlearn: 0.0002283\ttotal: 11m 51s\tremaining: 1m 1s\n",
      "460:\tlearn: 0.0002262\ttotal: 11m 52s\tremaining: 1m\n",
      "461:\tlearn: 0.0002243\ttotal: 11m 54s\tremaining: 58.7s\n",
      "462:\tlearn: 0.0002222\ttotal: 11m 56s\tremaining: 57.2s\n",
      "463:\tlearn: 0.0002213\ttotal: 11m 57s\tremaining: 55.7s\n",
      "464:\tlearn: 0.0002204\ttotal: 11m 59s\tremaining: 54.1s\n",
      "465:\tlearn: 0.0002199\ttotal: 12m\tremaining: 52.6s\n",
      "466:\tlearn: 0.0002191\ttotal: 12m 2s\tremaining: 51.1s\n",
      "467:\tlearn: 0.0002185\ttotal: 12m 4s\tremaining: 49.5s\n",
      "468:\tlearn: 0.0002176\ttotal: 12m 5s\tremaining: 48s\n",
      "469:\tlearn: 0.0002165\ttotal: 12m 7s\tremaining: 46.4s\n",
      "470:\tlearn: 0.0002153\ttotal: 12m 8s\tremaining: 44.9s\n",
      "471:\tlearn: 0.0002148\ttotal: 12m 10s\tremaining: 43.3s\n",
      "472:\tlearn: 0.0002124\ttotal: 12m 12s\tremaining: 41.8s\n",
      "473:\tlearn: 0.0002119\ttotal: 12m 14s\tremaining: 40.3s\n",
      "474:\tlearn: 0.0002106\ttotal: 12m 15s\tremaining: 38.7s\n",
      "475:\tlearn: 0.0002095\ttotal: 12m 17s\tremaining: 37.2s\n",
      "476:\tlearn: 0.0002079\ttotal: 12m 18s\tremaining: 35.6s\n",
      "477:\tlearn: 0.0002064\ttotal: 12m 20s\tremaining: 34.1s\n",
      "478:\tlearn: 0.0002058\ttotal: 12m 21s\tremaining: 32.5s\n",
      "479:\tlearn: 0.0002050\ttotal: 12m 23s\tremaining: 31s\n",
      "480:\tlearn: 0.0002039\ttotal: 12m 25s\tremaining: 29.4s\n",
      "481:\tlearn: 0.0002032\ttotal: 12m 27s\tremaining: 27.9s\n",
      "482:\tlearn: 0.0002021\ttotal: 12m 28s\tremaining: 26.4s\n",
      "483:\tlearn: 0.0002002\ttotal: 12m 30s\tremaining: 24.8s\n",
      "484:\tlearn: 0.0001999\ttotal: 12m 32s\tremaining: 23.3s\n",
      "485:\tlearn: 0.0001992\ttotal: 12m 33s\tremaining: 21.7s\n",
      "486:\tlearn: 0.0001982\ttotal: 12m 35s\tremaining: 20.2s\n",
      "487:\tlearn: 0.0001968\ttotal: 12m 37s\tremaining: 18.6s\n",
      "488:\tlearn: 0.0001959\ttotal: 12m 38s\tremaining: 17.1s\n",
      "489:\tlearn: 0.0001951\ttotal: 12m 40s\tremaining: 15.5s\n",
      "490:\tlearn: 0.0001939\ttotal: 12m 41s\tremaining: 14s\n",
      "491:\tlearn: 0.0001934\ttotal: 12m 43s\tremaining: 12.4s\n",
      "492:\tlearn: 0.0001926\ttotal: 12m 44s\tremaining: 10.9s\n",
      "493:\tlearn: 0.0001917\ttotal: 12m 46s\tremaining: 9.31s\n",
      "494:\tlearn: 0.0001906\ttotal: 12m 48s\tremaining: 7.76s\n",
      "495:\tlearn: 0.0001900\ttotal: 12m 49s\tremaining: 6.21s\n",
      "496:\tlearn: 0.0001888\ttotal: 12m 51s\tremaining: 4.66s\n",
      "497:\tlearn: 0.0001883\ttotal: 12m 53s\tremaining: 3.1s\n",
      "498:\tlearn: 0.0001871\ttotal: 12m 54s\tremaining: 1.55s\n",
      "499:\tlearn: 0.0001856\ttotal: 12m 56s\tremaining: 0us\n",
      "Accuracy: 1.0\n",
      "\n",
      "Confusion Matrix:\n",
      " [[66792     0]\n",
      " [    0 66936]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     66792\n",
      "           1       1.00      1.00      1.00     66936\n",
      "\n",
      "    accuracy                           1.00    133728\n",
      "   macro avg       1.00      1.00      1.00    133728\n",
      "weighted avg       1.00      1.00      1.00    133728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Fraud'], axis=1)\n",
    "y = df['Fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a CatBoost Classifier\n",
    "model = CatBoostClassifier(iterations=500, depth=10, learning_rate=0.05, loss_function='MultiClass', random_seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, cat_features=None)  # You can specify categorical features if needed\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/combined/combined_smote_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"Fraud_x\",\"FraudType_x\",\"Rndrng_NPI\",],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6526009\ttotal: 2.11s\tremaining: 17m 35s\n",
      "1:\tlearn: 0.6155817\ttotal: 4.27s\tremaining: 17m 42s\n",
      "2:\tlearn: 0.5821306\ttotal: 6.05s\tremaining: 16m 42s\n",
      "3:\tlearn: 0.5510170\ttotal: 8.04s\tremaining: 16m 37s\n",
      "4:\tlearn: 0.5227902\ttotal: 10.2s\tremaining: 16m 46s\n",
      "5:\tlearn: 0.4952990\ttotal: 11.9s\tremaining: 16m 23s\n",
      "6:\tlearn: 0.4702732\ttotal: 13.9s\tremaining: 16m 19s\n",
      "7:\tlearn: 0.4461858\ttotal: 16.1s\tremaining: 16m 28s\n",
      "8:\tlearn: 0.4248362\ttotal: 17.8s\tremaining: 16m 11s\n",
      "9:\tlearn: 0.4044452\ttotal: 19.8s\tremaining: 16m 10s\n",
      "10:\tlearn: 0.3847434\ttotal: 21.8s\tremaining: 16m 8s\n",
      "11:\tlearn: 0.3680426\ttotal: 23.6s\tremaining: 15m 59s\n",
      "12:\tlearn: 0.3514681\ttotal: 25.8s\tremaining: 16m 4s\n",
      "13:\tlearn: 0.3353391\ttotal: 27.7s\tremaining: 16m 1s\n",
      "14:\tlearn: 0.3211058\ttotal: 29.7s\tremaining: 15m 59s\n",
      "15:\tlearn: 0.3074795\ttotal: 31.5s\tremaining: 15m 53s\n",
      "16:\tlearn: 0.2940480\ttotal: 33.3s\tremaining: 15m 47s\n",
      "17:\tlearn: 0.2815128\ttotal: 35.3s\tremaining: 15m 45s\n",
      "18:\tlearn: 0.2698233\ttotal: 37.1s\tremaining: 15m 38s\n",
      "19:\tlearn: 0.2582042\ttotal: 39s\tremaining: 15m 35s\n",
      "20:\tlearn: 0.2482628\ttotal: 41s\tremaining: 15m 34s\n",
      "21:\tlearn: 0.2383857\ttotal: 42.9s\tremaining: 15m 31s\n",
      "22:\tlearn: 0.2282029\ttotal: 44.9s\tremaining: 15m 31s\n",
      "23:\tlearn: 0.2184468\ttotal: 46.7s\tremaining: 15m 26s\n",
      "24:\tlearn: 0.2095085\ttotal: 48.7s\tremaining: 15m 24s\n",
      "25:\tlearn: 0.2005321\ttotal: 50.6s\tremaining: 15m 21s\n",
      "26:\tlearn: 0.1924302\ttotal: 52.3s\tremaining: 15m 15s\n",
      "27:\tlearn: 0.1854146\ttotal: 54.1s\tremaining: 15m 11s\n",
      "28:\tlearn: 0.1781785\ttotal: 55.8s\tremaining: 15m 7s\n",
      "29:\tlearn: 0.1710875\ttotal: 57.8s\tremaining: 15m 5s\n",
      "30:\tlearn: 0.1654149\ttotal: 59.8s\tremaining: 15m 3s\n",
      "31:\tlearn: 0.1599804\ttotal: 1m 1s\tremaining: 15m 2s\n",
      "32:\tlearn: 0.1538165\ttotal: 1m 3s\tremaining: 14m 57s\n",
      "33:\tlearn: 0.1486782\ttotal: 1m 5s\tremaining: 14m 55s\n",
      "34:\tlearn: 0.1432111\ttotal: 1m 7s\tremaining: 14m 52s\n",
      "35:\tlearn: 0.1379613\ttotal: 1m 8s\tremaining: 14m 49s\n",
      "36:\tlearn: 0.1328853\ttotal: 1m 10s\tremaining: 14m 45s\n",
      "37:\tlearn: 0.1288539\ttotal: 1m 12s\tremaining: 14m 45s\n",
      "38:\tlearn: 0.1245031\ttotal: 1m 14s\tremaining: 14m 40s\n",
      "39:\tlearn: 0.1202437\ttotal: 1m 16s\tremaining: 14m 39s\n",
      "40:\tlearn: 0.1158161\ttotal: 1m 18s\tremaining: 14m 35s\n",
      "41:\tlearn: 0.1118541\ttotal: 1m 20s\tremaining: 14m 32s\n",
      "42:\tlearn: 0.1081798\ttotal: 1m 21s\tremaining: 14m 29s\n",
      "43:\tlearn: 0.1041492\ttotal: 1m 23s\tremaining: 14m 28s\n",
      "44:\tlearn: 0.1006028\ttotal: 1m 25s\tremaining: 14m 27s\n",
      "45:\tlearn: 0.0978485\ttotal: 1m 27s\tremaining: 14m 24s\n",
      "46:\tlearn: 0.0946100\ttotal: 1m 29s\tremaining: 14m 22s\n",
      "47:\tlearn: 0.0912774\ttotal: 1m 31s\tremaining: 14m 20s\n",
      "48:\tlearn: 0.0879900\ttotal: 1m 33s\tremaining: 14m 18s\n",
      "49:\tlearn: 0.0851646\ttotal: 1m 35s\tremaining: 14m 17s\n",
      "50:\tlearn: 0.0821980\ttotal: 1m 36s\tremaining: 14m 10s\n",
      "51:\tlearn: 0.0796320\ttotal: 1m 37s\tremaining: 14m 2s\n",
      "52:\tlearn: 0.0769983\ttotal: 1m 39s\tremaining: 13m 55s\n",
      "53:\tlearn: 0.0742474\ttotal: 1m 40s\tremaining: 13m 48s\n",
      "54:\tlearn: 0.0717108\ttotal: 1m 41s\tremaining: 13m 41s\n",
      "55:\tlearn: 0.0690620\ttotal: 1m 42s\tremaining: 13m 34s\n",
      "56:\tlearn: 0.0672533\ttotal: 1m 44s\tremaining: 13m 28s\n",
      "57:\tlearn: 0.0650565\ttotal: 1m 45s\tremaining: 13m 21s\n",
      "58:\tlearn: 0.0630001\ttotal: 1m 46s\tremaining: 13m 15s\n",
      "59:\tlearn: 0.0609904\ttotal: 1m 47s\tremaining: 13m 9s\n",
      "60:\tlearn: 0.0588379\ttotal: 1m 48s\tremaining: 13m 2s\n",
      "61:\tlearn: 0.0574328\ttotal: 1m 50s\tremaining: 12m 57s\n",
      "62:\tlearn: 0.0555262\ttotal: 1m 51s\tremaining: 12m 52s\n",
      "63:\tlearn: 0.0538701\ttotal: 1m 52s\tremaining: 12m 47s\n",
      "64:\tlearn: 0.0524117\ttotal: 1m 53s\tremaining: 12m 42s\n",
      "65:\tlearn: 0.0506338\ttotal: 1m 55s\tremaining: 12m 37s\n",
      "66:\tlearn: 0.0489445\ttotal: 1m 56s\tremaining: 12m 32s\n",
      "67:\tlearn: 0.0475612\ttotal: 1m 57s\tremaining: 12m 26s\n",
      "68:\tlearn: 0.0460863\ttotal: 1m 58s\tremaining: 12m 22s\n",
      "69:\tlearn: 0.0447933\ttotal: 2m\tremaining: 12m 17s\n",
      "70:\tlearn: 0.0435050\ttotal: 2m 1s\tremaining: 12m 11s\n",
      "71:\tlearn: 0.0421076\ttotal: 2m 2s\tremaining: 12m 7s\n",
      "72:\tlearn: 0.0406773\ttotal: 2m 3s\tremaining: 12m 2s\n",
      "73:\tlearn: 0.0395845\ttotal: 2m 4s\tremaining: 11m 58s\n",
      "74:\tlearn: 0.0384558\ttotal: 2m 5s\tremaining: 11m 53s\n",
      "75:\tlearn: 0.0372888\ttotal: 2m 7s\tremaining: 11m 49s\n",
      "76:\tlearn: 0.0361353\ttotal: 2m 8s\tremaining: 11m 46s\n",
      "77:\tlearn: 0.0352279\ttotal: 2m 9s\tremaining: 11m 42s\n",
      "78:\tlearn: 0.0342710\ttotal: 2m 11s\tremaining: 11m 38s\n",
      "79:\tlearn: 0.0333267\ttotal: 2m 12s\tremaining: 11m 34s\n",
      "80:\tlearn: 0.0322994\ttotal: 2m 13s\tremaining: 11m 30s\n",
      "81:\tlearn: 0.0315113\ttotal: 2m 14s\tremaining: 11m 26s\n",
      "82:\tlearn: 0.0305152\ttotal: 2m 15s\tremaining: 11m 22s\n",
      "83:\tlearn: 0.0295995\ttotal: 2m 17s\tremaining: 11m 20s\n",
      "84:\tlearn: 0.0288144\ttotal: 2m 18s\tremaining: 11m 16s\n",
      "85:\tlearn: 0.0279682\ttotal: 2m 19s\tremaining: 11m 12s\n",
      "86:\tlearn: 0.0271538\ttotal: 2m 21s\tremaining: 11m 9s\n",
      "87:\tlearn: 0.0262883\ttotal: 2m 22s\tremaining: 11m 5s\n",
      "88:\tlearn: 0.0256237\ttotal: 2m 23s\tremaining: 11m 2s\n",
      "89:\tlearn: 0.0249383\ttotal: 2m 24s\tremaining: 10m 59s\n",
      "90:\tlearn: 0.0243085\ttotal: 2m 26s\tremaining: 10m 56s\n",
      "91:\tlearn: 0.0236348\ttotal: 2m 27s\tremaining: 10m 53s\n",
      "92:\tlearn: 0.0231374\ttotal: 2m 28s\tremaining: 10m 49s\n",
      "93:\tlearn: 0.0225130\ttotal: 2m 29s\tremaining: 10m 46s\n",
      "94:\tlearn: 0.0219325\ttotal: 2m 30s\tremaining: 10m 42s\n",
      "95:\tlearn: 0.0213843\ttotal: 2m 32s\tremaining: 10m 39s\n",
      "96:\tlearn: 0.0208376\ttotal: 2m 33s\tremaining: 10m 36s\n",
      "97:\tlearn: 0.0203093\ttotal: 2m 34s\tremaining: 10m 34s\n",
      "98:\tlearn: 0.0197630\ttotal: 2m 35s\tremaining: 10m 31s\n",
      "99:\tlearn: 0.0192173\ttotal: 2m 37s\tremaining: 10m 28s\n",
      "100:\tlearn: 0.0186965\ttotal: 2m 38s\tremaining: 10m 25s\n",
      "101:\tlearn: 0.0181323\ttotal: 2m 39s\tremaining: 10m 22s\n",
      "102:\tlearn: 0.0177676\ttotal: 2m 40s\tremaining: 10m 19s\n",
      "103:\tlearn: 0.0172067\ttotal: 2m 41s\tremaining: 10m 16s\n",
      "104:\tlearn: 0.0168533\ttotal: 2m 43s\tremaining: 10m 14s\n",
      "105:\tlearn: 0.0164602\ttotal: 2m 44s\tremaining: 10m 12s\n",
      "106:\tlearn: 0.0160837\ttotal: 2m 45s\tremaining: 10m 9s\n",
      "107:\tlearn: 0.0156923\ttotal: 2m 47s\tremaining: 10m 6s\n",
      "108:\tlearn: 0.0152907\ttotal: 2m 48s\tremaining: 10m 4s\n",
      "109:\tlearn: 0.0149385\ttotal: 2m 49s\tremaining: 10m 1s\n",
      "110:\tlearn: 0.0146470\ttotal: 2m 50s\tremaining: 9m 59s\n",
      "111:\tlearn: 0.0143123\ttotal: 2m 52s\tremaining: 9m 56s\n",
      "112:\tlearn: 0.0139571\ttotal: 2m 53s\tremaining: 9m 54s\n",
      "113:\tlearn: 0.0136374\ttotal: 2m 54s\tremaining: 9m 51s\n",
      "114:\tlearn: 0.0133495\ttotal: 2m 55s\tremaining: 9m 49s\n",
      "115:\tlearn: 0.0130326\ttotal: 2m 57s\tremaining: 9m 46s\n",
      "116:\tlearn: 0.0127857\ttotal: 2m 58s\tremaining: 9m 44s\n",
      "117:\tlearn: 0.0125461\ttotal: 2m 59s\tremaining: 9m 42s\n",
      "118:\tlearn: 0.0122452\ttotal: 3m 1s\tremaining: 9m 39s\n",
      "119:\tlearn: 0.0118919\ttotal: 3m 2s\tremaining: 9m 37s\n",
      "120:\tlearn: 0.0115724\ttotal: 3m 3s\tremaining: 9m 34s\n",
      "121:\tlearn: 0.0113099\ttotal: 3m 4s\tremaining: 9m 32s\n",
      "122:\tlearn: 0.0110324\ttotal: 3m 6s\tremaining: 9m 30s\n",
      "123:\tlearn: 0.0107795\ttotal: 3m 7s\tremaining: 9m 27s\n",
      "124:\tlearn: 0.0104821\ttotal: 3m 8s\tremaining: 9m 25s\n",
      "125:\tlearn: 0.0102748\ttotal: 3m 10s\tremaining: 9m 24s\n",
      "126:\tlearn: 0.0100518\ttotal: 3m 11s\tremaining: 9m 21s\n",
      "127:\tlearn: 0.0098499\ttotal: 3m 12s\tremaining: 9m 19s\n",
      "128:\tlearn: 0.0096258\ttotal: 3m 13s\tremaining: 9m 17s\n",
      "129:\tlearn: 0.0094417\ttotal: 3m 14s\tremaining: 9m 14s\n",
      "130:\tlearn: 0.0092572\ttotal: 3m 16s\tremaining: 9m 12s\n",
      "131:\tlearn: 0.0090393\ttotal: 3m 17s\tremaining: 9m 10s\n",
      "132:\tlearn: 0.0088822\ttotal: 3m 18s\tremaining: 9m 8s\n",
      "133:\tlearn: 0.0086577\ttotal: 3m 19s\tremaining: 9m 6s\n",
      "134:\tlearn: 0.0085335\ttotal: 3m 21s\tremaining: 9m 3s\n",
      "135:\tlearn: 0.0083640\ttotal: 3m 22s\tremaining: 9m 1s\n",
      "136:\tlearn: 0.0081526\ttotal: 3m 23s\tremaining: 8m 59s\n",
      "137:\tlearn: 0.0079629\ttotal: 3m 24s\tremaining: 8m 57s\n",
      "138:\tlearn: 0.0077817\ttotal: 3m 26s\tremaining: 8m 55s\n",
      "139:\tlearn: 0.0076519\ttotal: 3m 27s\tremaining: 8m 53s\n",
      "140:\tlearn: 0.0074813\ttotal: 3m 28s\tremaining: 8m 51s\n",
      "141:\tlearn: 0.0072806\ttotal: 3m 29s\tremaining: 8m 48s\n",
      "142:\tlearn: 0.0070894\ttotal: 3m 31s\tremaining: 8m 47s\n",
      "143:\tlearn: 0.0069213\ttotal: 3m 32s\tremaining: 8m 45s\n",
      "144:\tlearn: 0.0067696\ttotal: 3m 33s\tremaining: 8m 43s\n",
      "145:\tlearn: 0.0066031\ttotal: 3m 35s\tremaining: 8m 41s\n",
      "146:\tlearn: 0.0064602\ttotal: 3m 36s\tremaining: 8m 38s\n",
      "147:\tlearn: 0.0063162\ttotal: 3m 37s\tremaining: 8m 37s\n",
      "148:\tlearn: 0.0062100\ttotal: 3m 38s\tremaining: 8m 35s\n",
      "149:\tlearn: 0.0061199\ttotal: 3m 39s\tremaining: 8m 33s\n",
      "150:\tlearn: 0.0060087\ttotal: 3m 41s\tremaining: 8m 31s\n",
      "151:\tlearn: 0.0058971\ttotal: 3m 42s\tremaining: 8m 29s\n",
      "152:\tlearn: 0.0057745\ttotal: 3m 43s\tremaining: 8m 27s\n",
      "153:\tlearn: 0.0056525\ttotal: 3m 44s\tremaining: 8m 25s\n",
      "154:\tlearn: 0.0055540\ttotal: 3m 46s\tremaining: 8m 23s\n",
      "155:\tlearn: 0.0054405\ttotal: 3m 47s\tremaining: 8m 21s\n",
      "156:\tlearn: 0.0053272\ttotal: 3m 48s\tremaining: 8m 19s\n",
      "157:\tlearn: 0.0052275\ttotal: 3m 50s\tremaining: 8m 18s\n",
      "158:\tlearn: 0.0051322\ttotal: 3m 51s\tremaining: 8m 16s\n",
      "159:\tlearn: 0.0050529\ttotal: 3m 52s\tremaining: 8m 14s\n",
      "160:\tlearn: 0.0049494\ttotal: 3m 53s\tremaining: 8m 12s\n",
      "161:\tlearn: 0.0048498\ttotal: 3m 54s\tremaining: 8m 10s\n",
      "162:\tlearn: 0.0047673\ttotal: 3m 56s\tremaining: 8m 8s\n",
      "163:\tlearn: 0.0046833\ttotal: 3m 57s\tremaining: 8m 6s\n",
      "164:\tlearn: 0.0045870\ttotal: 3m 58s\tremaining: 8m 4s\n",
      "165:\tlearn: 0.0044871\ttotal: 4m\tremaining: 8m 3s\n",
      "166:\tlearn: 0.0043917\ttotal: 4m 1s\tremaining: 8m 1s\n",
      "167:\tlearn: 0.0042969\ttotal: 4m 2s\tremaining: 7m 59s\n",
      "168:\tlearn: 0.0042296\ttotal: 4m 3s\tremaining: 7m 57s\n",
      "169:\tlearn: 0.0041723\ttotal: 4m 5s\tremaining: 7m 55s\n",
      "170:\tlearn: 0.0041145\ttotal: 4m 6s\tremaining: 7m 53s\n",
      "171:\tlearn: 0.0040472\ttotal: 4m 7s\tremaining: 7m 51s\n",
      "172:\tlearn: 0.0039852\ttotal: 4m 8s\tremaining: 7m 50s\n",
      "173:\tlearn: 0.0039106\ttotal: 4m 10s\tremaining: 7m 48s\n",
      "174:\tlearn: 0.0038543\ttotal: 4m 11s\tremaining: 7m 46s\n",
      "175:\tlearn: 0.0037843\ttotal: 4m 12s\tremaining: 7m 45s\n",
      "176:\tlearn: 0.0037155\ttotal: 4m 13s\tremaining: 7m 43s\n",
      "177:\tlearn: 0.0036604\ttotal: 4m 15s\tremaining: 7m 41s\n",
      "178:\tlearn: 0.0036178\ttotal: 4m 16s\tremaining: 7m 39s\n",
      "179:\tlearn: 0.0035687\ttotal: 4m 17s\tremaining: 7m 37s\n",
      "180:\tlearn: 0.0035050\ttotal: 4m 18s\tremaining: 7m 36s\n",
      "181:\tlearn: 0.0034343\ttotal: 4m 19s\tremaining: 7m 34s\n",
      "182:\tlearn: 0.0033780\ttotal: 4m 21s\tremaining: 7m 32s\n",
      "183:\tlearn: 0.0033359\ttotal: 4m 22s\tremaining: 7m 30s\n",
      "184:\tlearn: 0.0032978\ttotal: 4m 23s\tremaining: 7m 29s\n",
      "185:\tlearn: 0.0032329\ttotal: 4m 25s\tremaining: 7m 27s\n",
      "186:\tlearn: 0.0031808\ttotal: 4m 26s\tremaining: 7m 25s\n",
      "187:\tlearn: 0.0031071\ttotal: 4m 27s\tremaining: 7m 24s\n",
      "188:\tlearn: 0.0030729\ttotal: 4m 28s\tremaining: 7m 22s\n",
      "189:\tlearn: 0.0030208\ttotal: 4m 30s\tremaining: 7m 20s\n",
      "190:\tlearn: 0.0029522\ttotal: 4m 31s\tremaining: 7m 18s\n",
      "191:\tlearn: 0.0029225\ttotal: 4m 32s\tremaining: 7m 17s\n",
      "192:\tlearn: 0.0028792\ttotal: 4m 33s\tremaining: 7m 15s\n",
      "193:\tlearn: 0.0028398\ttotal: 4m 35s\tremaining: 7m 13s\n",
      "194:\tlearn: 0.0027960\ttotal: 4m 36s\tremaining: 7m 12s\n",
      "195:\tlearn: 0.0027593\ttotal: 4m 37s\tremaining: 7m 10s\n",
      "196:\tlearn: 0.0027201\ttotal: 4m 38s\tremaining: 7m 8s\n",
      "197:\tlearn: 0.0026823\ttotal: 4m 40s\tremaining: 7m 7s\n",
      "198:\tlearn: 0.0026504\ttotal: 4m 41s\tremaining: 7m 5s\n",
      "199:\tlearn: 0.0026231\ttotal: 4m 42s\tremaining: 7m 4s\n",
      "200:\tlearn: 0.0025971\ttotal: 4m 44s\tremaining: 7m 2s\n",
      "201:\tlearn: 0.0025607\ttotal: 4m 45s\tremaining: 7m 1s\n",
      "202:\tlearn: 0.0025399\ttotal: 4m 46s\tremaining: 6m 59s\n",
      "203:\tlearn: 0.0025117\ttotal: 4m 48s\tremaining: 6m 57s\n",
      "204:\tlearn: 0.0024777\ttotal: 4m 49s\tremaining: 6m 56s\n",
      "205:\tlearn: 0.0024540\ttotal: 4m 50s\tremaining: 6m 54s\n",
      "206:\tlearn: 0.0024222\ttotal: 4m 51s\tremaining: 6m 53s\n",
      "207:\tlearn: 0.0023776\ttotal: 4m 53s\tremaining: 6m 51s\n",
      "208:\tlearn: 0.0023616\ttotal: 4m 54s\tremaining: 6m 49s\n",
      "209:\tlearn: 0.0023421\ttotal: 4m 55s\tremaining: 6m 48s\n",
      "210:\tlearn: 0.0023211\ttotal: 4m 57s\tremaining: 6m 46s\n",
      "211:\tlearn: 0.0022997\ttotal: 4m 58s\tremaining: 6m 45s\n",
      "212:\tlearn: 0.0022749\ttotal: 4m 59s\tremaining: 6m 43s\n",
      "213:\tlearn: 0.0022629\ttotal: 5m\tremaining: 6m 42s\n",
      "214:\tlearn: 0.0022365\ttotal: 5m 2s\tremaining: 6m 40s\n",
      "215:\tlearn: 0.0022118\ttotal: 5m 3s\tremaining: 6m 38s\n",
      "216:\tlearn: 0.0021941\ttotal: 5m 4s\tremaining: 6m 37s\n",
      "217:\tlearn: 0.0021739\ttotal: 5m 5s\tremaining: 6m 35s\n",
      "218:\tlearn: 0.0021470\ttotal: 5m 7s\tremaining: 6m 34s\n",
      "219:\tlearn: 0.0021145\ttotal: 5m 8s\tremaining: 6m 32s\n",
      "220:\tlearn: 0.0020905\ttotal: 5m 9s\tremaining: 6m 30s\n",
      "221:\tlearn: 0.0020758\ttotal: 5m 10s\tremaining: 6m 29s\n",
      "222:\tlearn: 0.0020504\ttotal: 5m 12s\tremaining: 6m 27s\n",
      "223:\tlearn: 0.0020345\ttotal: 5m 13s\tremaining: 6m 26s\n",
      "224:\tlearn: 0.0020170\ttotal: 5m 14s\tremaining: 6m 24s\n",
      "225:\tlearn: 0.0020016\ttotal: 5m 16s\tremaining: 6m 23s\n",
      "226:\tlearn: 0.0019729\ttotal: 5m 17s\tremaining: 6m 21s\n",
      "227:\tlearn: 0.0019561\ttotal: 5m 18s\tremaining: 6m 20s\n",
      "228:\tlearn: 0.0019433\ttotal: 5m 19s\tremaining: 6m 18s\n",
      "229:\tlearn: 0.0019208\ttotal: 5m 21s\tremaining: 6m 16s\n",
      "230:\tlearn: 0.0018951\ttotal: 5m 22s\tremaining: 6m 15s\n",
      "231:\tlearn: 0.0018708\ttotal: 5m 23s\tremaining: 6m 13s\n",
      "232:\tlearn: 0.0018519\ttotal: 5m 25s\tremaining: 6m 12s\n",
      "233:\tlearn: 0.0018325\ttotal: 5m 26s\tremaining: 6m 10s\n",
      "234:\tlearn: 0.0018226\ttotal: 5m 27s\tremaining: 6m 9s\n",
      "235:\tlearn: 0.0018084\ttotal: 5m 28s\tremaining: 6m 7s\n",
      "236:\tlearn: 0.0017892\ttotal: 5m 29s\tremaining: 6m 6s\n",
      "237:\tlearn: 0.0017692\ttotal: 5m 31s\tremaining: 6m 4s\n",
      "238:\tlearn: 0.0017562\ttotal: 5m 32s\tremaining: 6m 2s\n",
      "239:\tlearn: 0.0017353\ttotal: 5m 33s\tremaining: 6m 1s\n",
      "240:\tlearn: 0.0017106\ttotal: 5m 34s\tremaining: 5m 59s\n",
      "241:\tlearn: 0.0017003\ttotal: 5m 36s\tremaining: 5m 58s\n",
      "242:\tlearn: 0.0016800\ttotal: 5m 37s\tremaining: 5m 56s\n",
      "243:\tlearn: 0.0016670\ttotal: 5m 38s\tremaining: 5m 55s\n",
      "244:\tlearn: 0.0016552\ttotal: 5m 39s\tremaining: 5m 53s\n",
      "245:\tlearn: 0.0016472\ttotal: 5m 41s\tremaining: 5m 52s\n",
      "246:\tlearn: 0.0016321\ttotal: 5m 42s\tremaining: 5m 50s\n",
      "247:\tlearn: 0.0016244\ttotal: 5m 43s\tremaining: 5m 49s\n",
      "248:\tlearn: 0.0016134\ttotal: 5m 44s\tremaining: 5m 47s\n",
      "249:\tlearn: 0.0016002\ttotal: 5m 46s\tremaining: 5m 46s\n",
      "250:\tlearn: 0.0015908\ttotal: 5m 47s\tremaining: 5m 44s\n",
      "251:\tlearn: 0.0015857\ttotal: 5m 48s\tremaining: 5m 43s\n",
      "252:\tlearn: 0.0015770\ttotal: 5m 50s\tremaining: 5m 41s\n",
      "253:\tlearn: 0.0015673\ttotal: 5m 51s\tremaining: 5m 40s\n",
      "254:\tlearn: 0.0015571\ttotal: 5m 52s\tremaining: 5m 38s\n",
      "255:\tlearn: 0.0015432\ttotal: 5m 53s\tremaining: 5m 37s\n",
      "256:\tlearn: 0.0015302\ttotal: 5m 55s\tremaining: 5m 35s\n",
      "257:\tlearn: 0.0015199\ttotal: 5m 56s\tremaining: 5m 34s\n",
      "258:\tlearn: 0.0015033\ttotal: 5m 57s\tremaining: 5m 32s\n",
      "259:\tlearn: 0.0014922\ttotal: 5m 58s\tremaining: 5m 31s\n",
      "260:\tlearn: 0.0014845\ttotal: 6m\tremaining: 5m 29s\n",
      "261:\tlearn: 0.0014783\ttotal: 6m 1s\tremaining: 5m 28s\n",
      "262:\tlearn: 0.0014660\ttotal: 6m 2s\tremaining: 5m 26s\n",
      "263:\tlearn: 0.0014601\ttotal: 6m 3s\tremaining: 5m 25s\n",
      "264:\tlearn: 0.0014506\ttotal: 6m 5s\tremaining: 5m 23s\n",
      "265:\tlearn: 0.0014423\ttotal: 6m 6s\tremaining: 5m 22s\n",
      "266:\tlearn: 0.0014307\ttotal: 6m 7s\tremaining: 5m 20s\n",
      "267:\tlearn: 0.0014168\ttotal: 6m 8s\tremaining: 5m 19s\n",
      "268:\tlearn: 0.0014114\ttotal: 6m 10s\tremaining: 5m 17s\n",
      "269:\tlearn: 0.0013965\ttotal: 6m 11s\tremaining: 5m 16s\n",
      "270:\tlearn: 0.0013893\ttotal: 6m 12s\tremaining: 5m 14s\n",
      "271:\tlearn: 0.0013792\ttotal: 6m 13s\tremaining: 5m 13s\n",
      "272:\tlearn: 0.0013742\ttotal: 6m 14s\tremaining: 5m 11s\n",
      "273:\tlearn: 0.0013665\ttotal: 6m 16s\tremaining: 5m 10s\n",
      "274:\tlearn: 0.0013483\ttotal: 6m 17s\tremaining: 5m 9s\n",
      "275:\tlearn: 0.0013319\ttotal: 6m 19s\tremaining: 5m 7s\n",
      "276:\tlearn: 0.0013283\ttotal: 6m 20s\tremaining: 5m 6s\n",
      "277:\tlearn: 0.0013173\ttotal: 6m 21s\tremaining: 5m 4s\n",
      "278:\tlearn: 0.0013018\ttotal: 6m 23s\tremaining: 5m 3s\n",
      "279:\tlearn: 0.0012941\ttotal: 6m 24s\tremaining: 5m 1s\n",
      "280:\tlearn: 0.0012806\ttotal: 6m 25s\tremaining: 5m\n",
      "281:\tlearn: 0.0012755\ttotal: 6m 26s\tremaining: 4m 59s\n",
      "282:\tlearn: 0.0012710\ttotal: 6m 28s\tremaining: 4m 57s\n",
      "283:\tlearn: 0.0012576\ttotal: 6m 29s\tremaining: 4m 56s\n",
      "284:\tlearn: 0.0012521\ttotal: 6m 30s\tremaining: 4m 54s\n",
      "285:\tlearn: 0.0012438\ttotal: 6m 32s\tremaining: 4m 53s\n",
      "286:\tlearn: 0.0012354\ttotal: 6m 33s\tremaining: 4m 51s\n",
      "287:\tlearn: 0.0012293\ttotal: 6m 34s\tremaining: 4m 50s\n",
      "288:\tlearn: 0.0012250\ttotal: 6m 35s\tremaining: 4m 48s\n",
      "289:\tlearn: 0.0012184\ttotal: 6m 36s\tremaining: 4m 47s\n",
      "290:\tlearn: 0.0012079\ttotal: 6m 38s\tremaining: 4m 45s\n",
      "291:\tlearn: 0.0012022\ttotal: 6m 39s\tremaining: 4m 44s\n",
      "292:\tlearn: 0.0011938\ttotal: 6m 40s\tremaining: 4m 42s\n",
      "293:\tlearn: 0.0011892\ttotal: 6m 41s\tremaining: 4m 41s\n",
      "294:\tlearn: 0.0011855\ttotal: 6m 42s\tremaining: 4m 40s\n",
      "295:\tlearn: 0.0011785\ttotal: 6m 44s\tremaining: 4m 38s\n",
      "296:\tlearn: 0.0011694\ttotal: 6m 45s\tremaining: 4m 37s\n",
      "297:\tlearn: 0.0011653\ttotal: 6m 46s\tremaining: 4m 35s\n",
      "298:\tlearn: 0.0011541\ttotal: 6m 47s\tremaining: 4m 34s\n",
      "299:\tlearn: 0.0011460\ttotal: 6m 49s\tremaining: 4m 32s\n",
      "300:\tlearn: 0.0011423\ttotal: 6m 50s\tremaining: 4m 31s\n",
      "301:\tlearn: 0.0011376\ttotal: 6m 51s\tremaining: 4m 29s\n",
      "302:\tlearn: 0.0011331\ttotal: 6m 52s\tremaining: 4m 28s\n",
      "303:\tlearn: 0.0011278\ttotal: 6m 53s\tremaining: 4m 26s\n",
      "304:\tlearn: 0.0011178\ttotal: 6m 55s\tremaining: 4m 25s\n",
      "305:\tlearn: 0.0011096\ttotal: 6m 56s\tremaining: 4m 23s\n",
      "306:\tlearn: 0.0011069\ttotal: 6m 57s\tremaining: 4m 22s\n",
      "307:\tlearn: 0.0011051\ttotal: 6m 58s\tremaining: 4m 20s\n",
      "308:\tlearn: 0.0010971\ttotal: 6m 59s\tremaining: 4m 19s\n",
      "309:\tlearn: 0.0010938\ttotal: 7m 1s\tremaining: 4m 18s\n",
      "310:\tlearn: 0.0010886\ttotal: 7m 2s\tremaining: 4m 16s\n",
      "311:\tlearn: 0.0010793\ttotal: 7m 3s\tremaining: 4m 15s\n",
      "312:\tlearn: 0.0010702\ttotal: 7m 4s\tremaining: 4m 13s\n",
      "313:\tlearn: 0.0010643\ttotal: 7m 6s\tremaining: 4m 12s\n",
      "314:\tlearn: 0.0010597\ttotal: 7m 7s\tremaining: 4m 10s\n",
      "315:\tlearn: 0.0010558\ttotal: 7m 8s\tremaining: 4m 9s\n",
      "316:\tlearn: 0.0010489\ttotal: 7m 9s\tremaining: 4m 8s\n",
      "317:\tlearn: 0.0010401\ttotal: 7m 10s\tremaining: 4m 6s\n",
      "318:\tlearn: 0.0010343\ttotal: 7m 12s\tremaining: 4m 5s\n",
      "319:\tlearn: 0.0010311\ttotal: 7m 13s\tremaining: 4m 3s\n",
      "320:\tlearn: 0.0010269\ttotal: 7m 14s\tremaining: 4m 2s\n",
      "321:\tlearn: 0.0010262\ttotal: 7m 15s\tremaining: 4m\n",
      "322:\tlearn: 0.0010252\ttotal: 7m 16s\tremaining: 3m 59s\n",
      "323:\tlearn: 0.0010192\ttotal: 7m 18s\tremaining: 3m 58s\n",
      "324:\tlearn: 0.0010169\ttotal: 7m 19s\tremaining: 3m 56s\n",
      "325:\tlearn: 0.0010067\ttotal: 7m 20s\tremaining: 3m 55s\n",
      "326:\tlearn: 0.0010005\ttotal: 7m 21s\tremaining: 3m 53s\n",
      "327:\tlearn: 0.0009986\ttotal: 7m 23s\tremaining: 3m 52s\n",
      "328:\tlearn: 0.0009956\ttotal: 7m 24s\tremaining: 3m 50s\n",
      "329:\tlearn: 0.0009931\ttotal: 7m 25s\tremaining: 3m 49s\n",
      "330:\tlearn: 0.0009921\ttotal: 7m 26s\tremaining: 3m 48s\n",
      "331:\tlearn: 0.0009877\ttotal: 7m 27s\tremaining: 3m 46s\n",
      "332:\tlearn: 0.0009862\ttotal: 7m 29s\tremaining: 3m 45s\n",
      "333:\tlearn: 0.0009811\ttotal: 7m 30s\tremaining: 3m 43s\n",
      "334:\tlearn: 0.0009784\ttotal: 7m 31s\tremaining: 3m 42s\n",
      "335:\tlearn: 0.0009715\ttotal: 7m 32s\tremaining: 3m 40s\n",
      "336:\tlearn: 0.0009649\ttotal: 7m 33s\tremaining: 3m 39s\n",
      "337:\tlearn: 0.0009604\ttotal: 7m 35s\tremaining: 3m 38s\n",
      "338:\tlearn: 0.0009578\ttotal: 7m 36s\tremaining: 3m 36s\n",
      "339:\tlearn: 0.0009530\ttotal: 7m 38s\tremaining: 3m 35s\n",
      "340:\tlearn: 0.0009492\ttotal: 7m 39s\tremaining: 3m 34s\n",
      "341:\tlearn: 0.0009435\ttotal: 7m 40s\tremaining: 3m 32s\n",
      "342:\tlearn: 0.0009387\ttotal: 7m 41s\tremaining: 3m 31s\n",
      "343:\tlearn: 0.0009340\ttotal: 7m 42s\tremaining: 3m 29s\n",
      "344:\tlearn: 0.0009265\ttotal: 7m 44s\tremaining: 3m 28s\n",
      "345:\tlearn: 0.0009211\ttotal: 7m 45s\tremaining: 3m 27s\n",
      "346:\tlearn: 0.0009169\ttotal: 7m 46s\tremaining: 3m 25s\n",
      "347:\tlearn: 0.0009150\ttotal: 7m 47s\tremaining: 3m 24s\n",
      "348:\tlearn: 0.0009111\ttotal: 7m 48s\tremaining: 3m 22s\n",
      "349:\tlearn: 0.0009062\ttotal: 7m 50s\tremaining: 3m 21s\n",
      "350:\tlearn: 0.0008999\ttotal: 7m 51s\tremaining: 3m 20s\n",
      "351:\tlearn: 0.0008966\ttotal: 7m 52s\tremaining: 3m 18s\n",
      "352:\tlearn: 0.0008946\ttotal: 7m 53s\tremaining: 3m 17s\n",
      "353:\tlearn: 0.0008941\ttotal: 7m 55s\tremaining: 3m 15s\n",
      "354:\tlearn: 0.0008855\ttotal: 7m 56s\tremaining: 3m 14s\n",
      "355:\tlearn: 0.0008792\ttotal: 7m 57s\tremaining: 3m 13s\n",
      "356:\tlearn: 0.0008736\ttotal: 7m 58s\tremaining: 3m 11s\n",
      "357:\tlearn: 0.0008702\ttotal: 7m 59s\tremaining: 3m 10s\n",
      "358:\tlearn: 0.0008690\ttotal: 8m 1s\tremaining: 3m 9s\n",
      "359:\tlearn: 0.0008687\ttotal: 8m 2s\tremaining: 3m 7s\n",
      "360:\tlearn: 0.0008662\ttotal: 8m 3s\tremaining: 3m 6s\n",
      "361:\tlearn: 0.0008638\ttotal: 8m 4s\tremaining: 3m 4s\n",
      "362:\tlearn: 0.0008595\ttotal: 8m 6s\tremaining: 3m 3s\n",
      "363:\tlearn: 0.0008538\ttotal: 8m 7s\tremaining: 3m 2s\n",
      "364:\tlearn: 0.0008505\ttotal: 8m 8s\tremaining: 3m\n",
      "365:\tlearn: 0.0008494\ttotal: 8m 10s\tremaining: 2m 59s\n",
      "366:\tlearn: 0.0008441\ttotal: 8m 11s\tremaining: 2m 58s\n",
      "367:\tlearn: 0.0008405\ttotal: 8m 12s\tremaining: 2m 56s\n",
      "368:\tlearn: 0.0008385\ttotal: 8m 13s\tremaining: 2m 55s\n",
      "369:\tlearn: 0.0008381\ttotal: 8m 14s\tremaining: 2m 53s\n",
      "370:\tlearn: 0.0008339\ttotal: 8m 16s\tremaining: 2m 52s\n",
      "371:\tlearn: 0.0008328\ttotal: 8m 17s\tremaining: 2m 51s\n",
      "372:\tlearn: 0.0008297\ttotal: 8m 18s\tremaining: 2m 49s\n",
      "373:\tlearn: 0.0008270\ttotal: 8m 20s\tremaining: 2m 48s\n",
      "374:\tlearn: 0.0008241\ttotal: 8m 21s\tremaining: 2m 47s\n",
      "375:\tlearn: 0.0008227\ttotal: 8m 22s\tremaining: 2m 45s\n",
      "376:\tlearn: 0.0008209\ttotal: 8m 23s\tremaining: 2m 44s\n",
      "377:\tlearn: 0.0008183\ttotal: 8m 24s\tremaining: 2m 42s\n",
      "378:\tlearn: 0.0008166\ttotal: 8m 26s\tremaining: 2m 41s\n",
      "379:\tlearn: 0.0008145\ttotal: 8m 27s\tremaining: 2m 40s\n",
      "380:\tlearn: 0.0008083\ttotal: 8m 28s\tremaining: 2m 38s\n",
      "381:\tlearn: 0.0008073\ttotal: 8m 29s\tremaining: 2m 37s\n",
      "382:\tlearn: 0.0008034\ttotal: 8m 30s\tremaining: 2m 36s\n",
      "383:\tlearn: 0.0007990\ttotal: 8m 32s\tremaining: 2m 34s\n",
      "384:\tlearn: 0.0007941\ttotal: 8m 33s\tremaining: 2m 33s\n",
      "385:\tlearn: 0.0007899\ttotal: 8m 34s\tremaining: 2m 31s\n",
      "386:\tlearn: 0.0007870\ttotal: 8m 35s\tremaining: 2m 30s\n",
      "387:\tlearn: 0.0007833\ttotal: 8m 37s\tremaining: 2m 29s\n",
      "388:\tlearn: 0.0007816\ttotal: 8m 38s\tremaining: 2m 27s\n",
      "389:\tlearn: 0.0007765\ttotal: 8m 39s\tremaining: 2m 26s\n",
      "390:\tlearn: 0.0007732\ttotal: 8m 40s\tremaining: 2m 25s\n",
      "391:\tlearn: 0.0007722\ttotal: 8m 41s\tremaining: 2m 23s\n",
      "392:\tlearn: 0.0007709\ttotal: 8m 43s\tremaining: 2m 22s\n",
      "393:\tlearn: 0.0007675\ttotal: 8m 44s\tremaining: 2m 21s\n",
      "394:\tlearn: 0.0007639\ttotal: 8m 45s\tremaining: 2m 19s\n",
      "395:\tlearn: 0.0007617\ttotal: 8m 46s\tremaining: 2m 18s\n",
      "396:\tlearn: 0.0007604\ttotal: 8m 48s\tremaining: 2m 17s\n",
      "397:\tlearn: 0.0007582\ttotal: 8m 49s\tremaining: 2m 15s\n",
      "398:\tlearn: 0.0007569\ttotal: 8m 50s\tremaining: 2m 14s\n",
      "399:\tlearn: 0.0007551\ttotal: 8m 51s\tremaining: 2m 12s\n",
      "400:\tlearn: 0.0007519\ttotal: 8m 52s\tremaining: 2m 11s\n",
      "401:\tlearn: 0.0007500\ttotal: 8m 54s\tremaining: 2m 10s\n",
      "402:\tlearn: 0.0007469\ttotal: 8m 55s\tremaining: 2m 8s\n",
      "403:\tlearn: 0.0007434\ttotal: 8m 56s\tremaining: 2m 7s\n",
      "404:\tlearn: 0.0007418\ttotal: 8m 57s\tremaining: 2m 6s\n",
      "405:\tlearn: 0.0007393\ttotal: 8m 59s\tremaining: 2m 4s\n",
      "406:\tlearn: 0.0007375\ttotal: 9m\tremaining: 2m 3s\n",
      "407:\tlearn: 0.0007365\ttotal: 9m 1s\tremaining: 2m 2s\n",
      "408:\tlearn: 0.0007345\ttotal: 9m 3s\tremaining: 2m\n",
      "409:\tlearn: 0.0007323\ttotal: 9m 4s\tremaining: 1m 59s\n",
      "410:\tlearn: 0.0007308\ttotal: 9m 5s\tremaining: 1m 58s\n",
      "411:\tlearn: 0.0007294\ttotal: 9m 6s\tremaining: 1m 56s\n",
      "412:\tlearn: 0.0007283\ttotal: 9m 7s\tremaining: 1m 55s\n",
      "413:\tlearn: 0.0007231\ttotal: 9m 8s\tremaining: 1m 53s\n",
      "414:\tlearn: 0.0007205\ttotal: 9m 9s\tremaining: 1m 52s\n",
      "415:\tlearn: 0.0007182\ttotal: 9m 10s\tremaining: 1m 51s\n",
      "416:\tlearn: 0.0007159\ttotal: 9m 12s\tremaining: 1m 49s\n",
      "417:\tlearn: 0.0007153\ttotal: 9m 13s\tremaining: 1m 48s\n",
      "418:\tlearn: 0.0007142\ttotal: 9m 14s\tremaining: 1m 47s\n",
      "419:\tlearn: 0.0007104\ttotal: 9m 15s\tremaining: 1m 45s\n",
      "420:\tlearn: 0.0007088\ttotal: 9m 17s\tremaining: 1m 44s\n",
      "421:\tlearn: 0.0007083\ttotal: 9m 17s\tremaining: 1m 43s\n",
      "422:\tlearn: 0.0007076\ttotal: 9m 18s\tremaining: 1m 41s\n",
      "423:\tlearn: 0.0007059\ttotal: 9m 19s\tremaining: 1m 40s\n",
      "424:\tlearn: 0.0007040\ttotal: 9m 20s\tremaining: 1m 38s\n",
      "425:\tlearn: 0.0006999\ttotal: 9m 20s\tremaining: 1m 37s\n",
      "426:\tlearn: 0.0006993\ttotal: 9m 21s\tremaining: 1m 36s\n",
      "427:\tlearn: 0.0006973\ttotal: 9m 22s\tremaining: 1m 34s\n",
      "428:\tlearn: 0.0006939\ttotal: 9m 23s\tremaining: 1m 33s\n",
      "429:\tlearn: 0.0006926\ttotal: 9m 23s\tremaining: 1m 31s\n",
      "430:\tlearn: 0.0006891\ttotal: 9m 24s\tremaining: 1m 30s\n",
      "431:\tlearn: 0.0006872\ttotal: 9m 25s\tremaining: 1m 28s\n",
      "432:\tlearn: 0.0006811\ttotal: 9m 26s\tremaining: 1m 27s\n",
      "433:\tlearn: 0.0006802\ttotal: 9m 26s\tremaining: 1m 26s\n",
      "434:\tlearn: 0.0006788\ttotal: 9m 27s\tremaining: 1m 24s\n",
      "435:\tlearn: 0.0006736\ttotal: 9m 28s\tremaining: 1m 23s\n",
      "436:\tlearn: 0.0006719\ttotal: 9m 29s\tremaining: 1m 22s\n",
      "437:\tlearn: 0.0006701\ttotal: 9m 29s\tremaining: 1m 20s\n",
      "438:\tlearn: 0.0006666\ttotal: 9m 30s\tremaining: 1m 19s\n",
      "439:\tlearn: 0.0006646\ttotal: 9m 31s\tremaining: 1m 17s\n",
      "440:\tlearn: 0.0006616\ttotal: 9m 31s\tremaining: 1m 16s\n",
      "441:\tlearn: 0.0006578\ttotal: 9m 32s\tremaining: 1m 15s\n",
      "442:\tlearn: 0.0006547\ttotal: 9m 33s\tremaining: 1m 13s\n",
      "443:\tlearn: 0.0006537\ttotal: 9m 34s\tremaining: 1m 12s\n",
      "444:\tlearn: 0.0006531\ttotal: 9m 34s\tremaining: 1m 11s\n",
      "445:\tlearn: 0.0006519\ttotal: 9m 35s\tremaining: 1m 9s\n",
      "446:\tlearn: 0.0006500\ttotal: 9m 36s\tremaining: 1m 8s\n",
      "447:\tlearn: 0.0006477\ttotal: 9m 37s\tremaining: 1m 6s\n",
      "448:\tlearn: 0.0006451\ttotal: 9m 37s\tremaining: 1m 5s\n",
      "449:\tlearn: 0.0006429\ttotal: 9m 38s\tremaining: 1m 4s\n",
      "450:\tlearn: 0.0006408\ttotal: 9m 39s\tremaining: 1m 2s\n",
      "451:\tlearn: 0.0006384\ttotal: 9m 40s\tremaining: 1m 1s\n",
      "452:\tlearn: 0.0006367\ttotal: 9m 40s\tremaining: 1m\n",
      "453:\tlearn: 0.0006344\ttotal: 9m 41s\tremaining: 58.9s\n",
      "454:\tlearn: 0.0006315\ttotal: 9m 42s\tremaining: 57.6s\n",
      "455:\tlearn: 0.0006308\ttotal: 9m 42s\tremaining: 56.2s\n",
      "456:\tlearn: 0.0006286\ttotal: 9m 43s\tremaining: 54.9s\n",
      "457:\tlearn: 0.0006276\ttotal: 9m 44s\tremaining: 53.6s\n",
      "458:\tlearn: 0.0006258\ttotal: 9m 45s\tremaining: 52.3s\n",
      "459:\tlearn: 0.0006243\ttotal: 9m 45s\tremaining: 50.9s\n",
      "460:\tlearn: 0.0006225\ttotal: 9m 46s\tremaining: 49.6s\n",
      "461:\tlearn: 0.0006210\ttotal: 9m 47s\tremaining: 48.3s\n",
      "462:\tlearn: 0.0006195\ttotal: 9m 47s\tremaining: 47s\n",
      "463:\tlearn: 0.0006190\ttotal: 9m 48s\tremaining: 45.7s\n",
      "464:\tlearn: 0.0006171\ttotal: 9m 49s\tremaining: 44.4s\n",
      "465:\tlearn: 0.0006154\ttotal: 9m 50s\tremaining: 43.1s\n",
      "466:\tlearn: 0.0006146\ttotal: 9m 50s\tremaining: 41.7s\n",
      "467:\tlearn: 0.0006136\ttotal: 9m 51s\tremaining: 40.4s\n",
      "468:\tlearn: 0.0006108\ttotal: 9m 52s\tremaining: 39.1s\n",
      "469:\tlearn: 0.0006092\ttotal: 9m 52s\tremaining: 37.8s\n",
      "470:\tlearn: 0.0006049\ttotal: 9m 53s\tremaining: 36.6s\n",
      "471:\tlearn: 0.0006038\ttotal: 9m 54s\tremaining: 35.3s\n",
      "472:\tlearn: 0.0006016\ttotal: 9m 55s\tremaining: 34s\n",
      "473:\tlearn: 0.0005997\ttotal: 9m 56s\tremaining: 32.7s\n",
      "474:\tlearn: 0.0005962\ttotal: 9m 56s\tremaining: 31.4s\n",
      "475:\tlearn: 0.0005957\ttotal: 9m 57s\tremaining: 30.1s\n",
      "476:\tlearn: 0.0005925\ttotal: 9m 58s\tremaining: 28.8s\n",
      "477:\tlearn: 0.0005911\ttotal: 9m 58s\tremaining: 27.6s\n",
      "478:\tlearn: 0.0005889\ttotal: 9m 59s\tremaining: 26.3s\n",
      "479:\tlearn: 0.0005881\ttotal: 10m\tremaining: 25s\n",
      "480:\tlearn: 0.0005862\ttotal: 10m 1s\tremaining: 23.8s\n",
      "481:\tlearn: 0.0005851\ttotal: 10m 2s\tremaining: 22.5s\n",
      "482:\tlearn: 0.0005840\ttotal: 10m 3s\tremaining: 21.2s\n",
      "483:\tlearn: 0.0005827\ttotal: 10m 4s\tremaining: 20s\n",
      "484:\tlearn: 0.0005806\ttotal: 10m 5s\tremaining: 18.7s\n",
      "485:\tlearn: 0.0005790\ttotal: 10m 5s\tremaining: 17.4s\n",
      "486:\tlearn: 0.0005775\ttotal: 10m 6s\tremaining: 16.2s\n",
      "487:\tlearn: 0.0005762\ttotal: 10m 7s\tremaining: 14.9s\n",
      "488:\tlearn: 0.0005743\ttotal: 10m 8s\tremaining: 13.7s\n",
      "489:\tlearn: 0.0005734\ttotal: 10m 9s\tremaining: 12.4s\n",
      "490:\tlearn: 0.0005721\ttotal: 10m 11s\tremaining: 11.2s\n",
      "491:\tlearn: 0.0005710\ttotal: 10m 12s\tremaining: 9.96s\n",
      "492:\tlearn: 0.0005700\ttotal: 10m 13s\tremaining: 8.71s\n",
      "493:\tlearn: 0.0005682\ttotal: 10m 14s\tremaining: 7.47s\n",
      "494:\tlearn: 0.0005668\ttotal: 10m 16s\tremaining: 6.22s\n",
      "495:\tlearn: 0.0005641\ttotal: 10m 17s\tremaining: 4.98s\n",
      "496:\tlearn: 0.0005623\ttotal: 10m 18s\tremaining: 3.73s\n",
      "497:\tlearn: 0.0005610\ttotal: 10m 20s\tremaining: 2.49s\n",
      "498:\tlearn: 0.0005596\ttotal: 10m 21s\tremaining: 1.25s\n",
      "499:\tlearn: 0.0005572\ttotal: 10m 22s\tremaining: 0us\n",
      "Accuracy: 0.9999398043641836\n",
      "\n",
      "Confusion Matrix:\n",
      " [[65985     0]\n",
      " [    8 66907]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     65985\n",
      "           1       1.00      1.00      1.00     66915\n",
      "\n",
      "    accuracy                           1.00    132900\n",
      "   macro avg       1.00      1.00      1.00    132900\n",
      "weighted avg       1.00      1.00      1.00    132900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Fraud'], axis=1)\n",
    "y = df['Fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a CatBoost Classifier\n",
    "model = CatBoostClassifier(iterations=500, depth=10, learning_rate=0.05, loss_function='MultiClass', random_seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, cat_features=None)  # You can specify categorical features if needed\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/Combined/imputed_combined.csv\")\n",
    "cols = ['Rndrng_Prvdr_Crdntls',\n",
    "'Rndrng_Prvdr_Gndr', \n",
    "'Rndrng_Prvdr_Type',\n",
    "'Rndrng_Prvdr_Mdcr_Prtcptg_Ind', \n",
    "'Tot_HCPCS_Cds', \n",
    "'Tot_Benes_x',\n",
    "'Tot_Srvcs', \n",
    "'Tot_Sbmtd_Chrg', \n",
    "'Tot_Mdcr_Alowd_Amt',\n",
    "'Tot_Mdcr_Pymt_Amt', \n",
    "'Tot_Mdcr_Stdzd_Amt', \n",
    "'Drug_Sprsn_Ind_x',\n",
    "'Drug_Tot_HCPCS_Cds', \n",
    "'Drug_Tot_Benes', \n",
    "'Drug_Tot_Srvcs',\n",
    "'Drug_Sbmtd_Chrg', \n",
    "'Drug_Mdcr_Alowd_Amt', \n",
    "'Drug_Mdcr_Pymt_Amt',\n",
    "       'Drug_Mdcr_Stdzd_Amt', 'Med_Sprsn_Ind', 'Med_Tot_HCPCS_Cds',\n",
    "       'Med_Tot_Benes', 'Med_Tot_Srvcs', 'Med_Sbmtd_Chrg',\n",
    "       'Med_Mdcr_Alowd_Amt', 'Med_Mdcr_Pymt_Amt', 'Med_Mdcr_Stdzd_Amt',\n",
    "       'Bene_Avg_Age_x', 'Bene_Age_LT_65_Cnt_x', 'Bene_Age_65_74_Cnt_x',\n",
    "       'Bene_Age_75_84_Cnt_x', 'Bene_Age_GT_84_Cnt_x', 'Bene_Feml_Cnt_x',\n",
    "       'Bene_Male_Cnt_x', 'Bene_Race_Wht_Cnt_x', 'Bene_Race_Black_Cnt_x',\n",
    "       'Bene_Race_API_Cnt', 'Bene_Race_Hspnc_Cnt_x',\n",
    "       'Bene_Race_NatInd_Cnt', 'Bene_Race_Othr_Cnt_x', 'Bene_Dual_Cnt_x',\n",
    "       'Bene_Ndual_Cnt_x', 'Bene_CC_AF_Pct_x', 'Bene_CC_Alzhmr_Pct_x',\n",
    "       'Bene_CC_Asthma_Pct_x', 'Bene_CC_Cncr_Pct_x', 'Bene_CC_CHF_Pct_x',\n",
    "       'Bene_CC_CKD_Pct_x', 'Bene_CC_COPD_Pct_x', 'Bene_CC_Dprssn_Pct_x',\n",
    "       'Bene_CC_Dbts_Pct_x', 'Bene_CC_Hyplpdma_Pct_x',\n",
    "       'Bene_CC_Hyprtnsn_Pct_x', 'Bene_CC_IHD_Pct_x', 'Bene_CC_Opo_Pct_x',\n",
    "       'Bene_CC_RAOA_Pct_x', 'Bene_CC_Sz_Pct_x', 'Bene_CC_Strok_Pct_x',\n",
    "       'Bene_Avg_Risk_Scre_x', 'Rndrng_NPI', 'Fraud_x', 'FraudType_x',\n",
    "'Prscrbr_Crdntls',\n",
    "       'Prscrbr_Type_src', 'Tot_Clms', 'Tot_30day_Fills',\n",
    "       'Tot_Drug_Cst', 'Tot_Day_Suply', 'GE65_Sprsn_Flag',\n",
    "       'GE65_Tot_Clms', 'GE65_Tot_30day_Fills', 'GE65_Tot_Drug_Cst',\n",
    "       'GE65_Tot_Day_Suply', 'GE65_Bene_Sprsn_Flag', 'GE65_Tot_Benes',\n",
    "       'Brnd_Sprsn_Flag', 'Brnd_Tot_Clms', 'Brnd_Tot_Drug_Cst',\n",
    "       'Gnrc_Sprsn_Flag', 'Gnrc_Tot_Clms', 'Gnrc_Tot_Drug_Cst',\n",
    "       'Othr_Sprsn_Flag', 'Othr_Tot_Clms', 'Othr_Tot_Drug_Cst',\n",
    "       'MAPD_Sprsn_Flag', 'MAPD_Tot_Clms', 'MAPD_Tot_Drug_Cst',\n",
    "       'PDP_Sprsn_Flag', 'PDP_Tot_Clms', 'PDP_Tot_Drug_Cst',\n",
    "       'LIS_Sprsn_Flag', 'LIS_Tot_Clms', 'LIS_Drug_Cst',\n",
    "       'NonLIS_Sprsn_Flag', 'NonLIS_Tot_Clms', 'NonLIS_Drug_Cst',\n",
    "       'Opioid_Tot_Clms', 'Opioid_Tot_Drug_Cst', 'Opioid_Tot_Suply',\n",
    "       'Opioid_Tot_Benes', 'Opioid_Prscrbr_Rate', 'Opioid_LA_Tot_Clms',\n",
    "       'Opioid_LA_Tot_Drug_Cst', 'Opioid_LA_Tot_Suply',\n",
    "       'Opioid_LA_Tot_Benes', 'Opioid_LA_Prscrbr_Rate', 'Antbtc_Tot_Clms',\n",
    "       'Antbtc_Tot_Drug_Cst', 'Antbtc_Tot_Benes',\n",
    "       'Antpsyct_GE65_Sprsn_Flag', 'Antpsyct_GE65_Tot_Clms',\n",
    "       'Antpsyct_GE65_Tot_Drug_Cst', 'Antpsyct_GE65_Tot_Benes',\n",
    "       'Bene_Race_Api_Cnt_x', \n",
    "       'Bene_Race_Natind_Cnt_x', \n",
    "       'Rfrg_Prvdr_Type_Flag', 'Tot_Suplrs', 'Tot_Suplr_HCPCS_Cds',\n",
    "       'Tot_Suplr_Benes', 'Tot_Suplr_Clms', 'Tot_Suplr_Srvcs',\n",
    "       'Suplr_Sbmtd_Chrgs', 'Suplr_Mdcr_Alowd_Amt', 'Suplr_Mdcr_Pymt_Amt',\n",
    "       'Suplr_Mdcr_Stdzd_Pymt_Amt', 'DME_Sprsn_Ind', 'DME_Tot_Suplrs',\n",
    "       'DME_Tot_Suplr_HCPCS_Cds', 'DME_Tot_Suplr_Benes',\n",
    "       'DME_Tot_Suplr_Clms', 'DME_Tot_Suplr_Srvcs',\n",
    "       'DME_Suplr_Sbmtd_Chrgs', 'DME_Suplr_Mdcr_Alowd_Amt',\n",
    "       'DME_Suplr_Mdcr_Pymt_Amt', 'DME_Suplr_Mdcr_Stdzd_Pymt_Amt',\n",
    "       'POS_Sprsn_Ind', 'POS_Tot_Suplrs', 'POS_Tot_Suplr_HCPCS_Cds',\n",
    "       'POS_Tot_Suplr_Benes', 'POS_Tot_Suplr_Clms', 'POS_Tot_Suplr_Srvcs',\n",
    "       'POS_Suplr_Sbmtd_Chrgs', 'POS_Suplr_Mdcr_Alowd_Amt',\n",
    "       'POS_Suplr_Mdcr_Pymt_Amt', 'POS_Suplr_Mdcr_Stdzd_Pymt_Amt',\n",
    "       'Drug_Tot_Suplrs', 'Drug_Tot_Suplr_HCPCS_Cds',\n",
    "       'Drug_Tot_Suplr_Benes', 'Drug_Tot_Suplr_Clms',\n",
    "       'Drug_Tot_Suplr_Srvcs', 'Drug_Suplr_Sbmtd_Chrgs',\n",
    "       'Drug_Suplr_Mdcr_Alowd_Amt', 'Drug_Suplr_Mdcr_Pymt_Amt',\n",
    "       'Drug_Suplr_Mdcr_Stdzd_Pymt_Amt', 'Bene_Avg_Age',\n",
    "       'Fraud', 'FraudType']\n",
    "df = df[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Fraud_x\",\"FraudType_x\",\"Rndrng_NPI\",],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.8665983\ttotal: 1.55s\tremaining: 6.21s\n",
      "1:\tlearn: 1.6038835\ttotal: 2.96s\tremaining: 4.44s\n",
      "2:\tlearn: 1.4119142\ttotal: 4.44s\tremaining: 2.96s\n",
      "3:\tlearn: 1.2619998\ttotal: 5.96s\tremaining: 1.49s\n",
      "4:\tlearn: 1.1392945\ttotal: 7.53s\tremaining: 0us\n",
      "Accuracy: 0.9998953271028037\n",
      "\n",
      "Confusion Matrix:\n",
      " [[66868     0     0     0     0]\n",
      " [    3     0     0     0     0]\n",
      " [    2     0     0     0     0]\n",
      " [    1     0     0     0     0]\n",
      " [    1     0     0     0     0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     66868\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           1.00     66875\n",
      "   macro avg       0.20      0.20      0.20     66875\n",
      "weighted avg       1.00      1.00      1.00     66875\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Fraud','FraudType'], axis=1)\n",
    "y = df['FraudType']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a CatBoost Classifier\n",
    "model = CatBoostClassifier(iterations=5, depth=10, learning_rate=0.05, loss_function='MultiClass', random_seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, cat_features=None)  # You can specify categorical features if needed\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/combined/combined_rus_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"Fraud_x\",\"Rndrng_NPI\",],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.2846142\ttotal: 195ms\tremaining: 781ms\n",
      "1:\tlearn: 2.2659605\ttotal: 363ms\tremaining: 545ms\n",
      "2:\tlearn: 2.2493475\ttotal: 555ms\tremaining: 370ms\n",
      "3:\tlearn: 2.2329180\ttotal: 732ms\tremaining: 183ms\n",
      "4:\tlearn: 2.2087960\ttotal: 900ms\tremaining: 0us\n",
      "Accuracy: 0.6086956521739131\n",
      "\n",
      "Confusion Matrix:\n",
      " [[12  2  1  0  0  0]\n",
      " [ 0  1  1  1  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1]\n",
      " [ 0  1  0  0  1  0]\n",
      " [ 1  0  0  0  1  0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.86        15\n",
      "           1       0.25      0.33      0.29         3\n",
      "           3       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         1\n",
      "          10       0.50      0.50      0.50         2\n",
      "          11       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.61        23\n",
      "   macro avg       0.28      0.27      0.27        23\n",
      "weighted avg       0.68      0.61      0.64        23\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['FraudType_x'], axis=1)\n",
    "y = df['FraudType_x']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a CatBoost Classifier\n",
    "model = CatBoostClassifier(iterations=5, depth=10, learning_rate=0.05, loss_function='MultiClass', random_seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, cat_features=None)  # You can specify categorical features if needed\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/combined/combined_ros_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"Fraud_x\",\"Rndrng_NPI\",],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.8797705\ttotal: 2.49s\tremaining: 9.96s\n",
      "1:\tlearn: 1.6129730\ttotal: 5.15s\tremaining: 7.72s\n",
      "2:\tlearn: 1.4288380\ttotal: 7.61s\tremaining: 5.08s\n",
      "3:\tlearn: 1.2758065\ttotal: 10.3s\tremaining: 2.57s\n",
      "4:\tlearn: 1.1566469\ttotal: 13s\tremaining: 0us\n",
      "Accuracy: 1.0\n",
      "\n",
      "Confusion Matrix:\n",
      " [[66792     0     0     0     0     0     0     0     0     0]\n",
      " [    0 22831     0     0     0     0     0     0     0     0]\n",
      " [    0     0  7111     0     0     0     0     0     0     0]\n",
      " [    0     0     0  1183     0     0     0     0     0     0]\n",
      " [    0     0     0     0  1197     0     0     0     0     0]\n",
      " [    0     0     0     0     0  3536     0     0     0     0]\n",
      " [    0     0     0     0     0     0  1194     0     0     0]\n",
      " [    0     0     0     0     0     0     0  7043     0     0]\n",
      " [    0     0     0     0     0     0     0     0 16790     0]\n",
      " [    0     0     0     0     0     0     0     0     0  6051]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     66792\n",
      "           1       1.00      1.00      1.00     22831\n",
      "           2       1.00      1.00      1.00      7111\n",
      "           3       1.00      1.00      1.00      1183\n",
      "           4       1.00      1.00      1.00      1197\n",
      "           5       1.00      1.00      1.00      3536\n",
      "           6       1.00      1.00      1.00      1194\n",
      "           7       1.00      1.00      1.00      7043\n",
      "          10       1.00      1.00      1.00     16790\n",
      "          11       1.00      1.00      1.00      6051\n",
      "\n",
      "    accuracy                           1.00    133728\n",
      "   macro avg       1.00      1.00      1.00    133728\n",
      "weighted avg       1.00      1.00      1.00    133728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['FraudType_x'], axis=1)\n",
    "y = df['FraudType_x']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a CatBoost Classifier\n",
    "model = CatBoostClassifier(iterations=5, depth=10, learning_rate=0.05, loss_function='MultiClass', random_seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, cat_features=None)  # You can specify categorical features if needed\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
