{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f639e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b723ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/part_B/features/partb_features_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a70c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['Rndrng_Prvdr_Type'] = label_encoder.fit_transform(df['Rndrng_Prvdr_Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eeef2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['Rndrng_Prvdr_Gndr'] = label_encoder.fit_transform(df['Rndrng_Prvdr_Gndr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22baba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['FraudType'] = label_encoder.fit_transform(df['FraudType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6534ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"Rndrng_NPI\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "604f2e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rndrng_Prvdr_Type</th>\n",
       "      <th>Rndrng_Prvdr_Gndr</th>\n",
       "      <th>Tot_Srvcs</th>\n",
       "      <th>Tot_Benes</th>\n",
       "      <th>Tot_Sbmtd_Chrg</th>\n",
       "      <th>Tot_Mdcr_Alowd_Amt</th>\n",
       "      <th>Tot_Mdcr_Pymt_Amt</th>\n",
       "      <th>Tot_Mdcr_Stdzd_Amt</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>FraudType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>764.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>402812.00</td>\n",
       "      <td>85319.63</td>\n",
       "      <td>69175.78</td>\n",
       "      <td>66401.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>5930.0</td>\n",
       "      <td>2633.0</td>\n",
       "      <td>915291.00</td>\n",
       "      <td>227372.53</td>\n",
       "      <td>176497.74</td>\n",
       "      <td>167363.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>182532.48</td>\n",
       "      <td>101757.15</td>\n",
       "      <td>76938.82</td>\n",
       "      <td>80179.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>23680.00</td>\n",
       "      <td>9011.99</td>\n",
       "      <td>7224.35</td>\n",
       "      <td>7301.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>152154.00</td>\n",
       "      <td>30631.10</td>\n",
       "      <td>23962.85</td>\n",
       "      <td>23463.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100721</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>171.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>329504.00</td>\n",
       "      <td>32266.94</td>\n",
       "      <td>25803.90</td>\n",
       "      <td>22622.59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100722</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>182515.00</td>\n",
       "      <td>93505.14</td>\n",
       "      <td>68252.03</td>\n",
       "      <td>62671.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100723</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>415.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>20985.00</td>\n",
       "      <td>16171.02</td>\n",
       "      <td>11759.42</td>\n",
       "      <td>11851.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100724</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>851.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>304460.56</td>\n",
       "      <td>113283.09</td>\n",
       "      <td>85463.83</td>\n",
       "      <td>77169.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100725</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>884.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>340479.02</td>\n",
       "      <td>90924.61</td>\n",
       "      <td>74063.76</td>\n",
       "      <td>73646.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100726 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Rndrng_Prvdr_Type  Rndrng_Prvdr_Gndr  Tot_Srvcs  Tot_Benes  \\\n",
       "0                       39                  1      764.0      291.0   \n",
       "1                       65                  1     5930.0     2633.0   \n",
       "2                        5                  1     2003.0      167.0   \n",
       "3                       56                  0      571.0       56.0   \n",
       "4                       27                  1      125.0       89.0   \n",
       "...                    ...                ...        ...        ...   \n",
       "1100721                 22                  1      171.0      155.0   \n",
       "1100722                 39                  0     1093.0      333.0   \n",
       "1100723                 13                  1      415.0       66.0   \n",
       "1100724                 63                  1      851.0      456.0   \n",
       "1100725                 39                  0      884.0      407.0   \n",
       "\n",
       "         Tot_Sbmtd_Chrg  Tot_Mdcr_Alowd_Amt  Tot_Mdcr_Pymt_Amt  \\\n",
       "0             402812.00            85319.63           69175.78   \n",
       "1             915291.00           227372.53          176497.74   \n",
       "2             182532.48           101757.15           76938.82   \n",
       "3              23680.00             9011.99            7224.35   \n",
       "4             152154.00            30631.10           23962.85   \n",
       "...                 ...                 ...                ...   \n",
       "1100721       329504.00            32266.94           25803.90   \n",
       "1100722       182515.00            93505.14           68252.03   \n",
       "1100723        20985.00            16171.02           11759.42   \n",
       "1100724       304460.56           113283.09           85463.83   \n",
       "1100725       340479.02            90924.61           74063.76   \n",
       "\n",
       "         Tot_Mdcr_Stdzd_Amt  Fraud  FraudType  \n",
       "0                  66401.61      0          0  \n",
       "1                 167363.18      0          0  \n",
       "2                  80179.52      0          0  \n",
       "3                   7301.35      0          0  \n",
       "4                  23463.98      0          0  \n",
       "...                     ...    ...        ...  \n",
       "1100721            22622.59      0          0  \n",
       "1100722            62671.75      0          0  \n",
       "1100723            11851.98      0          0  \n",
       "1100724            77169.73      0          0  \n",
       "1100725            73646.68      0          0  \n",
       "\n",
       "[1100726 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c46d523f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujaykumar/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9998955238796071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[220123      3]\n",
      " [    20      0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    220126\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           1.00    220146\n",
      "   macro avg       0.50      0.50      0.50    220146\n",
      "weighted avg       1.00      1.00      1.00    220146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Fraud', 'FraudType'], axis=1)\n",
    "y = df['Fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f39ad454",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/part_B/features/partb_rus_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06ad9d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"Rndrng_NPI\",\"Unnamed: 0.1\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f9a046b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rndrng_Prvdr_Type</th>\n",
       "      <th>Rndrng_Prvdr_Gndr</th>\n",
       "      <th>Tot_Srvcs</th>\n",
       "      <th>Tot_Benes</th>\n",
       "      <th>Tot_Sbmtd_Chrg</th>\n",
       "      <th>Tot_Mdcr_Alowd_Amt</th>\n",
       "      <th>Tot_Mdcr_Pymt_Amt</th>\n",
       "      <th>Tot_Mdcr_Stdzd_Amt</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>179.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>30229.0</td>\n",
       "      <td>13396.09</td>\n",
       "      <td>5503.01</td>\n",
       "      <td>5263.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>671028.0</td>\n",
       "      <td>183976.13</td>\n",
       "      <td>141210.32</td>\n",
       "      <td>138865.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>604.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1133045.0</td>\n",
       "      <td>108549.88</td>\n",
       "      <td>86518.05</td>\n",
       "      <td>89429.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>74284.0</td>\n",
       "      <td>20153.42</td>\n",
       "      <td>16121.87</td>\n",
       "      <td>14639.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>2817.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>173978.0</td>\n",
       "      <td>70552.14</td>\n",
       "      <td>56161.94</td>\n",
       "      <td>52806.91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>4146.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>998238.0</td>\n",
       "      <td>333015.83</td>\n",
       "      <td>253335.52</td>\n",
       "      <td>228881.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15750.0</td>\n",
       "      <td>11082.67</td>\n",
       "      <td>7841.14</td>\n",
       "      <td>7549.29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1237.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>45641.0</td>\n",
       "      <td>33723.68</td>\n",
       "      <td>26885.67</td>\n",
       "      <td>25002.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>632.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>418272.0</td>\n",
       "      <td>135167.73</td>\n",
       "      <td>107625.89</td>\n",
       "      <td>96228.16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7294.4</td>\n",
       "      <td>2593.63</td>\n",
       "      <td>828.82</td>\n",
       "      <td>810.51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rndrng_Prvdr_Type  Rndrng_Prvdr_Gndr  Tot_Srvcs  Tot_Benes  \\\n",
       "0                   58                  1      179.0      133.0   \n",
       "1                   40                  1     1938.0     1023.0   \n",
       "2                   53                  1      604.0      193.0   \n",
       "3                   36                  0      236.0       54.0   \n",
       "4                   70                  0     2817.0       89.0   \n",
       "..                 ...                ...        ...        ...   \n",
       "201                 78                  1     4146.0      781.0   \n",
       "202                 26                  1       94.0       45.0   \n",
       "203                 70                  1     1237.0       11.0   \n",
       "204                 18                  1      632.0      177.0   \n",
       "205                 39                  1       57.0       24.0   \n",
       "\n",
       "     Tot_Sbmtd_Chrg  Tot_Mdcr_Alowd_Amt  Tot_Mdcr_Pymt_Amt  \\\n",
       "0           30229.0            13396.09            5503.01   \n",
       "1          671028.0           183976.13          141210.32   \n",
       "2         1133045.0           108549.88           86518.05   \n",
       "3           74284.0            20153.42           16121.87   \n",
       "4          173978.0            70552.14           56161.94   \n",
       "..              ...                 ...                ...   \n",
       "201        998238.0           333015.83          253335.52   \n",
       "202         15750.0            11082.67            7841.14   \n",
       "203         45641.0            33723.68           26885.67   \n",
       "204        418272.0           135167.73          107625.89   \n",
       "205          7294.4             2593.63             828.82   \n",
       "\n",
       "     Tot_Mdcr_Stdzd_Amt  Fraud  \n",
       "0               5263.85      0  \n",
       "1             138865.00      0  \n",
       "2              89429.57      0  \n",
       "3              14639.61      0  \n",
       "4              52806.91      0  \n",
       "..                  ...    ...  \n",
       "201           228881.87      1  \n",
       "202             7549.29      1  \n",
       "203            25002.94      1  \n",
       "204            96228.16      1  \n",
       "205              810.51      1  \n",
       "\n",
       "[206 rows x 9 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1df7abf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5714285714285714\n",
      "\n",
      "Confusion Matrix:\n",
      " [[18  2]\n",
      " [16  6]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.90      0.67        20\n",
      "           1       0.75      0.27      0.40        22\n",
      "\n",
      "    accuracy                           0.57        42\n",
      "   macro avg       0.64      0.59      0.53        42\n",
      "weighted avg       0.64      0.57      0.53        42\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujaykumar/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Fraud'], axis=1)\n",
    "y = df['Fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "497f7dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/part_B/features/partb_ros_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e918da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"Rndrng_NPI\",\"Unnamed: 0.1\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4703154a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rndrng_Prvdr_Type</th>\n",
       "      <th>Rndrng_Prvdr_Gndr</th>\n",
       "      <th>Tot_Srvcs</th>\n",
       "      <th>Tot_Benes</th>\n",
       "      <th>Tot_Sbmtd_Chrg</th>\n",
       "      <th>Tot_Mdcr_Alowd_Amt</th>\n",
       "      <th>Tot_Mdcr_Pymt_Amt</th>\n",
       "      <th>Tot_Mdcr_Stdzd_Amt</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>764.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>402812.00</td>\n",
       "      <td>85319.63</td>\n",
       "      <td>69175.78</td>\n",
       "      <td>66401.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>5930.0</td>\n",
       "      <td>2633.0</td>\n",
       "      <td>915291.00</td>\n",
       "      <td>227372.53</td>\n",
       "      <td>176497.74</td>\n",
       "      <td>167363.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>182532.48</td>\n",
       "      <td>101757.15</td>\n",
       "      <td>76938.82</td>\n",
       "      <td>80179.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>23680.00</td>\n",
       "      <td>9011.99</td>\n",
       "      <td>7224.35</td>\n",
       "      <td>7301.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>152154.00</td>\n",
       "      <td>30631.10</td>\n",
       "      <td>23962.85</td>\n",
       "      <td>23463.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181095</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>5263.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>797304.00</td>\n",
       "      <td>591578.26</td>\n",
       "      <td>443915.59</td>\n",
       "      <td>436072.86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181096</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>1355.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>141699.11</td>\n",
       "      <td>114326.91</td>\n",
       "      <td>86767.98</td>\n",
       "      <td>93482.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181097</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28875.00</td>\n",
       "      <td>1916.61</td>\n",
       "      <td>1180.93</td>\n",
       "      <td>1213.85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181098</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>544.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>101853.08</td>\n",
       "      <td>44113.45</td>\n",
       "      <td>31179.59</td>\n",
       "      <td>30797.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181099</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7821.27</td>\n",
       "      <td>2558.48</td>\n",
       "      <td>1926.74</td>\n",
       "      <td>1947.82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2181100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Rndrng_Prvdr_Type  Rndrng_Prvdr_Gndr  Tot_Srvcs  Tot_Benes  \\\n",
       "0                       39                  1      764.0      291.0   \n",
       "1                       65                  1     5930.0     2633.0   \n",
       "2                        5                  1     2003.0      167.0   \n",
       "3                       56                  0      571.0       56.0   \n",
       "4                       27                  1      125.0       89.0   \n",
       "...                    ...                ...        ...        ...   \n",
       "2181095                 39                  0     5263.0      583.0   \n",
       "2181096                 73                  0     1355.0      197.0   \n",
       "2181097                 55                  0       45.0       17.0   \n",
       "2181098                  5                  1      544.0      111.0   \n",
       "2181099                 55                  1       34.0       24.0   \n",
       "\n",
       "         Tot_Sbmtd_Chrg  Tot_Mdcr_Alowd_Amt  Tot_Mdcr_Pymt_Amt  \\\n",
       "0             402812.00            85319.63           69175.78   \n",
       "1             915291.00           227372.53          176497.74   \n",
       "2             182532.48           101757.15           76938.82   \n",
       "3              23680.00             9011.99            7224.35   \n",
       "4             152154.00            30631.10           23962.85   \n",
       "...                 ...                 ...                ...   \n",
       "2181095       797304.00           591578.26          443915.59   \n",
       "2181096       141699.11           114326.91           86767.98   \n",
       "2181097        28875.00             1916.61            1180.93   \n",
       "2181098       101853.08            44113.45           31179.59   \n",
       "2181099         7821.27             2558.48            1926.74   \n",
       "\n",
       "         Tot_Mdcr_Stdzd_Amt  Fraud  \n",
       "0                  66401.61      0  \n",
       "1                 167363.18      0  \n",
       "2                  80179.52      0  \n",
       "3                   7301.35      0  \n",
       "4                  23463.98      0  \n",
       "...                     ...    ...  \n",
       "2181095           436072.86      1  \n",
       "2181096            93482.18      1  \n",
       "2181097             1213.85      1  \n",
       "2181098            30797.07      1  \n",
       "2181099             1947.82      1  \n",
       "\n",
       "[2181100 rows x 9 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91b0d7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6733872816468754\n",
      "\n",
      "Confusion Matrix:\n",
      " [[162604  55717]\n",
      " [ 86758 131141]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.70    218321\n",
      "           1       0.70      0.60      0.65    217899\n",
      "\n",
      "    accuracy                           0.67    436220\n",
      "   macro avg       0.68      0.67      0.67    436220\n",
      "weighted avg       0.68      0.67      0.67    436220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Fraud'], axis=1)\n",
    "y = df['Fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4ac3a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/part_B/features/partb_smote_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ccc233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"Rndrng_NPI\",\"Unnamed: 0.1\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c34d4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rndrng_Prvdr_Type</th>\n",
       "      <th>Rndrng_Prvdr_Gndr</th>\n",
       "      <th>Tot_Srvcs</th>\n",
       "      <th>Tot_Benes</th>\n",
       "      <th>Tot_Sbmtd_Chrg</th>\n",
       "      <th>Tot_Mdcr_Alowd_Amt</th>\n",
       "      <th>Tot_Mdcr_Pymt_Amt</th>\n",
       "      <th>Tot_Mdcr_Stdzd_Amt</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>764.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>402812.000000</td>\n",
       "      <td>85319.630000</td>\n",
       "      <td>69175.780000</td>\n",
       "      <td>66401.610000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>5930.000000</td>\n",
       "      <td>2633.000000</td>\n",
       "      <td>915291.000000</td>\n",
       "      <td>227372.530000</td>\n",
       "      <td>176497.740000</td>\n",
       "      <td>167363.180000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>182532.480000</td>\n",
       "      <td>101757.150000</td>\n",
       "      <td>76938.820000</td>\n",
       "      <td>80179.520000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>571.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>23680.000000</td>\n",
       "      <td>9011.990000</td>\n",
       "      <td>7224.350000</td>\n",
       "      <td>7301.350000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>152154.000000</td>\n",
       "      <td>30631.100000</td>\n",
       "      <td>23962.850000</td>\n",
       "      <td>23463.980000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142144</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>619.810162</td>\n",
       "      <td>117.984270</td>\n",
       "      <td>61751.217391</td>\n",
       "      <td>49360.731950</td>\n",
       "      <td>37496.765168</td>\n",
       "      <td>40400.328511</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142145</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>244.931581</td>\n",
       "      <td>80.942454</td>\n",
       "      <td>525289.642077</td>\n",
       "      <td>18164.832569</td>\n",
       "      <td>14176.507835</td>\n",
       "      <td>14155.308921</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142146</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1273.124734</td>\n",
       "      <td>108.762793</td>\n",
       "      <td>166706.381486</td>\n",
       "      <td>96367.158779</td>\n",
       "      <td>73512.655005</td>\n",
       "      <td>74457.695885</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142147</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>4108.360309</td>\n",
       "      <td>157.904550</td>\n",
       "      <td>587022.018933</td>\n",
       "      <td>456556.784847</td>\n",
       "      <td>358018.286947</td>\n",
       "      <td>311220.813829</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142148</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>136.932271</td>\n",
       "      <td>90.588753</td>\n",
       "      <td>24363.812960</td>\n",
       "      <td>10535.303774</td>\n",
       "      <td>5951.674813</td>\n",
       "      <td>5511.121330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2142149 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Rndrng_Prvdr_Type  Rndrng_Prvdr_Gndr    Tot_Srvcs    Tot_Benes  \\\n",
       "0                       39                  1   764.000000   291.000000   \n",
       "1                       65                  1  5930.000000  2633.000000   \n",
       "2                        5                  1  2003.000000   167.000000   \n",
       "3                       56                  0   571.000000    56.000000   \n",
       "4                       27                  1   125.000000    89.000000   \n",
       "...                    ...                ...          ...          ...   \n",
       "2142144                 53                  0   619.810162   117.984270   \n",
       "2142145                 25                  1   244.931581    80.942454   \n",
       "2142146                 35                  1  1273.124734   108.762793   \n",
       "2142147                 18                  1  4108.360309   157.904550   \n",
       "2142148                 57                  0   136.932271    90.588753   \n",
       "\n",
       "         Tot_Sbmtd_Chrg  Tot_Mdcr_Alowd_Amt  Tot_Mdcr_Pymt_Amt  \\\n",
       "0         402812.000000        85319.630000       69175.780000   \n",
       "1         915291.000000       227372.530000      176497.740000   \n",
       "2         182532.480000       101757.150000       76938.820000   \n",
       "3          23680.000000         9011.990000        7224.350000   \n",
       "4         152154.000000        30631.100000       23962.850000   \n",
       "...                 ...                 ...                ...   \n",
       "2142144    61751.217391        49360.731950       37496.765168   \n",
       "2142145   525289.642077        18164.832569       14176.507835   \n",
       "2142146   166706.381486        96367.158779       73512.655005   \n",
       "2142147   587022.018933       456556.784847      358018.286947   \n",
       "2142148    24363.812960        10535.303774        5951.674813   \n",
       "\n",
       "         Tot_Mdcr_Stdzd_Amt  Fraud  \n",
       "0              66401.610000      0  \n",
       "1             167363.180000      0  \n",
       "2              80179.520000      0  \n",
       "3               7301.350000      0  \n",
       "4              23463.980000      0  \n",
       "...                     ...    ...  \n",
       "2142144        40400.328511      1  \n",
       "2142145        14155.308921      1  \n",
       "2142146        74457.695885      1  \n",
       "2142147       311220.813829      1  \n",
       "2142148         5511.121330      1  \n",
       "\n",
       "[2142149 rows x 9 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c061420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6769157155194547\n",
      "\n",
      "Confusion Matrix:\n",
      " [[152670  59752]\n",
      " [ 78667 137341]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.72      0.69    212422\n",
      "           1       0.70      0.64      0.66    216008\n",
      "\n",
      "    accuracy                           0.68    428430\n",
      "   macro avg       0.68      0.68      0.68    428430\n",
      "weighted avg       0.68      0.68      0.68    428430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Fraud'], axis=1)\n",
    "y = df['Fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36d63dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/part_B/features/partb_rus_type_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "abd07d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"Rndrng_NPI\",\"Unnamed: 0.1\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e388186c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rndrng_Prvdr_Type</th>\n",
       "      <th>Rndrng_Prvdr_Gndr</th>\n",
       "      <th>Tot_Srvcs</th>\n",
       "      <th>Tot_Benes</th>\n",
       "      <th>Tot_Sbmtd_Chrg</th>\n",
       "      <th>Tot_Mdcr_Alowd_Amt</th>\n",
       "      <th>Tot_Mdcr_Pymt_Amt</th>\n",
       "      <th>Tot_Mdcr_Stdzd_Amt</th>\n",
       "      <th>FraudType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>179.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>30229.00</td>\n",
       "      <td>13396.09</td>\n",
       "      <td>5503.01</td>\n",
       "      <td>5263.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>102219.34</td>\n",
       "      <td>74794.37</td>\n",
       "      <td>57189.21</td>\n",
       "      <td>55213.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>745.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>34978.00</td>\n",
       "      <td>23798.82</td>\n",
       "      <td>17696.67</td>\n",
       "      <td>16890.06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>448.00</td>\n",
       "      <td>156.54</td>\n",
       "      <td>150.88</td>\n",
       "      <td>152.89</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>408961.71</td>\n",
       "      <td>131982.22</td>\n",
       "      <td>96566.20</td>\n",
       "      <td>100945.32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4913.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>701734.01</td>\n",
       "      <td>545818.28</td>\n",
       "      <td>428190.59</td>\n",
       "      <td>371882.56</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>84.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>15185.00</td>\n",
       "      <td>9429.72</td>\n",
       "      <td>5761.06</td>\n",
       "      <td>5788.47</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>205.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>645500.00</td>\n",
       "      <td>14871.18</td>\n",
       "      <td>11622.38</td>\n",
       "      <td>11851.11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>242.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>228918.00</td>\n",
       "      <td>26580.47</td>\n",
       "      <td>21789.30</td>\n",
       "      <td>21066.43</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>734.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>127700.00</td>\n",
       "      <td>41871.52</td>\n",
       "      <td>31161.16</td>\n",
       "      <td>30651.67</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>138360.00</td>\n",
       "      <td>100556.21</td>\n",
       "      <td>78978.49</td>\n",
       "      <td>71050.28</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>13277.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>1578045.71</td>\n",
       "      <td>402458.02</td>\n",
       "      <td>301002.59</td>\n",
       "      <td>316486.95</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>1355.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>141699.11</td>\n",
       "      <td>114326.91</td>\n",
       "      <td>86767.98</td>\n",
       "      <td>93482.18</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rndrng_Prvdr_Type  Rndrng_Prvdr_Gndr  Tot_Srvcs  Tot_Benes  \\\n",
       "0                  58                  1      179.0      133.0   \n",
       "1                  24                  0      937.0      181.0   \n",
       "2                  26                  1      745.0       37.0   \n",
       "3                  24                  1       24.0       18.0   \n",
       "4                  64                  1     1911.0      191.0   \n",
       "5                   9                  1     4913.0      187.0   \n",
       "6                  39                  1       84.0       27.0   \n",
       "7                  12                  1      205.0       95.0   \n",
       "8                  22                  1      242.0      177.0   \n",
       "9                  21                  0      734.0      667.0   \n",
       "10                 51                  1     1395.0      102.0   \n",
       "11                  9                  1    13277.0      725.0   \n",
       "12                 73                  0     1355.0      197.0   \n",
       "\n",
       "    Tot_Sbmtd_Chrg  Tot_Mdcr_Alowd_Amt  Tot_Mdcr_Pymt_Amt  Tot_Mdcr_Stdzd_Amt  \\\n",
       "0         30229.00            13396.09            5503.01             5263.85   \n",
       "1        102219.34            74794.37           57189.21            55213.57   \n",
       "2         34978.00            23798.82           17696.67            16890.06   \n",
       "3           448.00              156.54             150.88              152.89   \n",
       "4        408961.71           131982.22           96566.20           100945.32   \n",
       "5        701734.01           545818.28          428190.59           371882.56   \n",
       "6         15185.00             9429.72            5761.06             5788.47   \n",
       "7        645500.00            14871.18           11622.38            11851.11   \n",
       "8        228918.00            26580.47           21789.30            21066.43   \n",
       "9        127700.00            41871.52           31161.16            30651.67   \n",
       "10       138360.00           100556.21           78978.49            71050.28   \n",
       "11      1578045.71           402458.02          301002.59           316486.95   \n",
       "12       141699.11           114326.91           86767.98            93482.18   \n",
       "\n",
       "    FraudType  \n",
       "0           0  \n",
       "1           1  \n",
       "2           2  \n",
       "3           3  \n",
       "4           4  \n",
       "5           5  \n",
       "6           6  \n",
       "7           7  \n",
       "8           8  \n",
       "9           9  \n",
       "10         10  \n",
       "11         11  \n",
       "12         12  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bad0757b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "\n",
      "Confusion Matrix:\n",
      " [[0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       1.0\n",
      "           4       0.00      0.00      0.00       0.0\n",
      "           6       0.00      0.00      0.00       0.0\n",
      "           8       0.00      0.00      0.00       0.0\n",
      "           9       0.00      0.00      0.00       1.0\n",
      "          11       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       3.0\n",
      "   macro avg       0.00      0.00      0.00       3.0\n",
      "weighted avg       0.00      0.00      0.00       3.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujaykumar/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/sujaykumar/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['FraudType'], axis=1)\n",
    "y = df['FraudType']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LogisticRegression(random_state=423)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "906d3a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/part_B/features/partb_ros_type_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d82a91d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"Rndrng_NPI\",\"Unnamed: 0.1\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22a65e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rndrng_Prvdr_Type</th>\n",
       "      <th>Rndrng_Prvdr_Gndr</th>\n",
       "      <th>Tot_Srvcs</th>\n",
       "      <th>Tot_Benes</th>\n",
       "      <th>Tot_Sbmtd_Chrg</th>\n",
       "      <th>Tot_Mdcr_Alowd_Amt</th>\n",
       "      <th>Tot_Mdcr_Pymt_Amt</th>\n",
       "      <th>Tot_Mdcr_Stdzd_Amt</th>\n",
       "      <th>FraudType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>764.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>402812.00</td>\n",
       "      <td>85319.63</td>\n",
       "      <td>69175.78</td>\n",
       "      <td>66401.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>5930.0</td>\n",
       "      <td>2633.0</td>\n",
       "      <td>915291.00</td>\n",
       "      <td>227372.53</td>\n",
       "      <td>176497.74</td>\n",
       "      <td>167363.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>182532.48</td>\n",
       "      <td>101757.15</td>\n",
       "      <td>76938.82</td>\n",
       "      <td>80179.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>23680.00</td>\n",
       "      <td>9011.99</td>\n",
       "      <td>7224.35</td>\n",
       "      <td>7301.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>152154.00</td>\n",
       "      <td>30631.10</td>\n",
       "      <td>23962.85</td>\n",
       "      <td>23463.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14177145</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>1355.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>141699.11</td>\n",
       "      <td>114326.91</td>\n",
       "      <td>86767.98</td>\n",
       "      <td>93482.18</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14177146</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>1355.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>141699.11</td>\n",
       "      <td>114326.91</td>\n",
       "      <td>86767.98</td>\n",
       "      <td>93482.18</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14177147</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>1355.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>141699.11</td>\n",
       "      <td>114326.91</td>\n",
       "      <td>86767.98</td>\n",
       "      <td>93482.18</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14177148</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>1355.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>141699.11</td>\n",
       "      <td>114326.91</td>\n",
       "      <td>86767.98</td>\n",
       "      <td>93482.18</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14177149</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>1355.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>141699.11</td>\n",
       "      <td>114326.91</td>\n",
       "      <td>86767.98</td>\n",
       "      <td>93482.18</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14177150 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Rndrng_Prvdr_Type  Rndrng_Prvdr_Gndr  Tot_Srvcs  Tot_Benes  \\\n",
       "0                        39                  1      764.0      291.0   \n",
       "1                        65                  1     5930.0     2633.0   \n",
       "2                         5                  1     2003.0      167.0   \n",
       "3                        56                  0      571.0       56.0   \n",
       "4                        27                  1      125.0       89.0   \n",
       "...                     ...                ...        ...        ...   \n",
       "14177145                 73                  0     1355.0      197.0   \n",
       "14177146                 73                  0     1355.0      197.0   \n",
       "14177147                 73                  0     1355.0      197.0   \n",
       "14177148                 73                  0     1355.0      197.0   \n",
       "14177149                 73                  0     1355.0      197.0   \n",
       "\n",
       "          Tot_Sbmtd_Chrg  Tot_Mdcr_Alowd_Amt  Tot_Mdcr_Pymt_Amt  \\\n",
       "0              402812.00            85319.63           69175.78   \n",
       "1              915291.00           227372.53          176497.74   \n",
       "2              182532.48           101757.15           76938.82   \n",
       "3               23680.00             9011.99            7224.35   \n",
       "4              152154.00            30631.10           23962.85   \n",
       "...                  ...                 ...                ...   \n",
       "14177145       141699.11           114326.91           86767.98   \n",
       "14177146       141699.11           114326.91           86767.98   \n",
       "14177147       141699.11           114326.91           86767.98   \n",
       "14177148       141699.11           114326.91           86767.98   \n",
       "14177149       141699.11           114326.91           86767.98   \n",
       "\n",
       "          Tot_Mdcr_Stdzd_Amt  FraudType  \n",
       "0                   66401.61          0  \n",
       "1                  167363.18          0  \n",
       "2                   80179.52          0  \n",
       "3                    7301.35          0  \n",
       "4                   23463.98          0  \n",
       "...                      ...        ...  \n",
       "14177145            93482.18         12  \n",
       "14177146            93482.18         12  \n",
       "14177147            93482.18         12  \n",
       "14177148            93482.18         12  \n",
       "14177149            93482.18         12  \n",
       "\n",
       "[14177150 rows x 9 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b69b1409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujaykumar/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/sujaykumar/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.27157856127642016\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 30061  17900  34907      0      3   5956      0      2  33730    115\n",
      "   34815  51840   9242]\n",
      " [  8115  32214  24233      0      0  24101      0      0  24142      0\n",
      "   40203  40443  24383]\n",
      " [ 39595      0  39862      0      0  39541      0      0      0      0\n",
      "   59582  39604      0]\n",
      " [     0 217713      0      0      0      0      0      0      0      0\n",
      "       0      0      0]\n",
      " [     0      0 108633      0      0      0      0      0      0      0\n",
      "       0 109348      0]\n",
      " [     0  27198  27339      0      0  27519      0      0      0      0\n",
      "   54380  54659  27170]\n",
      " [     0      0      0      0      0      0      0      0      0      0\n",
      "  218570      0      0]\n",
      " [     0      0  33505      0      0  16724      0      0  33668      0\n",
      "   50450  66408  16546]\n",
      " [     0      0      0      0      0      0      0      0 218003      0\n",
      "       0      0      0]\n",
      " [     0      0 218134      0      0      0      0      0      0      0\n",
      "       0      0      0]\n",
      " [ 21749  14482  29311      0      0   7350      0      0  14605      0\n",
      "   80371  36450  14636]\n",
      " [ 31378      0  62530      0      0      0      0      0      0      0\n",
      "       0 123876      0]\n",
      " [     0      0      0      0      0      0      0      0      0      0\n",
      "       0      0 218136]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.14      0.17    218571\n",
      "           1       0.10      0.15      0.12    217834\n",
      "           2       0.07      0.18      0.10    218184\n",
      "           3       0.00      0.00      0.00    217713\n",
      "           4       0.00      0.00      0.00    217981\n",
      "           5       0.23      0.13      0.16    218265\n",
      "           6       0.00      0.00      0.00    218570\n",
      "           7       0.00      0.00      0.00    217301\n",
      "           8       0.67      1.00      0.80    218003\n",
      "           9       0.00      0.00      0.00    218134\n",
      "          10       0.15      0.37      0.21    218954\n",
      "          11       0.24      0.57      0.33    217784\n",
      "          12       0.70      1.00      0.83    218136\n",
      "\n",
      "    accuracy                           0.27   2835430\n",
      "   macro avg       0.18      0.27      0.21   2835430\n",
      "weighted avg       0.18      0.27      0.21   2835430\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujaykumar/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['FraudType'], axis=1)\n",
    "y = df['FraudType']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LogisticRegression(random_state=423)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8bb723",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
